"""
ì˜¤ë””ì˜¤ ì²˜ë¦¬ API ì—”ë“œí¬ì¸íŠ¸
- ì „ì²˜ë¦¬ (Step 2)
- STT (Step 3)
"""
from fastapi import APIRouter, HTTPException, BackgroundTasks
from pathlib import Path
from typing import Dict
from app.services.preprocessing import preprocess_audio
from app.services.stt import run_stt_pipeline
from app.services.diarization import run_diarization, merge_stt_with_diarization
from app.core.config import settings
from app.core.device import get_device
import json
from sqlalchemy.orm import Session
from app.api.deps import get_db
from fastapi import Depends
from app.models.audio_file import AudioFile
from app.models.preprocessing import PreprocessingResult
from app.models.stt import STTResult


router = APIRouter()

# ì²˜ë¦¬ ìƒíƒœ ì €ì¥ (ì‹¤ì œë¡œëŠ” DB ì‚¬ìš©)
PROCESSING_STATUS: Dict[str, dict] = {}


def process_audio_pipeline(
    file_id: str,
    db: Session,
    whisper_mode: str = "local"
):
    """
    ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì˜¤ë””ì˜¤ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

    Args:
        file_id: íŒŒì¼ ID
        db: DB ì„¸ì…˜
        whisper_mode: Whisper ëª¨ë“œ ("local" ë˜ëŠ” "api")
    """
    try:
        # ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€
        device = get_device()

        # ëª¨ë¸ í¬ê¸° ê³ ì •
        model_size = "large-v3"

        # ìƒíƒœ ì—…ë°ì´íŠ¸: ì „ì²˜ë¦¬ ì‹œì‘
        PROCESSING_STATUS[file_id] = {
            "status": "preprocessing",
            "step": "ì „ì²˜ë¦¬ ì¤‘...",
            "progress": 10,
            "device": device,
            "model_size": model_size,
        }

        # 1) íŒŒì¼ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸° (ì„ì‹œë¡œ í•˜ë“œì½”ë”©, ë‚˜ì¤‘ì— DBì—ì„œ ê°€ì ¸ì˜¤ê¸°)
        upload_dir = Path("/app/uploads")
        input_files = list(upload_dir.glob(f"{file_id}.*"))
        if not input_files:
            raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_id}")
        input_path = input_files[0]

        # ì‘ì—… ë””ë ‰í† ë¦¬ ìƒì„±
        work_dir = Path(f"/app/temp/{file_id}")
        work_dir.mkdir(parents=True, exist_ok=True)

        # 2) ì „ì²˜ë¦¬
        preprocessed_path = work_dir / "preprocessed.wav"
        _, original_dur, processed_dur = preprocess_audio(input_path, preprocessed_path)

        PROCESSING_STATUS[file_id] = {
            "status": "preprocessing",
            "step": "ì „ì²˜ë¦¬ ì™„ë£Œ",
            "progress": 30,
            "original_duration": original_dur,
            "processed_duration": processed_dur,
        }

        # 3) STT
        use_local = whisper_mode == "local"
        stt_method = f"{'ë¡œì»¬' if use_local else 'API'} Whisper ({model_size})"

        PROCESSING_STATUS[file_id] = {
            "status": "stt",
            "step": f"STT ì§„í–‰ ì¤‘... ({stt_method})",
            "progress": 40,
        }

        # Whisper ì „ì‚¬ (ë¡œì»¬ ë˜ëŠ” API)
        final_txt = run_stt_pipeline(
            preprocessed_path,
            work_dir,
            openai_api_key=settings.OPENAI_API_KEY if not use_local else None,
            use_local_whisper=use_local,
            model_size=model_size,
            device=device
        )

        # STT ì™„ë£Œ í›„ ë©”ëª¨ë¦¬ ì •ë¦¬ (Diarization ì „ ë©”ëª¨ë¦¬ í™•ë³´)
        print("ğŸ§¹ STT ì™„ë£Œ, ë©”ëª¨ë¦¬ ì •ë¦¬ ì¤‘...")
        import gc
        import torch
        gc.collect()  # Python ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰
        if torch.cuda.is_available():
            torch.cuda.empty_cache()  # CUDA ìºì‹œ ì •ë¦¬
        print("âœ… ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")

        # 4) Diarization (í™”ì ë¶„ë¦¬)
        PROCESSING_STATUS[file_id] = {
            "status": "diarization",
            "step": "í™”ì ë¶„ë¦¬ ì¤‘...",
            "progress": 70,
        }

        try:
            diarization_result = run_diarization(preprocessed_path, device=device)

            # Diarization ê²°ê³¼ ì €ì¥
            diarization_json = work_dir / "diarization_result.json"
            with open(diarization_json, 'w', encoding='utf-8') as f:
                json.dump(diarization_result, f, ensure_ascii=False, indent=2)

            # STT ê²°ê³¼ íŒŒì‹±
            stt_segments = []
            for line in final_txt.read_text(encoding='utf-8').splitlines():
                if line.strip():
                    # [00:00:00.000 - 00:00:02.800] í…ìŠ¤íŠ¸ í˜•ì‹ íŒŒì‹±
                    import re
                    match = re.match(r'\[(\d{2}:\d{2}:\d{2}\.\d{3}) - (\d{2}:\d{2}:\d{2}\.\d{3})\] (.+)', line)
                    if match:
                        start_str, end_str, text = match.groups()
                        # ì‹œê°„ì„ ì´ˆë¡œ ë³€í™˜
                        def time_to_seconds(t):
                            h, m, s = t.split(':')
                            return int(h) * 3600 + int(m) * 60 + float(s)

                        stt_segments.append({
                            "text": text,
                            "start": time_to_seconds(start_str),
                            "end": time_to_seconds(end_str)
                        })

            # STT + Diarization ë³‘í•©
            merged_result = merge_stt_with_diarization(stt_segments, diarization_result)

            # ë³‘í•© ê²°ê³¼ ì €ì¥
            merged_json = work_dir / "merged_result.json"
            with open(merged_json, 'w', encoding='utf-8') as f:
                json.dump(merged_result, f, ensure_ascii=False, indent=2)

        except Exception as diarization_error:
            print(f"âš ï¸ Diarization failed: {diarization_error}")
            # Diarization ì‹¤íŒ¨í•´ë„ STT ê²°ê³¼ëŠ” ìœ ì§€
            diarization_result = None
            merged_result = None

        # 5) DB ì €ì¥
        PROCESSING_STATUS[file_id] = {
            "status": "saving",
            "step": "DB ì €ì¥ ì¤‘...",
            "progress": 90,
        }

        # TODO: DBì— STTResult ì €ì¥
        # í˜„ì¬ëŠ” íŒŒì¼ë¡œë§Œ ì €ì¥ë¨

        # ì™„ë£Œ
        PROCESSING_STATUS[file_id] = {
            "status": "completed",
            "step": "ì™„ë£Œ",
            "progress": 100,
            "transcript_path": str(final_txt),
            "diarization_path": str(work_dir / "diarization_result.json") if diarization_result else None,
            "merged_path": str(work_dir / "merged_result.json") if merged_result else None,
        }

    except Exception as e:
        PROCESSING_STATUS[file_id] = {
            "status": "failed",
            "step": "ì˜¤ë¥˜ ë°œìƒ",
            "progress": 0,
            "error": str(e),
        }


@router.post("/process/{file_id}")
async def start_processing(
    file_id: str,
    background_tasks: BackgroundTasks,
    whisper_mode: str = None  # "local" or "api" (Noneì¼ ê²½ìš° ì„¤ì •ê°’ ì‚¬ìš©)
):
    """
    ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ)

    Args:
        file_id: ì—…ë¡œë“œëœ íŒŒì¼ ID
        whisper_mode: Whisper ëª¨ë“œ ("local" ë˜ëŠ” "api", ê¸°ë³¸ê°’: ì„¤ì •ê°’)

    Returns:
        ì²˜ë¦¬ ì‹œì‘ í™•ì¸ ë©”ì‹œì§€

    Note:
        - model_size: large-v3 ê³ ì •
        - device: ìë™ ê°ì§€ (CUDA > MPS > CPU)
    """
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    upload_dir = Path("/app/uploads")
    input_files = list(upload_dir.glob(f"{file_id}.*"))
    if not input_files:
        raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # ì„¤ì •ê°’ ë˜ëŠ” íŒŒë¼ë¯¸í„° ì‚¬ìš©
    use_whisper_mode = whisper_mode if whisper_mode else settings.WHISPER_MODE

    # Whisper ëª¨ë“œ ê²€ì¦
    if use_whisper_mode not in ["local", "api"]:
        raise HTTPException(status_code=400, detail="whisper_modeëŠ” 'local' ë˜ëŠ” 'api'ì—¬ì•¼ í•©ë‹ˆë‹¤.")

    # API ëª¨ë“œì¼ ë•Œ API í‚¤ í™•ì¸
    if use_whisper_mode == "api" and not settings.OPENAI_API_KEY:
        raise HTTPException(status_code=400, detail="OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

    # ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€
    detected_device = get_device()

    # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹œì‘
    PROCESSING_STATUS[file_id] = {
        "status": "queued",
        "step": "ëŒ€ê¸° ì¤‘...",
        "progress": 0,
        "whisper_mode": use_whisper_mode,
        "model_size": "large-v3",
        "device": detected_device,
    }

    # TODO: DB ì„¸ì…˜ì„ ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ì— ì „ë‹¬
    background_tasks.add_task(
        process_audio_pipeline,
        file_id,
        None,
        use_whisper_mode
    )

    return {
        "file_id": file_id,
        "message": "ì²˜ë¦¬ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
        "status": "queued",
        "whisper_mode": use_whisper_mode,
        "model_size": "large-v3",
        "device": detected_device,
    }


@router.get("/status/{file_id}")
async def get_processing_status(file_id: str):
    """
    ì²˜ë¦¬ ìƒíƒœ ì¡°íšŒ

    Args:
        file_id: íŒŒì¼ ID

    Returns:
        í˜„ì¬ ì²˜ë¦¬ ìƒíƒœ
    """
    if file_id not in PROCESSING_STATUS:
        raise HTTPException(status_code=404, detail="ì²˜ë¦¬ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    return PROCESSING_STATUS[file_id]


@router.get("/transcript/{file_id}")
async def get_transcript(file_id: str):
    """
    ì „ì‚¬ ê²°ê³¼ ì¡°íšŒ

    Args:
        file_id: íŒŒì¼ ID

    Returns:
        ì „ì‚¬ í…ìŠ¤íŠ¸
    """
    if file_id not in PROCESSING_STATUS:
        raise HTTPException(status_code=404, detail="ì²˜ë¦¬ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    status = PROCESSING_STATUS[file_id]
    if status["status"] != "completed":
        raise HTTPException(status_code=400, detail="ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    transcript_path = Path(status["transcript_path"])
    if not transcript_path.exists():
        raise HTTPException(status_code=404, detail="ì „ì‚¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    lines = []
    for line in transcript_path.read_text(encoding="utf-8").splitlines():
        if line.strip():
            lines.append(line)

    return {"file_id": file_id, "transcript": lines, "total_lines": len(lines)}
