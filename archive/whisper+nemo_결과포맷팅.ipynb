{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__OYYtud9r-t",
        "outputId": "81d1828e-fbe0-48c8-9ec5-03fccdba4def"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping lightning as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping pytorch-lightning as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y numpy torch torchaudio torchvision lightning pytorch-lightning nvidia-cudnn-cu12 -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "KLe8LG5XDwFh",
        "outputId": "a2e9d00a-c146-482f-c9d2-dafb5a97bb14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m127.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.17.1 requires torch>=1.13.0, which is not installed.\n",
            "accelerate 1.11.0 requires torch>=2.0.0, which is not installed.\n",
            "fastai 2.8.5 requires torch<2.10,>=1.10, which is not installed.\n",
            "fastai 2.8.5 requires torchvision>=0.11, which is not installed.\n",
            "sentence-transformers 5.1.2 requires torch>=1.11.0, which is not installed.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "c20d15205047494db38b41d9c6b07585"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchaudio torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vwT94VzIDv8r",
        "outputId": "382824ca-da76-480a-bb4a-31eace35220b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch\n",
            "  Downloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting torchaudio\n",
            "  Downloading torchaudio-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.24.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Collecting nvidia-nccl-cu12==2.27.5 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch)\n",
            "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.5.0 (from torch)\n",
            "  Downloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Downloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.24.0-cp312-cp312-manylinux_2_28_x86_64.whl (8.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m126.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvshmem-cu12\n",
            "    Found existing installation: nvidia-nvshmem-cu12 3.4.5\n",
            "    Uninstalling nvidia-nvshmem-cu12-3.4.5:\n",
            "      Successfully uninstalled nvidia-nvshmem-cu12-3.4.5\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
            "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "Successfully installed nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 torch-2.9.0 torchaudio-2.9.0 torchvision-0.24.0 triton-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightning pytorch-lightning\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXzQIeOfD7Jp",
        "outputId": "70410045-66e9-4601-ac38-e15de9ff25a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightning\n",
            "  Downloading lightning-2.5.6-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.5.6-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: PyYAML<8.0,>5.4 in /usr/local/lib/python3.12/dist-packages (from lightning) (6.0.3)\n",
            "Requirement already satisfied: fsspec<2027.0,>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (2025.3.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: packaging<27.0,>=20.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (25.0)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (2.9.0)\n",
            "Collecting torchmetrics<3.0,>0.7.0 (from lightning)\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>4.5.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (4.15.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (3.13.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.5.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics<3.0,>0.7.0->lightning) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.22.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (3.11)\n",
            "Downloading lightning-2.5.6-py3-none-any.whl (827 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m827.9/827.9 kB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.6-py3-none-any.whl (831 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.6/831.6 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch-lightning, lightning\n",
            "Successfully installed lightning-2.5.6 lightning-utilities-0.15.2 pytorch-lightning-2.5.6 torchmetrics-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faster-whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyDBuo7AEc1V",
        "outputId": "2142d5d0-b400-4a28-e4c1-ce572822e82e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faster-whisper\n",
            "  Downloading faster_whisper-1.2.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting ctranslate2<5,>=4.0 (from faster-whisper)\n",
            "  Downloading ctranslate2-4.6.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.21 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (0.36.0)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (0.22.1)\n",
            "Collecting onnxruntime<2,>=1.14 (from faster-whisper)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting av>=11 (from faster-whisper)\n",
            "  Downloading av-16.0.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (4.67.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (1.26.4)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.12/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (2.32.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (1.2.0)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.13.3)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.21->faster-whisper) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.21->faster-whisper) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.21->faster-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.21->faster-whisper) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
            "Downloading faster_whisper-1.2.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-16.0.1-cp312-cp312-manylinux_2_28_x86_64.whl (40.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ctranslate2-4.6.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (38.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m125.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, ctranslate2, av, coloredlogs, onnxruntime, faster-whisper\n",
            "Successfully installed av-16.0.1 coloredlogs-15.0.1 ctranslate2-4.6.1 faster-whisper-1.2.1 humanfriendly-10.0 onnxruntime-1.23.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchcodec\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6NwbyTDJYx_",
        "outputId": "a0eec43f-6c3f-4335-aa97-5e7b7d16ff0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchcodec\n",
            "  Downloading torchcodec-0.8.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Downloading torchcodec-0.8.1-cp312-cp312-manylinux_2_28_x86_64.whl (2.0 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchcodec\n",
            "Successfully installed torchcodec-0.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nemo-toolkit[asr]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CpG7I6ugEglc",
        "outputId": "5498d90f-8853-4380-efb4-d3baa5c9e671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nemo-toolkit[asr]\n",
            "  Downloading nemo_toolkit-2.5.2-py3-none-any.whl.metadata (95 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/95.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.3/95.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec==2024.12.0 (from nemo-toolkit[asr])\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: huggingface_hub>=0.24 in /usr/local/lib/python3.12/dist-packages (from nemo-toolkit[asr]) (0.36.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from nemo-toolkit[asr]) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from nemo-toolkit[asr]) (1.26.4)\n",
            "Collecting onnx>=1.7.0 (from nemo-toolkit[asr])\n",
            "  Downloading onnx-1.19.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: protobuf~=5.29.5 in /usr/local/lib/python3.12/dist-packages (from nemo-toolkit[asr]) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from nemo-toolkit[asr]) (2.9.0.post0)\n",
            "Collecting ruamel.yaml (from nemo-toolkit[asr])\n",
            "  Downloading ruamel.yaml-0.18.16-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from nemo-toolkit[asr]) (1.6.1)\n",
            "Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.12/dist-packages (from nemo-toolkit[asr]) (75.2.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from nemo-toolkit[asr]) (2.19.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from nemo-toolkit[asr]) (1.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from nemo-toolkit[asr]) (2.9.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from nemo-toolkit[asr]) (4.67.1)\n",
            "Collecting wget (from nemo-toolkit[asr])\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from nemo-toolkit[asr]) (2.0.0)\n",
            "Collecting braceexpand (from nemo-toolkit[asr])\n",
            "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.12/dist-packages (from nemo-toolkit[asr]) (0.8.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from nemo-toolkit[asr]) (0.8.1)\n",
            "Collecting jiwer<4.0.0,>=3.1.0 (from nemo-toolkit[asr])\n",
            "  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting kaldi-python-io (from nemo-toolkit[asr])\n",
            "  Downloading kaldi-python-io-1.2.2.tar.gz (8.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lhotse!=1.31.0 (from nemo-toolkit[asr])\n",
            "  Downloading lhotse-1.31.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: librosa>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from nemo-toolkit[asr]) (0.11.0)\n",
            "Collecting marshmallow (from nemo-toolkit[asr])\n",
            "  Downloading marshmallow-4.1.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting optuna (from nemo-toolkit[asr])\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from nemo-toolkit[asr]) (25.0)\n",
            "Collecting pyannote.core (from nemo-toolkit[asr])\n",
            "  Downloading pyannote_core-6.0.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting pyannote.metrics (from nemo-toolkit[asr])\n",
            "  Downloading pyannote_metrics-4.0.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from nemo-toolkit[asr]) (0.25.1)\n",
            "Collecting pyloudnorm (from nemo-toolkit[asr])\n",
            "  Downloading pyloudnorm-0.1.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting resampy (from nemo-toolkit[asr])\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.12/dist-packages (from nemo-toolkit[asr]) (1.16.3)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (from nemo-toolkit[asr]) (0.13.1)\n",
            "Collecting sox<=1.5.0 (from nemo-toolkit[asr])\n",
            "  Downloading sox-1.5.0.tar.gz (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting texterrors<1.0.0 (from nemo-toolkit[asr])\n",
            "  Downloading texterrors-0.5.1.tar.gz (23 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting whisper_normalizer (from nemo-toolkit[asr])\n",
            "  Downloading whisper_normalizer-0.1.12-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting num2words (from nemo-toolkit[asr])\n",
            "  Downloading num2words-0.5.14-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from nemo-toolkit[asr]) (4.0.0)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.12/dist-packages (from nemo-toolkit[asr]) (7.5.0)\n",
            "Collecting mediapy==1.1.6 (from nemo-toolkit[asr])\n",
            "  Downloading mediapy-1.1.6-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from nemo-toolkit[asr]) (2.2.2)\n",
            "Collecting sacremoses>=0.0.43 (from nemo-toolkit[asr])\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: sentencepiece<1.0.0 in /usr/local/lib/python3.12/dist-packages (from nemo-toolkit[asr]) (0.2.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from nemo-toolkit[asr]) (3.1.2)\n",
            "Collecting fiddle (from nemo-toolkit[asr])\n",
            "  Downloading fiddle-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting hydra-core<=1.3.2,>1.3 (from nemo-toolkit[asr])\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting lightning<=2.4.0,>2.2.1 (from nemo-toolkit[asr])\n",
            "  Downloading lightning-2.4.0-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: omegaconf<=2.3 in /usr/local/lib/python3.12/dist-packages (from nemo-toolkit[asr]) (2.3.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (from nemo-toolkit[asr]) (0.17.1)\n",
            "Requirement already satisfied: torchmetrics>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from nemo-toolkit[asr]) (1.8.2)\n",
            "Collecting transformers~=4.53.0 (from nemo-toolkit[asr])\n",
            "  Downloading transformers-4.53.3-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (from nemo-toolkit[asr]) (0.22.3)\n",
            "Collecting webdataset>=0.2.86 (from nemo-toolkit[asr])\n",
            "  Downloading webdataset-1.0.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting nv_one_logger_core>=2.3.0 (from nemo-toolkit[asr])\n",
            "  Downloading nv_one_logger_core-2.3.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting nv_one_logger_training_telemetry>=2.3.0 (from nemo-toolkit[asr])\n",
            "  Downloading nv_one_logger_training_telemetry-2.3.1-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting nv_one_logger_pytorch_lightning_integration>=2.3.0 (from nemo-toolkit[asr])\n",
            "  Downloading nv_one_logger_pytorch_lightning_integration-2.3.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting bitsandbytes==0.46.0 (from nemo-toolkit[asr])\n",
            "  Downloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.12/dist-packages (from mediapy==1.1.6->nemo-toolkit[asr]) (7.34.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapy==1.1.6->nemo-toolkit[asr]) (3.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from mediapy==1.1.6->nemo-toolkit[asr]) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.24->nemo-toolkit[asr]) (3.20.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.24->nemo-toolkit[asr]) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.24->nemo-toolkit[asr]) (2.32.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.24->nemo-toolkit[asr]) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.24->nemo-toolkit[asr]) (1.2.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core<=1.3.2,>1.3->nemo-toolkit[asr]) (4.9.3)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from jiwer<4.0.0,>=3.1.0->nemo-toolkit[asr]) (8.3.0)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer<4.0.0,>=3.1.0->nemo-toolkit[asr])\n",
            "  Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from lhotse!=1.31.0->nemo-toolkit[asr]) (3.1.0)\n",
            "Collecting cytoolz>=0.10.1 (from lhotse!=1.31.0->nemo-toolkit[asr])\n",
            "  Downloading cytoolz-1.1.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting intervaltree>=3.1.0 (from lhotse!=1.31.0->nemo-toolkit[asr])\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate>=0.8.1 in /usr/local/lib/python3.12/dist-packages (from lhotse!=1.31.0->nemo-toolkit[asr]) (0.9.0)\n",
            "Collecting lilcom>=1.1.0 (from lhotse!=1.31.0->nemo-toolkit[asr])\n",
            "  Downloading lilcom-1.8.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->nemo-toolkit[asr]) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->nemo-toolkit[asr]) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->nemo-toolkit[asr]) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->nemo-toolkit[asr]) (1.0.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->nemo-toolkit[asr]) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->nemo-toolkit[asr]) (1.1.2)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from lightning<=2.4.0,>2.2.1->nemo-toolkit[asr]) (0.15.2)\n",
            "Collecting packaging (from nemo-toolkit[asr])\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.12/dist-packages (from lightning<=2.4.0,>2.2.1->nemo-toolkit[asr]) (2.5.6)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->nemo-toolkit[asr]) (0.43.0)\n",
            "Collecting StrEnum<0.5.0,>=0.4.0 (from nv_one_logger_core>=2.3.0->nemo-toolkit[asr])\n",
            "  Downloading StrEnum-0.4.15-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: overrides<8.0.0,>=7.7.0 in /usr/local/lib/python3.12/dist-packages (from nv_one_logger_core>=2.3.0->nemo-toolkit[asr]) (7.7.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.10.6 in /usr/local/lib/python3.12/dist-packages (from nv_one_logger_core>=2.3.0->nemo-toolkit[asr]) (2.11.10)\n",
            "Requirement already satisfied: toml<0.11.0,>=0.10.2 in /usr/local/lib/python3.12/dist-packages (from nv_one_logger_core>=2.3.0->nemo-toolkit[asr]) (0.10.2)\n",
            "Collecting setuptools>=70.0.0 (from nemo-toolkit[asr])\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx>=1.7.0->nemo-toolkit[asr]) (0.5.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacremoses>=0.0.43->nemo-toolkit[asr]) (2024.11.6)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->nemo-toolkit[asr]) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile->nemo-toolkit[asr]) (2.0.0)\n",
            "Collecting pybind11 (from texterrors<1.0.0->nemo-toolkit[asr])\n",
            "  Using cached pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)\n",
            "Collecting plac (from texterrors<1.0.0->nemo-toolkit[asr])\n",
            "  Downloading plac-1.4.5-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting loguru (from texterrors<1.0.0->nemo-toolkit[asr])\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from texterrors<1.0.0->nemo-toolkit[asr]) (3.2.0)\n",
            "Collecting Levenshtein (from texterrors<1.0.0->nemo-toolkit[asr])\n",
            "  Downloading levenshtein-0.27.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->nemo-toolkit[asr]) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->nemo-toolkit[asr]) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->nemo-toolkit[asr]) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->nemo-toolkit[asr]) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->nemo-toolkit[asr]) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->nemo-toolkit[asr]) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->nemo-toolkit[asr]) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->nemo-toolkit[asr]) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch->nemo-toolkit[asr]) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch->nemo-toolkit[asr]) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch->nemo-toolkit[asr]) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->nemo-toolkit[asr]) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->nemo-toolkit[asr]) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->nemo-toolkit[asr]) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->nemo-toolkit[asr]) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->nemo-toolkit[asr]) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->nemo-toolkit[asr]) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch->nemo-toolkit[asr]) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->nemo-toolkit[asr]) (3.5.0)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers~=4.53.0->nemo-toolkit[asr])\n",
            "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers~=4.53.0->nemo-toolkit[asr]) (0.6.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->nemo-toolkit[asr]) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->nemo-toolkit[asr]) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->nemo-toolkit[asr]) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->nemo-toolkit[asr]) (0.70.16)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from fiddle->nemo-toolkit[asr]) (1.4.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from fiddle->nemo-toolkit[asr]) (0.21)\n",
            "Collecting libcst (from fiddle->nemo-toolkit[asr])\n",
            "  Downloading libcst-1.8.6-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.12/dist-packages (from inflect->nemo-toolkit[asr]) (10.8.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from inflect->nemo-toolkit[asr]) (4.4.4)\n",
            "Collecting docopt>=0.6.2 (from num2words->nemo-toolkit[asr])\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna->nemo-toolkit[asr]) (1.17.1)\n",
            "Collecting colorlog (from optuna->nemo-toolkit[asr])\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna->nemo-toolkit[asr]) (2.0.44)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->nemo-toolkit[asr]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->nemo-toolkit[asr]) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->nemo-toolkit[asr]) (1.17.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft->nemo-toolkit[asr]) (5.9.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft->nemo-toolkit[asr]) (1.11.0)\n",
            "INFO: pip is looking at multiple versions of pyannote-core to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting pyannote.core (from nemo-toolkit[asr])\n",
            "  Downloading pyannote_core-6.0.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading pyannote.core-5.0.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from pyannote.core->nemo-toolkit[asr]) (2.4.0)\n",
            "INFO: pip is looking at multiple versions of pyannote-metrics to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting pyannote.metrics (from nemo-toolkit[asr])\n",
            "  Downloading pyannote.metrics-3.2.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting pyannote.database>=4.0.1 (from pyannote.metrics->nemo-toolkit[asr])\n",
            "  Downloading pyannote_database-6.1.0-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from pyloudnorm->nemo-toolkit[asr]) (1.0.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml->nemo-toolkit[asr])\n",
            "  Downloading ruamel.yaml.clib-0.2.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->nemo-toolkit[asr]) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->nemo-toolkit[asr]) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->nemo-toolkit[asr]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->nemo-toolkit[asr]) (3.1.3)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->nemo-toolkit[asr]) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb->nemo-toolkit[asr]) (4.5.0)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->nemo-toolkit[asr]) (2.43.0)\n",
            "Collecting indic-numtowords (from whisper_normalizer->nemo-toolkit[asr])\n",
            "  Downloading indic_numtowords-1.1.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna->nemo-toolkit[asr]) (1.3.10)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile->nemo-toolkit[asr]) (2.23)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from cytoolz>=0.10.1->lhotse!=1.31.0->nemo-toolkit[asr]) (0.12.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo-toolkit[asr]) (3.13.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->nemo-toolkit[asr]) (4.0.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapy==1.1.6->nemo-toolkit[asr]) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapy==1.1.6->nemo-toolkit[asr]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapy==1.1.6->nemo-toolkit[asr]) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapy==1.1.6->nemo-toolkit[asr]) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapy==1.1.6->nemo-toolkit[asr]) (3.2.5)\n",
            "Collecting pandas (from nemo-toolkit[asr])\n",
            "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading pandas-2.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is still looking at multiple versions of pyannote-core to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading pandas-2.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyannote.database>=4.0.1 (from pyannote.metrics->nemo-toolkit[asr])\n",
            "  Downloading pyannote_database-6.0.0-py3-none-any.whl.metadata (30 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading pyannote.database-5.1.3-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from pyannote.database>=4.0.1->pyannote.metrics->nemo-toolkit[asr]) (0.20.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.10.6->nv_one_logger_core>=2.3.0->nemo-toolkit[asr]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.10.6->nv_one_logger_core>=2.3.0->nemo-toolkit[asr]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.10.6->nv_one_logger_core>=2.3.0->nemo-toolkit[asr]) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.24->nemo-toolkit[asr]) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.24->nemo-toolkit[asr]) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.24->nemo-toolkit[asr]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.24->nemo-toolkit[asr]) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna->nemo-toolkit[asr]) (3.2.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->nemo-toolkit[asr]) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard->nemo-toolkit[asr]) (3.0.3)\n",
            "Collecting jedi>=0.16 (from ipython->mediapy==1.1.6->nemo-toolkit[asr])\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo-toolkit[asr]) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo-toolkit[asr]) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo-toolkit[asr]) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo-toolkit[asr]) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo-toolkit[asr]) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo-toolkit[asr]) (0.2.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo-toolkit[asr]) (4.9.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo-toolkit[asr]) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo-toolkit[asr]) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo-toolkit[asr]) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo-toolkit[asr]) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo-toolkit[asr]) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo-toolkit[asr]) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo-toolkit[asr]) (1.22.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->nemo-toolkit[asr]) (5.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython->mediapy==1.1.6->nemo-toolkit[asr]) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython->mediapy==1.1.6->nemo-toolkit[asr]) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->mediapy==1.1.6->nemo-toolkit[asr]) (0.2.14)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo-toolkit[asr]) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo-toolkit[asr]) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo-toolkit[asr]) (4.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo-toolkit[asr]) (0.1.2)\n",
            "Downloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl (67.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mediapy-1.1.6-py3-none-any.whl (24 kB)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiwer-3.1.0-py3-none-any.whl (22 kB)\n",
            "Downloading lhotse-1.31.1-py3-none-any.whl (866 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.5/866.5 kB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.4.0-py3-none-any.whl (810 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nv_one_logger_core-2.3.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nv_one_logger_pytorch_lightning_integration-2.3.1-py3-none-any.whl (9.8 kB)\n",
            "Downloading nv_one_logger_training_telemetry-2.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.19.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m129.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.53.3-py3-none-any.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m144.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading webdataset-1.0.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
            "Downloading fiddle-0.3.0-py3-none-any.whl (419 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m419.8/419.8 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-4.1.0-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nemo_toolkit-2.5.2-py3-none-any.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading num2words-0.5.14-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyloudnorm-0.1.1-py3-none-any.whl (9.6 kB)\n",
            "Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m119.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml-0.18.16-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading whisper_normalizer-0.1.12-py3-none-any.whl (36 kB)\n",
            "Downloading cytoolz-1.1.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m114.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lilcom-1.8.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/93.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.database-5.1.3-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (753 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m753.1/753.1 kB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading StrEnum-0.4.15-py3-none-any.whl (8.9 kB)\n",
            "Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m112.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Downloading indic_numtowords-1.1.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading levenshtein-0.27.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libcst-1.8.6-cp312-cp312-manylinux_2_28_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading plac-1.4.5-py2.py3-none-any.whl (22 kB)\n",
            "Using cached pybind11-3.0.1-py3-none-any.whl (293 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sox, texterrors, kaldi-python-io, wget, docopt, intervaltree\n",
            "  Building wheel for sox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sox: filename=sox-1.5.0-py3-none-any.whl size=40036 sha256=3131c679690d452fd3296382a752500ef049178532dd053b4cba4f9d7b3b81d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/c7/e7/baea1f7e79b9eb53addc81cc9b827424f4a7d8c9cc18c03659\n",
            "  Building wheel for texterrors (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for texterrors: filename=texterrors-0.5.1-cp312-cp312-linux_x86_64.whl size=1197637 sha256=2aeacf4c70e63d3ee0dfcc77c3d5925f35787ec41a355c354a6fbc1df236eea0\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/8f/81/7df3770dce1fcd6dc49118d4b1766f99334dd2ff43848f3893\n",
            "  Building wheel for kaldi-python-io (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaldi-python-io: filename=kaldi_python_io-1.2.2-py3-none-any.whl size=8953 sha256=2890aaed6a5052b35ab98e2f13546fc476808ddf85d4508489cca170e774e2a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/a9/7b/af1bff74047bf7dfde7040b8fbe968ebb2f68eeed71249a14c\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=7fb6c691d75fbe6bc0c86a4ef749f15f4bff779034127d48a0c4f646799b06e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/46/3b/e29ffbe4ebe614ff224bad40fc6a5773a67a163251585a13a9\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=f0ac959e3bc67282dbaaa5957420057b0fd60b2652d8a952e198f856bf10805d\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/bf/a1/4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26098 sha256=b5dbc7a0af18454e721e124efc727d1293a1caba19138a697c2d592c8cae3caa\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/c3/c3/238bf93c243597857edd94ddb0577faa74a8e16e9585896e83\n",
            "Successfully built sox texterrors kaldi-python-io wget docopt intervaltree\n",
            "Installing collected packages: wget, StrEnum, plac, docopt, braceexpand, webdataset, sox, setuptools, sacremoses, ruamel.yaml.clib, rapidfuzz, pybind11, packaging, num2words, marshmallow, loguru, lilcom, libcst, kaldi-python-io, jedi, intervaltree, indic-numtowords, fsspec, cytoolz, colorlog, whisper_normalizer, ruamel.yaml, resampy, pyloudnorm, pyannote.core, onnx, Levenshtein, jiwer, hydra-core, fiddle, tokenizers, texterrors, optuna, nv_one_logger_core, mediapy, transformers, pyannote.database, nv_one_logger_training_telemetry, nemo-toolkit, lhotse, bitsandbytes, pyannote.metrics, lightning, nv_one_logger_pytorch_lightning_integration\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.1\n",
            "    Uninstalling transformers-4.57.1:\n",
            "      Successfully uninstalled transformers-4.57.1\n",
            "  Attempting uninstall: lightning\n",
            "    Found existing installation: lightning 2.5.6\n",
            "    Uninstalling lightning-2.5.6:\n",
            "      Successfully uninstalled lightning-2.5.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Levenshtein-0.27.3 StrEnum-0.4.15 bitsandbytes-0.46.0 braceexpand-0.1.7 colorlog-6.10.1 cytoolz-1.1.0 docopt-0.6.2 fiddle-0.3.0 fsspec-2024.12.0 hydra-core-1.3.2 indic-numtowords-1.1.0 intervaltree-3.1.0 jedi-0.19.2 jiwer-3.1.0 kaldi-python-io-1.2.2 lhotse-1.31.1 libcst-1.8.6 lightning-2.4.0 lilcom-1.8.1 loguru-0.7.3 marshmallow-4.1.0 mediapy-1.1.6 nemo-toolkit-2.5.2 num2words-0.5.14 nv_one_logger_core-2.3.1 nv_one_logger_pytorch_lightning_integration-2.3.1 nv_one_logger_training_telemetry-2.3.1 onnx-1.19.1 optuna-4.5.0 packaging-24.2 plac-1.4.5 pyannote.core-5.0.0 pyannote.database-5.1.3 pyannote.metrics-3.2.1 pybind11-3.0.1 pyloudnorm-0.1.1 rapidfuzz-3.14.3 resampy-0.4.3 ruamel.yaml-0.18.16 ruamel.yaml.clib-0.2.14 sacremoses-0.1.1 setuptools-80.9.0 sox-1.5.0 texterrors-0.5.1 tokenizers-0.21.4 transformers-4.53.3 webdataset-1.0.2 wget-3.2 whisper_normalizer-0.1.12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "packaging"
                ]
              },
              "id": "e5f66a25a5b949e8abf64d90885f818b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import torchaudio\n",
        "from pathlib import Path\n",
        "from faster_whisper import WhisperModel\n",
        "from nemo.collections.asr.models.msdd_models import NeuralDiarizer\n",
        "from omegaconf import OmegaConf"
      ],
      "metadata": {
        "id": "1FZJf_uR_QcI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "652d2f4b-6151-465a-fb1c-4d8ed20d774a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2025-11-10 02:48:16 nemo_logging:405] Megatron num_microbatches_calculator not found, using Apex version.\n",
            "WARNING:nv_one_logger.api.config:OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.\n",
            "WARNING:nv_one_logger.training_telemetry.api.training_telemetry_provider:No exporters were provided. This means that no telemetry data will be collected.\n",
            "[NeMo W 2025-11-10 02:48:19 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:300: SyntaxWarning: invalid escape sequence '\\('\n",
            "      m = re.match('([su]([0-9]{1,2})p?) \\(([0-9]{1,2}) bit\\)$', token)\n",
            "    \n",
            "[NeMo W 2025-11-10 02:48:19 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:301: SyntaxWarning: invalid escape sequence '\\('\n",
            "      m2 = re.match('([su]([0-9]{1,2})p?)( \\(default\\))?$', token)\n",
            "    \n",
            "[NeMo W 2025-11-10 02:48:19 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:310: SyntaxWarning: invalid escape sequence '\\('\n",
            "      elif re.match('(flt)p?( \\(default\\))?$', token):\n",
            "    \n",
            "[NeMo W 2025-11-10 02:48:19 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:314: SyntaxWarning: invalid escape sequence '\\('\n",
            "      elif re.match('(dbl)p?( \\(default\\))?$', token):\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# 파일 업로드\n",
        "uploaded = files.upload()\n",
        "audio_path = list(uploaded.keys())[0]\n",
        "print(f\"업로드된 파일: {audio_path}\")"
      ],
      "metadata": {
        "id": "t_oJfRVQ_uVS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "7819f496-36bc-4a63-c7b1-5445bbca2d3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-21d995da-5ed6-408a-bfa0-b41afc202cde\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-21d995da-5ed6-408a-bfa0-b41afc202cde\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 1106_오후회의.m4a to 1106_오후회의.m4a\n",
            "업로드된 파일: 1106_오후회의.m4a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 오디오 변환 (M4A → WAV 16kHz mono)"
      ],
      "metadata": {
        "id": "4JbvK4jRM1Jl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "import torch\n",
        "import torchaudio\n",
        "\n",
        "# 출력 디렉토리 생성\n",
        "output_dir = \"output\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# WAV로 변환 (원본)\n",
        "wav_path = os.path.join(output_dir, \"audio.wav\")\n",
        "# 전처리된 파일 경로\n",
        "preprocessed_path = os.path.join(output_dir, \"audio_preprocessed.wav\")\n",
        "\n",
        "print(\"🔄 오디오 변환 및 전처리 중...\")\n",
        "\n",
        "# ffmpeg로 직접 변환 (torchaudio 버전 문제 우회)\n",
        "subprocess.run([\n",
        "    'ffmpeg', '-i', audio_path,\n",
        "    '-ar', '16000',  # 16kHz\n",
        "    '-ac', '1',      # mono\n",
        "    '-y',            # overwrite\n",
        "    wav_path\n",
        "], capture_output=True, check=True)\n",
        "\n",
        "# 변환된 파일 로드\n",
        "waveform, sample_rate = torchaudio.load(wav_path)\n",
        "\n",
        "print(f\"   원본 길이: {waveform.shape[1] / sample_rate:.1f}초\")\n",
        "print(f\"   원본 볼륨: {waveform.abs().max():.3f}\")\n",
        "\n",
        "# ===== 전처리 시작 =====\n",
        "\n",
        "# 1. High-pass 필터 (저주파 노이즈 제거)\n",
        "print(\"   🔧 저주파 노이즈 제거 중...\")\n",
        "waveform = torchaudio.functional.highpass_biquad(\n",
        "    waveform,\n",
        "    sample_rate,\n",
        "    cutoff_freq=80  # 80Hz 이하 제거 (에어컨, 기계음 등)\n",
        ")\n",
        "\n",
        "# 2. 무음 구간 최소화 (앞뒤 무음 제거)\n",
        "print(\"   🔧 무음 구간 정리 중...\")\n",
        "threshold = 0.01\n",
        "non_silent = torch.where(waveform.abs() > threshold)[1]\n",
        "\n",
        "if len(non_silent) > 0:\n",
        "    # 앞뒤 0.5초 여유 두고 자르기\n",
        "    start_sample = max(0, non_silent[0] - int(0.5 * sample_rate))\n",
        "    end_sample = min(waveform.shape[1], non_silent[-1] + int(0.5 * sample_rate))\n",
        "    waveform = waveform[:, start_sample:end_sample]\n",
        "\n",
        "# 3. 적응형 볼륨 증폭 (컴프레서 효과)\n",
        "print(\"   🔧 볼륨 증폭 중...\")\n",
        "max_amp = waveform.abs().max()\n",
        "\n",
        "if max_amp < 0.3:  # 너무 작은 경우\n",
        "    # 목표 볼륨: 0.7 (70%)\n",
        "    target_volume = 0.7\n",
        "    gain = target_volume / max_amp\n",
        "    waveform = waveform * gain\n",
        "    print(f\"   📈 볼륨 증폭: {gain:.2f}배 ({max_amp:.3f} → {waveform.abs().max():.3f})\")\n",
        "elif max_amp < 0.5:  # 약간 작은 경우\n",
        "    # 목표 볼륨: 0.75\n",
        "    target_volume = 0.75\n",
        "    gain = target_volume / max_amp\n",
        "    waveform = waveform * gain\n",
        "    print(f\"   📈 볼륨 증폭: {gain:.2f}배 ({max_amp:.3f} → {waveform.abs().max():.3f})\")\n",
        "else:\n",
        "    # 충분히 큰 경우: 0.85로 정규화\n",
        "    waveform = waveform / max_amp * 0.85\n",
        "    print(f\"   ✓ 볼륨 정규화: {waveform.abs().max():.3f}\")\n",
        "\n",
        "# 4. 소프트 클리핑 방지 (혹시 모를 과도한 증폭 보정)\n",
        "waveform = torch.tanh(waveform * 1.2) * 0.9  # 부드러운 제한\n",
        "\n",
        "# 전처리된 오디오 저장 (별도 파일로 저장)\n",
        "print(\"   💾 전처리된 오디오 저장 중...\")\n",
        "torchaudio.save(preprocessed_path, waveform, sample_rate)\n",
        "\n",
        "duration = waveform.shape[1] / sample_rate\n",
        "final_volume = waveform.abs().max()\n",
        "print(f\"✅ 전처리 완료: {preprocessed_path}\")\n",
        "print(f\"   샘플레이트: {sample_rate}Hz\")\n",
        "print(f\"   최종 길이: {duration:.1f}초\")\n",
        "print(f\"   최종 볼륨: {final_volume:.3f}\")\n",
        "print(f\"   품질: 노이즈 제거 + 볼륨 최적화 완료\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1WvanWoI4kn",
        "outputId": "f43f2a33-a03c-4f68-c4d5-7fc413c16c5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 오디오 변환 및 전처리 중...\n",
            "   원본 길이: 2086.0초\n",
            "   원본 볼륨: 0.945\n",
            "   🔧 저주파 노이즈 제거 중...\n",
            "   🔧 무음 구간 정리 중...\n",
            "   🔧 볼륨 증폭 중...\n",
            "   ✓ 볼륨 정규화: 0.850\n",
            "   💾 전처리된 오디오 저장 중...\n",
            "✅ 전처리 완료: output/audio_preprocessed.wav\n",
            "   샘플레이트: 16000Hz\n",
            "   최종 길이: 2086.0초\n",
            "   최종 볼륨: 0.693\n",
            "   품질: 노이즈 제거 + 볼륨 최적화 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Whisper로 음성 전사"
      ],
      "metadata": {
        "id": "0yupbcEyM4RN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Whisper 모델 로드\n",
        "model_size = \"large-v3\"\n",
        "print(f\"Whisper {model_size} 모델 로딩...\")\n",
        "whisper_model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
        "\n",
        "# ✅ 전처리된 오디오 사용\n",
        "print(\"음성 전사 중 (전처리 적용)...\")\n",
        "segments, info = whisper_model.transcribe(\n",
        "    preprocessed_path,  # ← 이 부분 변경!\n",
        "    language=\"ko\",\n",
        "    beam_size=5,\n",
        "    word_timestamps=True,\n",
        "    vad_filter=True,  # VAD 필터 추가 권장\n",
        "    vad_parameters={\n",
        "        \"threshold\": 0.5,\n",
        "        \"min_speech_duration_ms\": 250\n",
        "    }\n",
        ")\n",
        "\n",
        "# 나머지 코드 동일\n",
        "transcription = []\n",
        "for segment in segments:\n",
        "    transcription.append({\n",
        "        'start': segment.start,\n",
        "        'end': segment.end,\n",
        "        'text': segment.text,\n",
        "        'words': [\n",
        "            {'word': w.word, 'start': w.start, 'end': w.end}\n",
        "            for w in segment.words\n",
        "        ] if segment.words else []\n",
        "    })\n",
        "\n",
        "print(f\"✅ 전사 완료: {len(transcription)} 세그먼트\")\n",
        "print(f\"   언어: {info.language}\")\n",
        "\n",
        "# 미리보기\n",
        "print(\"\\n[전사 미리보기]\")\n",
        "for i, seg in enumerate(transcription[:3]):\n",
        "    print(f\"{i+1}. [{seg['start']:.2f}s - {seg['end']:.2f}s] {seg['text']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqMhvh6KJAAZ",
        "outputId": "dd222628-d421-4631-87ab-1f409cba526c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whisper large-v3 모델 로딩...\n",
            "음성 전사 중 (전처리 적용)...\n",
            "✅ 전사 완료: 758 세그먼트\n",
            "   언어: ko\n",
            "\n",
            "[전사 미리보기]\n",
            "1. [4.27s - 6.47s]  그러면 너무 회의만 하지 말고\n",
            "2. [7.23s - 9.11s]  좀 토킹 어바웃을 해볼까요?\n",
            "3. [9.25s - 10.05s]  좀 여유롭게\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NeMo로 화자 분리"
      ],
      "metadata": {
        "id": "ppSC8zz4M89b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['LD_LIBRARY_PATH'] = ''\n",
        "import torch\n",
        "torch.backends.cudnn.enabled = False  # cuDNN 비활성화\n"
      ],
      "metadata": {
        "id": "lnkiHGpYK13f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== NeMo 화자 분리 설정 (포괄적 인식 모드) =====\n",
        "import json\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "print(\"\\n👥 화자 분리 준비 중 (포괄적 인식 모드)...\")\n",
        "\n",
        "manifest_path = os.path.join(output_dir, \"manifest.json\")\n",
        "with open(manifest_path, 'w') as f:\n",
        "    json.dump({\n",
        "        \"audio_filepath\": preprocessed_path,\n",
        "        \"offset\": 0,\n",
        "        \"duration\": None,\n",
        "        \"label\": \"infer\",\n",
        "        \"text\": \"-\",\n",
        "        \"num_speakers\": None,\n",
        "        \"rttm_filepath\": None,\n",
        "        \"uem_filepath\": None\n",
        "    }, f)\n",
        "    f.write('\\n')\n",
        "\n",
        "config = OmegaConf.create({\n",
        "    'device': 'cuda',\n",
        "    'num_workers': 0,\n",
        "    'sample_rate': 16000,\n",
        "    'batch_size': 32,\n",
        "    'verbose': True,\n",
        "\n",
        "    'diarizer': {\n",
        "        'manifest_filepath': manifest_path,\n",
        "        'out_dir': output_dir,\n",
        "        'oracle_vad': False,\n",
        "        'collar': 0.25,\n",
        "        'ignore_overlap': False,  # ★ 동시 발화 처리 활성화\n",
        "\n",
        "        'speaker_embeddings': {\n",
        "            'model_path': 'titanet_large',\n",
        "            'parameters': {\n",
        "                # Multi-scale: 긴→짧은 윈도우\n",
        "                'window_length_in_sec': [2.0, 1.5, 1.0, 0.5],  # ★ 가장 긴 스케일 추가\n",
        "                'shift_length_in_sec': [1.0, 0.75, 0.5, 0.25],\n",
        "                'multiscale_weights': [0.8, 1.0, 1.0, 0.6],  # ★ 중간 스케일 중시\n",
        "                'multiscale_args_dict': {\n",
        "                    'scale_dict': {\n",
        "                        0: [2.0, 1.0],\n",
        "                        1: [1.5, 0.75],\n",
        "                        2: [1.0, 0.5],\n",
        "                        3: [0.5, 0.25]\n",
        "                    }\n",
        "                },\n",
        "                'save_embeddings': False\n",
        "            }\n",
        "        },\n",
        "\n",
        "        'clustering': {\n",
        "            'parameters': {\n",
        "                'oracle_num_speakers': False,\n",
        "                'max_num_speakers': 10,  # ★ 8→10 (더 많은 화자 허용)\n",
        "                'max_rp_threshold': 0.18,  # ★ 0.12→0.18 (완화: 다른 사람을 잘 구분)\n",
        "                'enhanced_count_thres': 60,  # ★ 80→60 (화자 수 추정 민감)\n",
        "                'sparse_search_volume': 40  # ★ 30→40 (탐색 범위 확대)\n",
        "            }\n",
        "        },\n",
        "\n",
        "        'vad': {\n",
        "            'model_path': 'vad_multilingual_marblenet',\n",
        "            'parameters': {\n",
        "                'window_length_in_sec': 0.15,\n",
        "                'shift_length_in_sec': 0.01,\n",
        "                'smoothing': 'median',\n",
        "                'overlap': 0.85,  # ★ 0.875→0.85 (약간 완화)\n",
        "                # ★ VAD 민감도 대폭 완화 (짧은 발화 캡처)\n",
        "                'onset': 0.4,  # ★ 0.6→0.4 (음성 시작 더 민감)\n",
        "                'offset': 0.25,  # ★ 0.4→0.25 (음성 종료 더 민감)\n",
        "                'pad_onset': 0.1,  # ★ 0.05→0.1 (앞 여유 증가)\n",
        "                'pad_offset': 0.1,  # ★ 0.05→0.1 (뒤 여유 증가)\n",
        "                'min_duration_on': 0.08,  # ★ 0.1→0.08 (최소 음성 길이 축소)\n",
        "                'min_duration_off': 0.15,  # ★ 0.1→0.15 (최소 침묵 증가)\n",
        "                'filter_speech_first': True\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "})\n",
        "\n",
        "print(\"✅ 포괄적 인식 설정 완료\")\n",
        "print(f\"   - 화자 수: 자동 감지 (최대 10명)\")\n",
        "print(f\"   - 클러스터링 threshold: 0.18 (완화)\")\n",
        "print(f\"   - Multi-scale: 4단계 (2.0s → 0.5s)\")\n",
        "print(f\"   - VAD 민감도: 높음 (짧은 발화 캡처)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR7Mck7-9iEv",
        "outputId": "bf749657-449f-40ce-90e7-2f7392fcee84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "👥 화자 분리 준비 중 (포괄적 인식 모드)...\n",
            "✅ 포괄적 인식 설정 완료\n",
            "   - 화자 수: 자동 감지 (최대 10명)\n",
            "   - 클러스터링 threshold: 0.18 (완화)\n",
            "   - Multi-scale: 4단계 (2.0s → 0.5s)\n",
            "   - VAD 민감도: 높음 (짧은 발화 캡처)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 화자 분리 실행 =====\n",
        "print(\"\\n🔄 화자 분리 실행 중...\")\n",
        "\n",
        "from nemo.collections.asr.models import ClusteringDiarizer\n",
        "\n",
        "diarizer = ClusteringDiarizer(cfg=config)\n",
        "diarizer.diarize()\n",
        "\n",
        "print(\"✅ 화자 분리 완료\")\n",
        "\n",
        "# RTTM 파일 읽기\n",
        "rttm_path = os.path.join(output_dir, \"pred_rttms\", \"audio_preprocessed.rttm\")\n",
        "\n",
        "speaker_timestamps = []\n",
        "detected_speakers = set()\n",
        "\n",
        "with open(rttm_path, 'r') as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split()\n",
        "        if len(parts) >= 8:\n",
        "            start_time = float(parts[3])\n",
        "            duration = float(parts[4])\n",
        "            speaker_id = parts[7]\n",
        "\n",
        "            speaker_timestamps.append({\n",
        "                'start': start_time,\n",
        "                'end': start_time + duration,\n",
        "                'speaker': speaker_id\n",
        "            })\n",
        "            detected_speakers.add(speaker_id)\n",
        "\n",
        "print(f\"   감지된 화자 수: {len(detected_speakers)}명\")\n",
        "print(f\"   화자: {sorted(detected_speakers)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF7OQ4iS9mmP",
        "outputId": "aa65c8f0-85de-40ba-8c9e-4f73bd601202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 화자 분리 실행 중...\n",
            "[NeMo I 2025-11-10 03:12:30 nemo_logging:393] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2025-11-10 03:12:30 nemo_logging:393] Found existing object /root/.cache/torch/NeMo/NeMo_2.5.2/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2025-11-10 03:12:30 nemo_logging:393] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.5.2/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2025-11-10 03:12:30 nemo_logging:393] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2025-11-10 03:12:30 nemo_logging:405] Please use the EncDecSpeakerLabelModel instead of this model. EncDecClassificationModel model is kept for backward compatibility with older models.\n",
            "[NeMo W 2025-11-10 03:12:30 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2025-11-10 03:12:30 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2025-11-10 03:12:31 nemo_logging:405] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-11-10 03:12:31 nemo_logging:393] PADDING: 16\n",
            "[NeMo I 2025-11-10 03:12:31 nemo_logging:393] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.5.2/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2025-11-10 03:12:31 nemo_logging:393] Loading pretrained titanet_large model from NGC\n",
            "[NeMo I 2025-11-10 03:12:31 nemo_logging:393] Found existing object /root/.cache/torch/NeMo/NeMo_2.5.2/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n",
            "[NeMo I 2025-11-10 03:12:31 nemo_logging:393] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.5.2/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n",
            "[NeMo I 2025-11-10 03:12:31 nemo_logging:393] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2025-11-10 03:12:31 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n",
            "    sample_rate: 16000\n",
            "    labels: null\n",
            "    batch_size: 64\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      noise:\n",
            "        manifest_path: /manifests/noise/rir_noise_manifest.json\n",
            "        prob: 0.5\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 15\n",
            "      speed:\n",
            "        prob: 0.5\n",
            "        sr: 16000\n",
            "        resample_type: kaiser_fast\n",
            "        min_speed_rate: 0.95\n",
            "        max_speed_rate: 1.05\n",
            "    num_workers: 15\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2025-11-10 03:12:31 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n",
            "    sample_rate: 16000\n",
            "    labels: null\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    num_workers: 15\n",
            "    pin_memory: true\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-11-10 03:12:31 nemo_logging:393] PADDING: 16\n",
            "[NeMo I 2025-11-10 03:12:31 nemo_logging:393] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.5.2/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2025-11-10 03:12:31 nemo_logging:405] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-11-10 03:12:31 nemo_logging:393] Number of files to diarize: 1\n",
            "[NeMo I 2025-11-10 03:12:31 nemo_logging:393] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-11-10 03:12:31 nemo_logging:393] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2025-11-10 03:12:31 nemo_logging:393] Perform streaming frame-level VAD\n",
            "[NeMo I 2025-11-10 03:12:31 nemo_logging:393] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2025-11-10 03:12:31 nemo_logging:393] Dataset successfully loaded with 42 items and total duration provided from manifest is  0.58 hours.\n",
            "[NeMo I 2025-11-10 03:12:31 nemo_logging:393] # 42 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 42/42 [00:36<00:00,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-11-10 03:13:08 nemo_logging:393] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-11-10 03:13:32 nemo_logging:393] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:01<00:00,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-11-10 03:13:34 nemo_logging:393] Subsegmentation for embedding extraction: scale0, output/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2025-11-10 03:13:34 nemo_logging:393] Extracting embeddings for Diarization\n",
            "[NeMo I 2025-11-10 03:13:34 nemo_logging:393] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2025-11-10 03:13:34 nemo_logging:393] Dataset successfully loaded with 1632 items and total duration provided from manifest is  0.80 hours.\n",
            "[NeMo I 2025-11-10 03:13:34 nemo_logging:393] # 1632 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/4] extract embeddings: 100%|██████████| 51/51 [00:02<00:00, 19.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-11-10 03:13:36 nemo_logging:393] Subsegmentation for embedding extraction: scale1, output/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2025-11-10 03:13:36 nemo_logging:393] Extracting embeddings for Diarization\n",
            "[NeMo I 2025-11-10 03:13:36 nemo_logging:393] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2025-11-10 03:13:36 nemo_logging:393] Dataset successfully loaded with 2196 items and total duration provided from manifest is  0.85 hours.\n",
            "[NeMo I 2025-11-10 03:13:36 nemo_logging:393] # 2196 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/4] extract embeddings: 100%|██████████| 69/69 [00:03<00:00, 22.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-11-10 03:13:39 nemo_logging:393] Subsegmentation for embedding extraction: scale2, output/speaker_outputs/subsegments_scale2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-11-10 03:13:40 nemo_logging:393] Extracting embeddings for Diarization\n",
            "[NeMo I 2025-11-10 03:13:40 nemo_logging:393] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2025-11-10 03:13:40 nemo_logging:393] Dataset successfully loaded with 3356 items and total duration provided from manifest is  0.89 hours.\n",
            "[NeMo I 2025-11-10 03:13:40 nemo_logging:393] # 3356 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/4] extract embeddings: 100%|██████████| 105/105 [00:03<00:00, 26.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-11-10 03:13:44 nemo_logging:393] Subsegmentation for embedding extraction: scale3, output/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2025-11-10 03:13:44 nemo_logging:393] Extracting embeddings for Diarization\n",
            "[NeMo I 2025-11-10 03:13:44 nemo_logging:393] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2025-11-10 03:13:44 nemo_logging:393] Dataset successfully loaded with 6904 items and total duration provided from manifest is  0.94 hours.\n",
            "[NeMo I 2025-11-10 03:13:44 nemo_logging:393] # 6904 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/4] extract embeddings: 100%|██████████| 216/216 [00:06<00:00, 32.18it/s]\n",
            "clustering: 100%|██████████| 1/1 [00:02<00:00,  2.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-11-10 03:13:53 nemo_logging:393] Outputs are saved in /content/output directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2025-11-10 03:13:53 nemo_logging:405] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 화자 분리 완료\n",
            "   감지된 화자 수: 5명\n",
            "   화자: ['speaker_0', 'speaker_1', 'speaker_2', 'speaker_3', 'speaker_4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 화자와 텍스트 결합"
      ],
      "metadata": {
        "id": "LQpLMy3qNCYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Whisper 결과와 화자 정보 매칭 (세그먼트 기반) =====\n",
        "print(\"\\n🔗 전사 결과와 화자 정보 매칭 중...\")\n",
        "\n",
        "def find_speaker_for_segment(start, end, speaker_timestamps):\n",
        "    \"\"\"\n",
        "    세그먼트 전체에서 가장 많이 겹치는 화자 찾기\n",
        "    \"\"\"\n",
        "    speaker_overlaps = {}\n",
        "\n",
        "    for spk in speaker_timestamps:\n",
        "        overlap_start = max(start, spk['start'])\n",
        "        overlap_end = min(end, spk['end'])\n",
        "        overlap = max(0, overlap_end - overlap_start)\n",
        "\n",
        "        if overlap > 0:\n",
        "            speaker = spk['speaker']\n",
        "            speaker_overlaps[speaker] = speaker_overlaps.get(speaker, 0) + overlap\n",
        "\n",
        "    if not speaker_overlaps:\n",
        "        return \"UNKNOWN\"\n",
        "\n",
        "    # 가장 많이 겹치는 화자 반환\n",
        "    return max(speaker_overlaps, key=speaker_overlaps.get)\n",
        "\n",
        "# ★ 세그먼트 단위로 화자 할당 (단어 단위 X)\n",
        "formatted_segments = []\n",
        "\n",
        "for segment in transcription:\n",
        "    # 세그먼트 전체 시간으로 화자 결정\n",
        "    speaker = find_speaker_for_segment(segment['start'], segment['end'], speaker_timestamps)\n",
        "\n",
        "    formatted_segments.append({\n",
        "        'start': segment['start'],\n",
        "        'end': segment['end'],\n",
        "        'speaker': speaker,\n",
        "        'text': segment['text'].strip()\n",
        "    })\n",
        "\n",
        "print(f\"✅ 화자 할당 완료: {len(formatted_segments)} 세그먼트\")\n",
        "\n",
        "# 같은 화자의 인접 발화 병합\n",
        "merged_segments = []\n",
        "for seg in formatted_segments:\n",
        "    if merged_segments and \\\n",
        "       merged_segments[-1]['speaker'] == seg['speaker'] and \\\n",
        "       merged_segments[-1]['speaker'] != 'UNKNOWN':\n",
        "\n",
        "        gap = seg['start'] - merged_segments[-1]['end']\n",
        "\n",
        "        # 2초 이내면 병합\n",
        "        if gap <= 2.0:\n",
        "            merged_segments[-1]['text'] += ' ' + seg['text']\n",
        "            merged_segments[-1]['end'] = seg['end']\n",
        "        else:\n",
        "            merged_segments.append(seg)\n",
        "    else:\n",
        "        merged_segments.append(seg)\n",
        "\n",
        "formatted_segments = merged_segments\n",
        "\n",
        "# 최종 화자 수\n",
        "final_speakers = set([seg['speaker'] for seg in formatted_segments if seg['speaker'] != 'UNKNOWN'])\n",
        "\n",
        "print(f\"   최종 세그먼트: {len(formatted_segments)}개\")\n",
        "print(f\"   🎯 최종 화자 수: {len(final_speakers)}명\")\n",
        "print(f\"   화자 목록: {', '.join(sorted(final_speakers))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwqsivW6KfYR",
        "outputId": "240d09ec-ce19-4da5-fa51-880593672096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔗 전사 결과와 화자 정보 매칭 중...\n",
            "✅ 화자 할당 완료: 758 세그먼트\n",
            "   최종 세그먼트: 291개\n",
            "   🎯 최종 화자 수: 5명\n",
            "   화자 목록: speaker_0, speaker_1, speaker_2, speaker_3, speaker_4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== JSON 형식 화자 분리 결과 생성 =====\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "print(\"\\n📊 JSON 형식 결과 생성 중...\")\n",
        "\n",
        "# 1. Turns 데이터 생성 (RTTM 기반)\n",
        "turns = []\n",
        "for ts in speaker_timestamps:\n",
        "    turns.append({\n",
        "        \"speaker_label\": ts['speaker'].upper(),  # speaker_0 → SPEAKER_0\n",
        "        \"start\": round(ts['start'], 2),\n",
        "        \"end\": round(ts['end'], 2)\n",
        "    })\n",
        "\n",
        "# 시간순 정렬\n",
        "turns.sort(key=lambda x: x['start'])\n",
        "\n",
        "print(f\"   ✅ Turns: {len(turns)}개 세그먼트\")\n",
        "\n",
        "# 2. Speaker Embeddings 추출\n",
        "print(\"   🔄 화자별 대표 임베딩 추출 중...\")\n",
        "\n",
        "# NeMo에서 생성한 embedding 파일 경로\n",
        "emb_dir = os.path.join(output_dir, \"speaker_outputs\", \"embeddings\")\n",
        "os.makedirs(emb_dir, exist_ok=True)\n",
        "\n",
        "# Speaker embedding 모델 로드 (이미 로드되어 있으면 재사용)\n",
        "from nemo.collections.asr.models import EncDecSpeakerLabelModel\n",
        "\n",
        "if 'speaker_model' not in dir():\n",
        "    print(\"   📥 TitaNet 모델 로딩...\")\n",
        "    speaker_model = EncDecSpeakerLabelModel.from_pretrained(\"titanet_large\")\n",
        "    speaker_model = speaker_model.eval().to('cuda')\n",
        "\n",
        "# 화자별 임베딩 추출\n",
        "embeddings_dict = {}\n",
        "\n",
        "for speaker_id in detected_speakers:\n",
        "    # 해당 화자의 모든 세그먼트 찾기\n",
        "    speaker_segments = [ts for ts in speaker_timestamps if ts['speaker'] == speaker_id]\n",
        "\n",
        "    if not speaker_segments:\n",
        "        continue\n",
        "\n",
        "    # 가장 긴 세그먼트 3개 선택 (대표성 높은 발화)\n",
        "    speaker_segments.sort(key=lambda x: x['end'] - x['start'], reverse=True)\n",
        "    top_segments = speaker_segments[:min(3, len(speaker_segments))]\n",
        "\n",
        "    segment_embeddings = []\n",
        "\n",
        "    for seg in top_segments:\n",
        "        try:\n",
        "            # 오디오 로드\n",
        "            waveform, sr = torchaudio.load(\n",
        "                preprocessed_path,\n",
        "                frame_offset=int(seg['start'] * 16000),\n",
        "                num_frames=int((seg['end'] - seg['start']) * 16000)\n",
        "            )\n",
        "\n",
        "            # 최소 길이 체크 (너무 짧으면 스킵)\n",
        "            if waveform.shape[1] < 1600:  # 0.1초 미만\n",
        "                continue\n",
        "\n",
        "            # 임베딩 추출\n",
        "            with torch.no_grad():\n",
        "                waveform = waveform.to('cuda')\n",
        "                signal_length = torch.tensor([waveform.shape[1]]).to('cuda')\n",
        "\n",
        "                # ★ TitaNet은 tuple (logits, emb)를 반환\n",
        "                output = speaker_model(input_signal=waveform, input_signal_length=signal_length)\n",
        "\n",
        "                # output이 tuple인 경우 임베딩만 추출\n",
        "                if isinstance(output, tuple):\n",
        "                    emb = output[-1]  # 마지막 요소가 embedding\n",
        "                else:\n",
        "                    emb = output\n",
        "\n",
        "                emb = emb.cpu().numpy()[0]  # (embedding_dim,)\n",
        "                segment_embeddings.append(emb)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   ⚠️ {speaker_id} 세그먼트 [{seg['start']:.1f}s-{seg['end']:.1f}s] 스킵: {str(e)[:50]}\")\n",
        "            continue\n",
        "\n",
        "    if not segment_embeddings:\n",
        "        print(f\"   ⚠️ {speaker_id}: 유효한 임베딩 없음, 스킵\")\n",
        "        continue\n",
        "\n",
        "    # 평균 임베딩 계산 (여러 세그먼트의 평균)\n",
        "    mean_embedding = np.mean(segment_embeddings, axis=0)\n",
        "\n",
        "    # 정규화 (L2 norm)\n",
        "    mean_embedding = mean_embedding / np.linalg.norm(mean_embedding)\n",
        "\n",
        "    embeddings_dict[speaker_id.upper()] = mean_embedding.tolist()\n",
        "\n",
        "    print(f\"   ✓ {speaker_id.upper()}: {len(segment_embeddings)}개 세그먼트 평균, dim={len(mean_embedding)}\")\n",
        "\n",
        "# 3. 최종 JSON 생성\n",
        "output_json = {\n",
        "    \"turns\": turns,\n",
        "    \"embeddings\": embeddings_dict,\n",
        "    \"metadata\": {\n",
        "        \"num_speakers\": len(detected_speakers),\n",
        "        \"total_turns\": len(turns),\n",
        "        \"audio_duration\": round(duration, 2) if 'duration' in dir() else 0,\n",
        "        \"embedding_dim\": len(list(embeddings_dict.values())[0]) if embeddings_dict else 0\n",
        "    }\n",
        "}\n",
        "\n",
        "# JSON 파일 저장\n",
        "json_output_path = os.path.join(output_dir, \"diarization_result.json\")\n",
        "with open(json_output_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(output_json, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"\\n✅ JSON 결과 저장 완료: {json_output_path}\")\n",
        "print(f\"   화자 수: {len(detected_speakers)}명\")\n",
        "print(f\"   총 turns: {len(turns)}개\")\n",
        "print(f\"   임베딩 차원: {output_json['metadata']['embedding_dim']}\")\n",
        "\n",
        "# 미리보기\n",
        "print(\"\\n[JSON 미리보기 - 처음 5개 turns]\")\n",
        "preview = {\n",
        "    \"turns\": turns[:5],\n",
        "    \"embeddings\": {k: f\"[{len(v)} dims, first 5: {v[:5]}]\" for k, v in embeddings_dict.items()},\n",
        "    \"metadata\": output_json[\"metadata\"]\n",
        "}\n",
        "print(json.dumps(preview, indent=2, ensure_ascii=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "255i7YncsFzJ",
        "outputId": "830bb13a-29ae-4cc1-d6e1-899dc70d56bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 JSON 형식 결과 생성 중...\n",
            "   ✅ Turns: 766개 세그먼트\n",
            "   🔄 화자별 대표 임베딩 추출 중...\n",
            "   ✓ SPEAKER_2: 3개 세그먼트 평균, dim=192\n",
            "   ✓ SPEAKER_3: 3개 세그먼트 평균, dim=192\n",
            "   ✓ SPEAKER_4: 3개 세그먼트 평균, dim=192\n",
            "   ✓ SPEAKER_1: 3개 세그먼트 평균, dim=192\n",
            "   ✓ SPEAKER_0: 3개 세그먼트 평균, dim=192\n",
            "\n",
            "✅ JSON 결과 저장 완료: output/diarization_result.json\n",
            "   화자 수: 5명\n",
            "   총 turns: 766개\n",
            "   임베딩 차원: 192\n",
            "\n",
            "[JSON 미리보기 - 처음 5개 turns]\n",
            "{\n",
            "  \"turns\": [\n",
            "    {\n",
            "      \"speaker_label\": \"SPEAKER_1\",\n",
            "      \"start\": 4.56,\n",
            "      \"end\": 6.75\n",
            "    },\n",
            "    {\n",
            "      \"speaker_label\": \"SPEAKER_1\",\n",
            "      \"start\": 7.5,\n",
            "      \"end\": 10.38\n",
            "    },\n",
            "    {\n",
            "      \"speaker_label\": \"SPEAKER_2\",\n",
            "      \"start\": 10.38,\n",
            "      \"end\": 11.93\n",
            "    },\n",
            "    {\n",
            "      \"speaker_label\": \"SPEAKER_2\",\n",
            "      \"start\": 12.54,\n",
            "      \"end\": 13.41\n",
            "    },\n",
            "    {\n",
            "      \"speaker_label\": \"SPEAKER_1\",\n",
            "      \"start\": 13.41,\n",
            "      \"end\": 13.77\n",
            "    }\n",
            "  ],\n",
            "  \"embeddings\": {\n",
            "    \"SPEAKER_2\": \"[192 dims, first 5: [-0.031645651906728745, 0.13020065426826477, 0.1139407604932785, -0.022909896448254585, -0.1378033310174942]]\",\n",
            "    \"SPEAKER_3\": \"[192 dims, first 5: [-0.024797625839710236, -0.03396477550268173, 0.09175880253314972, 0.015499652363359928, -0.07271988689899445]]\",\n",
            "    \"SPEAKER_4\": \"[192 dims, first 5: [0.11943823844194412, -0.034729599952697754, -0.07893848419189453, 0.03651506453752518, -0.07325645536184311]]\",\n",
            "    \"SPEAKER_1\": \"[192 dims, first 5: [-0.07870450615882874, 0.11556865274906158, 0.08004069328308105, 0.07262333482503891, -0.09861373156309128]]\",\n",
            "    \"SPEAKER_0\": \"[192 dims, first 5: [-0.03194919228553772, 0.1537827104330063, 0.08487872034311295, 0.010582980699837208, -0.14043846726417542]]\"\n",
            "  },\n",
            "  \"metadata\": {\n",
            "    \"num_speakers\": 5,\n",
            "    \"total_turns\": 766,\n",
            "    \"audio_duration\": 0.31,\n",
            "    \"embedding_dim\": 192\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 결과 포맷팅 및 저장 =====\n",
        "output_path = os.path.join(output_dir, \"transcript.txt\")\n",
        "\n",
        "formatted_text = \"\"\n",
        "for seg in formatted_segments:\n",
        "    speaker_label = seg['speaker'].replace('speaker_', 'Speaker ')\n",
        "    formatted_text += f\"{speaker_label}: {seg['text']}\\n\\n\"\n",
        "\n",
        "# 파일 저장\n",
        "with open(output_path, 'w', encoding='utf-8') as f:\n",
        "    f.write(formatted_text)\n",
        "\n",
        "# 통계 출력\n",
        "print(\"=\" * 50)\n",
        "print(\"화자 분리 결과\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"감지된 화자 수: {len(detected_speakers)}명\")\n",
        "print(f\"총 발화 세그먼트: {len(formatted_segments)}개\")\n",
        "print(f\"\\n화자별 발화 횟수:\")\n",
        "\n",
        "from collections import Counter\n",
        "speaker_counts = Counter([seg['speaker'] for seg in formatted_segments])\n",
        "for speaker, count in sorted(speaker_counts.items()):\n",
        "    speaker_label = speaker.replace('speaker_', 'Speaker ')\n",
        "    print(f\"  {speaker_label}: {count}회\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"미리보기 (처음 20개)\")\n",
        "print(\"=\" * 50)\n",
        "for i, seg in enumerate(formatted_segments[:20], 1):\n",
        "    speaker_label = seg['speaker'].replace('speaker_', 'Speaker ')\n",
        "    print(f\"{i}. [{seg['start']:.1f}s] {speaker_label}: {seg['text'][:100]}\")\n",
        "\n",
        "print(f\"\\n전체 내용: {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9iB2hfLMTL-",
        "outputId": "832c982c-3c46-436d-83f4-e14624278226"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "화자 분리 결과\n",
            "==================================================\n",
            "감지된 화자 수: 5명\n",
            "총 발화 세그먼트: 291개\n",
            "\n",
            "화자별 발화 횟수:\n",
            "  UNKNOWN: 9회\n",
            "  Speaker 0: 112회\n",
            "  Speaker 1: 62회\n",
            "  Speaker 2: 58회\n",
            "  Speaker 3: 21회\n",
            "  Speaker 4: 29회\n",
            "\n",
            "==================================================\n",
            "미리보기 (처음 20개)\n",
            "==================================================\n",
            "1. [4.3s] Speaker 1: 그러면 너무 회의만 하지 말고 좀 토킹 어바웃을 해볼까요? 좀 여유롭게\n",
            "2. [10.1s] Speaker 2: 처음에 그냥 아이트 브레이킹? 지금 누른 거예요? 자, 재용 님 말하세요\n",
            "3. [16.9s] Speaker 3: 방금 강제로 20분 산책을 하다 왔습니다\n",
            "4. [19.2s] Speaker 4: 강제로요?\n",
            "5. [20.6s] Speaker 3: 담배 소리 이 앞에 편의점 갔다가 신분증 없다가 빠꾸 맞아 먹어서 여기 칼국수집 쪽 편의점 갔다가 거기서도 빠꾸 맞아 가지고\n",
            "6. [30.1s] Speaker 2: 왠지 안 올라왔잖아\n",
            "7. [31.2s] Speaker 3: 저 반대쪽 편의점 가서 거기서 겨우 사 왔어요\n",
            "8. [34.3s] Speaker 0: 고등학생 같긴 해\n",
            "9. [34.9s] Speaker 4: 그럴 리가 없는데?\n",
            "10. [37.3s] Speaker 2: 그 정도인가?\n",
            "11. [39.2s] Speaker 1: 거의 좀 서른인데?\n",
            "12. [40.9s] Speaker 0: 얘가 그랬어요\n",
            "13. [43.2s] Speaker 2: 흠, 그 정도인가?\n",
            "14. [52.7s] Speaker 2: 중간중간에 계속 말을 해봐요 우리가 하는 것처럼 언제든지 치고 들어와 봐요\n",
            "15. [60.8s] Speaker 2: 그럼 진행해 주시죠\n",
            "16. [63.9s] Speaker 0: 너무 죄송해요 저 지금 이거 뭐지? 구글 클라우드 SCT라는 걸 처음 저는 이게 이렇게 어려운 건 줄 몰라요 애셈블레어, AIS인데 개꿀 저는 이거 지금 구글 클라우드랑 구글 스토\n",
            "17. [118.6s] Speaker 3: 해보긴 했는데 빠르긴 진짜 빠르거든요 15분짜리 파일이면은 한 그 시간 스탬프가 0.3에서 0.5천 원에 짜락 찍혀요 근데 결과가 안 좋아요\n",
            "18. [132.7s] Speaker 0: 안 좋다고 하면 약간 어떤 느낌\n",
            "19. [138.0s] UNKNOWN: 열게요\n",
            "20. [140.2s] Speaker 0: 중간 멈췄구나 자 그래서 이제 그러면 지금 니모랑 스피치 브레인 말씀하셨다가 좀 더 말씀해 줄 수 있어요?\n",
            "\n",
            "전체 내용: output/transcript.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# 결과 파일 다운로드\n",
        "files.download(output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-RwMAzp6NHRT",
        "outputId": "433a2531-7285-4774-ce0b-4b492ad85b6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1f6ea714-f676-4dde-9d75-46bb5c7af2cb\", \"transcript.txt\", 40497)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OfmMVe4Vz9b3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}