# LLM 사용 여부 판단
- 비 LLM
    - 그래프 기반 요약(TextRank)
    - 주제어 확률 기반 요약(Keyword Probability Based)
    - 지식 기반 의미 통합
    - 통계 기반 문장 선택
    - 템플릿 기반 의미 합성
    - Extractive 요약 모델(BERT, KoBERT 등)
    - Seq2Seq 기반 생성 요약(T5, BART 등)

- 판단 결과 요약 결과자체는 품질이 매우 떨어지지는 않음. 하지만, 사전에서 찾지 못한 단어에 대한 의미 생성에 LLM이 필수라 판단되어 LLM을 사용하기로 확정.

# LLM 모델 탐색
- API
    - Claude 3.5 Haiku (Anthropic)
    - HyperCLOVA X (Naver)
    - Gemini 1.5 Flash (Google)
    - Upstage Solar Pro / Mini (Upstage)
    - DeepSeek-V3 (DeepSeek)
    - Mistral Large 2 / small(Mistral AI)
- Local
    - LG EXAONE 3.0 7.8B (LG AI Research)
    - Qwen 2.5 7B / 14B (Alibaba)
    - Google Gemma 2, 3 (9B) - 후순위
    - Upstage Solar 10.7B (v1.0)
    - Mistral-Nemo (12B) - 최후순위
    - Microsoft Phi-3.5 Mini

# LLM 모델 결과
- LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct
    - 요약 시간: 143.23 초
    - 1~2문장을 부탁했지만, 그 이상의 긴 문장이 출력
    - 전혀 관련 없거나, 부탁한 적 없는 문장이 출력
        - ex)HIV설명에 kilobyte와 Democracy에 대한 설명 or Attention 설명에 Abandon에 대한 설명 등
    - prompt에 주어진 내용 그대로 출력
    - 같은 답변 다중 반복 출력
    - 합성어/신조어의 뜻에 강한듯 보임
- Qwen/Qwen2-7B-Instruct
    - 요약 시간 : 86.36 초
    - 다의어의 경우, 알맞지 않은 결과 출력 → 문맥이 주어지지 않은 이유
        - 한번에 여러 의미를 다 출력하게 하는 방법은 가능한가?
        - 프롬프트를 다시 수정해보자.
    - 신조어(갓생 등)에 약한 모습을 보임
    - 중국모델이라 그런지 한자가 포함되어 나옴

# 오탈자 처리
- GIGO
- 현재 우선도가 높지 않다고 판단
    - 2차 step까지 완료 후, 결과 보고 판단
    - 당장은 필요성 X

# 단어 사전
- wiktionary & wordnet_ko 제외

# 예정
- 모든 탐색 LLM 테스트
- 프롬포트 강화
- 사전 추가 및 검증