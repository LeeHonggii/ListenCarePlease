# TO DO

- 정량적 지표 test
    1. 실제 결과를 구할 수 있는지 (계산 가능?)
    2. 시각화 가능?
- [x]  발화 점유율
- [x]  발화 빈도
- [x]  발화 간 침묵 시간
- [x]  TTR
- [ ]  정보량
- [ ]  엔트로피
- [ ]  PPL
- [ ]  PMI

https://drive.google.com/drive/folders/1DYjba19FxBIOCYUaP49ZdiJL_nX6veOE?usp=drive_link

# data

[result_final.json](attachment:f00d4d34-f86c-4b90-9cc1-ec24be527403:result_final.json)

[result_final_with_embeddings.json](attachment:946bab8f-5c4b-484a-9980-dc371e5b8597:result_final_with_embeddings.json)

# #1. 발화 기반 구조적 지표 (Turn / Time 기반)

### **1) 발화 점유율 (Share of Voice, SoV)**

$$
SoV_k = \frac{\sum^{n}_{i=1}(End_{i,k}-Start_{i,k})}{Total Meeting Duration} * 100
$$

![sov_donut_chart.png](attachment:b33a0c34-9ce7-4376-a294-8dd3065526c6:sov_donut_chart.png)

![sov_bar_chart.png](attachment:721fdef6-b2c2-4434-9c56-4ea2d9be7eea:sov_bar_chart.png)

![sov_token_donut_chart.png](attachment:158314bd-4a8e-48f4-ad7f-de51324b788e:sov_token_donut_chart.png)

![sov_token_bar_chart.png](attachment:6a5ee068-630b-45f4-b9fd-a506ec6249e8:sov_token_bar_chart.png)

```markdown
======================================================================
📊 시간 기반 vs 토큰 기반 발화 점유율 비교
======================================================================
  Speaker  Time (%)  Token (%)  Difference
SPEAKER_0 34.802774  38.025594    3.222820
SPEAKER_2 16.557778  15.868373   -0.689405
SPEAKER_5 15.209490  16.416819    1.207329
SPEAKER_1 12.158376  11.700183   -0.458193
SPEAKER_4 11.999316   9.067642   -2.931675
SPEAKER_3  9.272266   8.921389   -0.350877
======================================================================

💡 해석:
  - Difference > 0: 말을 빠르게 많이 하는 스타일
  - Difference < 0: 말을 천천히 적게 하는 스타일
  - Difference ≈ 0: 평균적인 말하기 속도
```

---

### **2) 발화 빈도 & 턴 테이킹 지표 (Turn-taking Frequency)**

data 의 segments value 이용

![turn_taking_donut_chart.png](attachment:98f5064c-e9f6-41de-b46f-2b2c9855bf26:turn_taking_donut_chart.png)

![turn_taking_bar_chart.png](attachment:33323e2b-ad35-44ae-89f0-7b4563c065c4:turn_taking_bar_chart.png)

![speaking_style_scatter.png](attachment:da339dca-6635-4d11-aa5a-df382f53cf94:speaking_style_scatter.png)

```markdown
전체 발화 횟수 (총 턴 수): 385회

--------------------------------------------------------------------------------
화자              발화 횟수        빈도 비율(%)        평균 길이(초)        스타일                 
--------------------------------------------------------------------------------
SPEAKER_0       109          28.31           4.30            짧고 빠른 발화 ⚡          
SPEAKER_5       84           21.82           2.44            짧고 빠른 발화 ⚡          
SPEAKER_2       57           14.81           3.91            짧고 빠른 발화 ⚡          
SPEAKER_1       55           14.29           2.97            짧고 빠른 발화 ⚡          
SPEAKER_4       43           11.17           3.75            짧고 빠른 발화 ⚡          
SPEAKER_3       37           9.61            3.37            짧고 빠른 발화 ⚡          
--------------------------------------------------------------------------------
합계              385          100.00         
================================================================================

💡 해석 가이드:
  - 짧고 빠른 발화 (<10초): 활발한 토론, 상호작용 빈번
  - 적절한 길이 (10-30초): 일반적인 대화 패턴
  - 긴 발화 (30초-3분): 설명, 보고 스타일
  - 매우 긴 발화 (>3분): 일방적 강의, 프레젠테이션
```

---

### **3) 발화 간 침묵 시간 (Silence Gap)**

![silence_ratio_pie_chart.png](attachment:01f741ac-0d06-454f-aa0c-10d30762fcac:silence_ratio_pie_chart.png)

```markdown
⏱️ 긴 침묵 구간 분석 (>= 5초)
================================================================================
총 48개의 긴 침묵 구간 발견

--------------------------------------------------------------------------------
시작 시간           종료 시간           길이(초)           이전 화자           다음 화자          
--------------------------------------------------------------------------------
2270.07         2598.36         328.29          SPEAKER_0       END            
1801.89         1854.08         52.19           SPEAKER_0       SPEAKER_0      
1964.51         1992.57         28.06           SPEAKER_0       SPEAKER_5      
1857.45         1884.08         26.63           SPEAKER_0       SPEAKER_0      
1350.83         1375.26         24.43           SPEAKER_0       SPEAKER_3      
2044.21         2067.46         23.25           SPEAKER_0       SPEAKER_5      
2067.91         2090.32         22.41           SPEAKER_5       SPEAKER_0      
1894.35         1914.68         20.33           SPEAKER_2       SPEAKER_2      
1284.13         1301.12         16.99           SPEAKER_0       SPEAKER_0      
1.03            17.75           16.72           SPEAKER_5       SPEAKER_0      
... 외 38개
```

---

# #2. 언어적 정보 기반 지표 (Information-based Metrics)

**정보량 / 엔트로피 / perplexity / PMI / TTR**

---

## **4) 정보량 (Information Content, -log p(x))**

문장의 정보량을 어떻게 계산할까?

1. 통계적 확률 기반 (LLM) : “이 문장이 문맥상 얼마나 예측 불가능한가?”
    1. 
    
    $$
    I(S) = -\sum^{n}_{i=1}logP(w_i | w_{1...i-1},context)
    $$
    
    P : 앞의 문맥을 봤을 때 해당 단어가 나올 확룰
    
    I : 문장의 총 정보
    
    도구 : hf → GPT2LMHeadModel, CaualLM
    
2. 의미적 거리 기반 (Embedding) : “이 문장이 앞의 내용가 얼마나 다른 이야기를 하는가?”
    1. 벡터화 : 현재 문장과 이전 윈도우의 문장들을 벡터로 변환
    2. 컨텍스트 벡터 생성 : 이전 문장들의 평균 벡터 계산
    3. 거리 계산 :
        
        $$
        Info(S_t) = 1 - CosinSimliarity(V_s, V_{context})
        $$
        
3. 키워드 희소성 기반 (TF-IDF) 

---

## **5) 정보 엔트로피 (Information Entropy)**

---

## **6) Perplexity 변화 추이**

(PPL은 모델 기준 예측 난이도)

---

## **7) TTR (Type-Token Ratio: 어휘 다양성)**

$$
TTR = \frac{고유\ 단어\ 수}{전체\ 단어\ 수}
$$

- 알고리즘
    
    🛠️ STEP 1: 데이터 준비 및 전처리
    1.1 JSON 파일 로드
    1.2 형태소 분석 (Mecab/Kiwi)
    1.3 명사(NNG, NNP) 추출
    1.4 Stopwords 제거
    1.5 시간 정보와 함께 저장 → [{time, word, pos}, ...]
    
    🪟 STEP 2: 슬라이딩 윈도우 설정
    2.1 윈도우 크기 설정 (명사 30~50개 또는 시간 60~120초)
    2.2 이동 간격 설정 (1~5개 또는 5~10초)
    2.3 최소 윈도우 크기 체크 (< 10개면 skip)
    
    🧮 STEP 3: 구간별 TTR 계산
    3.1 각 윈도우에서 Types/Tokens 계산
    3.2 (선택) RTTR 또는 LogTTR 계산
    3.3 윈도우 중심 시간 기록
    
    📈 STEP 4: 시각화
    4.1 원본 TTR 라인 플롯
    4.2 이동 평균(MA) 적용 및 신뢰구간 표시
    4.3 전체 평균 기준선 추가
    4.4 급변 구간 하이라이트
    4.5 해석 가이드 추가
    
    📊 STEP 5: 추가 분석 (선택)
    5.1 TTR 변화율 계산 (기울기)
    5.2 구간별 대표 키워드 추출
    5.3 TTR 급등/급락 구간의 실제 발화 내용 출력
    

![ttr_timeline.png](attachment:dd771d24-1397-42d7-bd60-b18c617899b5:ttr_timeline.png)

평가 : 추세를 확인할 수는 있다. 이게 TTR이 낮아질 수 있을까?

단어 추출해놓은거 보면 쉽지 않아 보인다.

---

## **8) PMI (Pointwise Mutual Information)**

### ✨ PMI × Perplexity 조합

| **구분** | **PMI 높음 (내용 끈끈함)** | **PMI 낮음 (내용 산만함)** |
| --- | --- | --- |
| **PPL 낮음**
(흐름 매끄러움) | **🏆 최상의 회의 (Deep Flow)**
주제도 깊고, 티키타카도 잘됨.
*(이상적인 전략 회의)* | **🗣️ 잡담/친목 (Small Talk)**
대화는 즐겁고 매끄럽지만,
남는 내용은 없음. |
| **PPL 높음**
(흐름 끊김/낯섦) | **⚔️ 격렬한 논쟁 (Debate)**
주제는 확실하지만,
서로 반박하느라 흐름이 거침. | **💥 최악의 회의 (Chaos)**
주제도 중구난방이고,
서로 무슨 말 하는지 모름. |

---

# 진행 중 어려운 점 (장애물이나 막힌곳 설명)

1. (2) 평균 발화 시간이 2~4초 밖에 되지 않다는 점이 이상하다. ⇒ 평균의 함정인가? 
2. (3)에서 slience time 이 너무 길다.
    
    총 발화 시간은 meta data인 [’file_info’][’duration’]에서 가져오는데 이게 [’segments’] 의 마지막 대화 종료시간과 차이가 너무 나더라.
    
    diarization 문제인가? 흠…
    
    해결 방법 ⇒ 총 발화시간을 metadata에서 뽑지 말고 segments의 첫 대화의 ‘start’와 마지막 발화의 ‘end’의 차이로 재정의하면 앞뒤 공백을 임의로 줄일 수 있다.
    
    그러나 이거 바꾸려면 1, 2, 3 지표의 코드를 모두 수정해야 하니, 나중에 함
    
3. (4) TTR 파트에서 STEP1만 24분이 소요