{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ad8b494",
   "metadata": {},
   "source": [
    "ì´ íŒŒì¼ì€ colab ê¸°ì¤€ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23edf8b",
   "metadata": {},
   "source": [
    "#ìŒì„± ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b59609",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install webrtcvad soundfile scipy\n",
    "!pip install faster-whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e386f93d",
   "metadata": {},
   "source": [
    "##Google Drive Mount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e754e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Google Drive Mount ===\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde47ae5",
   "metadata": {},
   "source": [
    "##m4a â†’ wav ë³€í™˜(16kHz, mono)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4671c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 0) ffmpeg ë³€í™˜ (ëª¨ë“  í¬ë§· â†’ 16kHz / mono WAV) ===\n",
    "import subprocess\n",
    "\n",
    "# ì›ë³¸ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (ì˜ˆ: m4a, mp3 ë“±)\n",
    "audio_path = \"íŒŒì¼ ê²½ë¡œ\"\n",
    "# ë³€í™˜ ê²°ê³¼ (ì „ì²˜ë¦¬ ì…ë ¥ìš©)\n",
    "converted_wav = \"íŒŒì¼ ê²½ë¡œ\"\n",
    "\n",
    "print(\"ğŸ”„ ffmpeg ë³€í™˜ ì¤‘... (16kHz / mono)\")\n",
    "subprocess.run([\n",
    "    \"ffmpeg\", \"-y\",\n",
    "    \"-i\", audio_path,\n",
    "    \"-ar\", \"16000\",   # 16kHz\n",
    "    \"-ac\", \"1\",       # mono\n",
    "    \"-acodec\", \"pcm_s16le\",\n",
    "    converted_wav\n",
    "], stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)\n",
    "print(f\"âœ… ë³€í™˜ ì™„ë£Œ â†’ {converted_wav}\")\n",
    "\n",
    "# ì´í›„ input_wav ê²½ë¡œë¥¼ ffmpeg ë³€í™˜ëœ íŒŒì¼ë¡œ ì§€ì •\n",
    "input_wav = converted_wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becc6dae",
   "metadata": {},
   "source": [
    "##ì „ì²˜ë¦¬ íŒŒë¼ë¯¸í„°, í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4c8697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Whisper íˆ¬ì… ì „ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ===\n",
    "# ì…ë ¥: 16kHz / mono WAV (m4aâ†’wav ë³€í™˜ì€ ì´ë¯¸ ëë‚œ ìƒíƒœ)\n",
    "# ë‹¨ê³„: HPF(80Hz) -> VAD(webrtcvad) -> Gain Normalize -> ì €ì¥\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import webrtcvad\n",
    "from scipy.signal import butter, sosfiltfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc81f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# ì„¤ì •ê°’\n",
    "# -----------------------------\n",
    "# ìœ„ì—ì„œ ìƒì„±ëœ converted_wav íŒŒì¼ì„ input_wavë¡œ ì‚¬ìš©\n",
    "output_wav = \"íŒŒì¼ ê²½ë¡œ\"\n",
    "\n",
    "SR = 16000\n",
    "HPF_CUTOFF = 80.0      # Hz\n",
    "HPF_ORDER  = 4         # Butterworth ì°¨ìˆ˜\n",
    "VAD_AGGR   = 2         # 0(ëŠìŠ¨) ~ 3(ê³µê²©ì ) ê¶Œì¥: 2\n",
    "FRAME_MS   = 20        # webrtcvad í—ˆìš©: 10/20/30ms\n",
    "PAD_MS     = 150       # ë°œí™” êµ¬ê°„ ì „í›„ íŒ¨ë”© (hangover)\n",
    "TARGET_PEAK = 0.98     # Peak ì •ê·œí™” ëª©í‘œì¹˜ (0~1), ë„ˆë¬´ ë†’ì´ë©´ clip ìœ„í—˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0a1b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# ìœ í‹¸ í•¨ìˆ˜\n",
    "# -----------------------------\n",
    "def highpass_hz_80(audio: np.ndarray, sr: int) -> np.ndarray:\n",
    "    sos = butter(HPF_ORDER, HPF_CUTOFF, btype=\"highpass\", fs=sr, output=\"sos\")\n",
    "    return sosfiltfilt(sos, audio).astype(np.float32)\n",
    "\n",
    "def float_to_int16(x: np.ndarray) -> np.ndarray:\n",
    "    x = np.clip(x, -1.0, 1.0)\n",
    "    return (x * 32767.0).astype(np.int16)\n",
    "\n",
    "def int16_to_float(x: np.ndarray) -> np.ndarray:\n",
    "    return (x.astype(np.float32) / 32767.0)\n",
    "\n",
    "def frame_bytes_from_int16(x_i16: np.ndarray, sr: int, frame_ms: int):\n",
    "    frame_len = int(sr * frame_ms / 1000)\n",
    "    pad = (-len(x_i16)) % frame_len\n",
    "    if pad:\n",
    "        x_i16 = np.pad(x_i16, (0, pad), mode=\"constant\")\n",
    "    for i in range(0, len(x_i16), frame_len):\n",
    "        yield x_i16[i:i+frame_len].tobytes()\n",
    "    return pad\n",
    "\n",
    "def vad_keep_mask(audio_f32: np.ndarray, sr: int, frame_ms: int, aggressiveness: int, pad_ms: int):\n",
    "    vad = webrtcvad.Vad(aggressiveness)\n",
    "    x_i16 = float_to_int16(audio_f32)\n",
    "    frame_len = int(sr * frame_ms / 1000)\n",
    "    n_frames = int(np.ceil(len(x_i16) / frame_len))\n",
    "    pad = (-len(x_i16)) % frame_len\n",
    "    if pad:\n",
    "        x_i16 = np.pad(x_i16, (0, pad), mode=\"constant\")\n",
    "    voiced = np.zeros(n_frames, dtype=bool)\n",
    "\n",
    "    for idx in range(n_frames):\n",
    "        frm = x_i16[idx*frame_len:(idx+1)*frame_len].tobytes()\n",
    "        voiced[idx] = vad.is_speech(frm, sr)\n",
    "\n",
    "    pad_frames = max(1, int(pad_ms / frame_ms))\n",
    "    keep = np.zeros_like(voiced, dtype=bool)\n",
    "    for i, v in enumerate(voiced):\n",
    "        if v:\n",
    "            s = max(0, i - pad_frames)\n",
    "            e = min(n_frames, i + pad_frames + 1)\n",
    "            keep[s:e] = True\n",
    "\n",
    "    keep_samples = np.repeat(keep, frame_len)\n",
    "    keep_samples = keep_samples[:len(x_i16)]\n",
    "    keep_samples = keep_samples[:len(audio_f32)]\n",
    "    if len(keep_samples) < len(audio_f32):\n",
    "        keep_samples = np.pad(keep_samples, (0, len(audio_f32)-len(keep_samples)), mode=\"constant\")\n",
    "\n",
    "    return keep_samples\n",
    "\n",
    "def peak_normalize(x: np.ndarray, target_peak: float = 0.98) -> np.ndarray:\n",
    "    peak = np.max(np.abs(x)) + 1e-12\n",
    "    g = target_peak / peak\n",
    "    y = np.clip(x * g, -1.0, 1.0)\n",
    "    return y.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123aad1a",
   "metadata": {},
   "source": [
    "##ì „ì²˜ë¦¬ ê³¼ì • ì§„í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9751f6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
    "# -----------------------------\n",
    "# 1) ì½ê¸° (16kHz/mono ê°€ì •)\n",
    "audio, sr = sf.read(input_wav, always_2d=False)\n",
    "if sr != SR:\n",
    "    raise ValueError(f\"ì…ë ¥ SR={sr}ê°€ 16kHzê°€ ì•„ë‹™ë‹ˆë‹¤. ë³€í™˜ í›„ íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”.\")\n",
    "if audio.ndim != 1:\n",
    "    raise ValueError(\"ì…ë ¥ì´ monoê°€ ì•„ë‹™ë‹ˆë‹¤. ë³€í™˜ í›„ mono WAVë¥¼ ë„£ì–´ì£¼ì„¸ìš”.\")\n",
    "audio = audio.astype(np.float32)\n",
    "\n",
    "# 2) HPF(80Hz)\n",
    "audio_hpf = highpass_hz_80(audio, SR)\n",
    "\n",
    "# 3) VADë¡œ ë°œí™” êµ¬ê°„ë§Œ ìœ ì§€(ì „í›„ PAD)\n",
    "mask = vad_keep_mask(audio_hpf, SR, FRAME_MS, VAD_AGGR, PAD_MS)\n",
    "voiced = audio_hpf[mask]\n",
    "\n",
    "if voiced.size < int(0.1 * len(audio_hpf)) and len(audio_hpf) > 0:\n",
    "    voiced = audio_hpf  # fallback\n",
    "\n",
    "# 4) Gain Normalization (peak ê¸°ì¤€)\n",
    "voiced_norm = peak_normalize(voiced, TARGET_PEAK)\n",
    "\n",
    "# 5) ì €ì¥ (PCM_16)\n",
    "os.makedirs(os.path.dirname(output_wav), exist_ok=True)\n",
    "sf.write(output_wav, voiced_norm, SR, subtype=\"PCM_16\")\n",
    "\n",
    "print(f\"[OK] ì €ì¥ ì™„ë£Œ â†’ {output_wav}\")\n",
    "print(f\"ì›ë³¸ ê¸¸ì´: {len(audio)/SR:.2f}s,  ì „ì²˜ë¦¬ í›„ ê¸¸ì´: {len(voiced_norm)/SR:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f3af89",
   "metadata": {},
   "source": [
    "#Chunk ë¶„í• "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4deb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# âœ… OpenAI Whisper-1 í•œêµ­ì–´ ì „ì‚¬ + txt ì €ì¥ (Colabìš©)\n",
    "# ===============================================\n",
    "\n",
    "# 1ï¸âƒ£ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "!pip install --upgrade openai\n",
    "!pip install --upgrade openai pydub\n",
    "!apt -q install -y ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237a6a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pydub import AudioSegment\n",
    "import math\n",
    "import subprocess\n",
    "\n",
    "# ===== ì„¤ì • =====\n",
    "AUDIO_PATH = Path(\"ì…ë ¥ íŒŒì¼ ìœ„ì¹˜\")   # ì›ë³¸ ì˜¤ë””ì˜¤\n",
    "CHUNK_MINUTES = 10                                               # 10ë¶„ ë‹¨ìœ„\n",
    "DRIVE_CHUNK_DIR = Path(\"ì¶œë ¥ íŒŒì¼ ìœ„ì¹˜\")                         # ì „ì†¡ìš© wav ì €ì¥ í´ë”(Drive)\n",
    "LOCAL_TMP_DIR = Path(\"/content/chunks_tmp\")                      # ë¡œì»¬ ì„ì‹œ í´ë”(WAV ë“±)\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "MAX_TARGET_MB = 25  # ì•ˆë‚´ìš© ì²´í¬ (ì‹¤ì œ í•œë„ëŠ” 25MB)\n",
    "\n",
    "# ===== ì¤€ë¹„ =====\n",
    "assert AUDIO_PATH.exists(), f\"ì›ë³¸ ì˜¤ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤: {AUDIO_PATH}\"\n",
    "DRIVE_CHUNK_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOCAL_TMP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ===== ë¶„í•  =====\n",
    "audio = AudioSegment.from_file(AUDIO_PATH)\n",
    "chunk_ms = CHUNK_MINUTES * 60 * 1000\n",
    "num_chunks = math.ceil(len(audio) / chunk_ms)\n",
    "print(f\"ğŸ”¹ ì´ {num_chunks}ê°œë¡œ ë¶„í•  ì˜ˆì •(ì•½ {CHUNK_MINUTES}ë¶„ ë‹¨ìœ„)\")\n",
    "\n",
    "exported = []\n",
    "for i, start in enumerate(range(0, len(audio), chunk_ms)):\n",
    "    seg = audio[start:start+chunk_ms]\n",
    "\n",
    "    # â˜… ë¡œì»¬ ì„ì‹œ wav (ì›ë³¸ ìœ ì§€)\n",
    "    raw_wav = LOCAL_TMP_DIR / f\"chunk_{i:04d}.wav\"\n",
    "    seg.export(raw_wav, format=\"wav\")\n",
    "\n",
    "    # ============================================\n",
    "    # â˜…â˜…â˜… ffmpegë¡œ WAV ê·¸ëŒ€ë¡œ 16kHz monoë¡œ ì €ì¥\n",
    "    # ============================================\n",
    "    wav_path = DRIVE_CHUNK_DIR / f\"chunk_{i:04d}.wav\"\n",
    "    cmd = [\n",
    "        \"ffmpeg\", \"-v\", \"error\", \"-y\",\n",
    "        \"-i\", str(raw_wav),\n",
    "        \"-ac\", \"1\", \"-ar\", str(SAMPLE_RATE),\n",
    "        str(wav_path),\n",
    "    ]\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "    size_mb = wav_path.stat().st_size / (1024 * 1024)\n",
    "    print(f\"  â–¶ chunk_{i:04d}.wav  {size_mb:.2f} MB\")\n",
    "    if size_mb >= MAX_TARGET_MB:\n",
    "        print(\"    âš ï¸ 25MBì— ê·¼ì ‘/ì´ˆê³¼í•©ë‹ˆë‹¤. í•„ìš” ì‹œ CHUNK_MINUTESë¥¼ ë” ì¤„ì´ì„¸ìš”.\")\n",
    "\n",
    "    exported.append(wav_path)\n",
    "\n",
    "print(f\"âœ… WAV ë¶„í•  ì™„ë£Œ: {len(exported)}ê°œ íŒŒì¼ â†’ {DRIVE_CHUNK_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa490752",
   "metadata": {},
   "source": [
    "#Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd4cc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# âœ… ë¶„í• ëœ ì²­í¬(wav)ê°€ ë“¤ì–´ìˆëŠ” í´ë” (ì•ì„œ ì‚¬ìš©í•˜ë˜ ê²½ë¡œ ê·¸ëŒ€ë¡œ)\n",
    "CHUNK_DIR = Path(\"ì²­í¬ ìœ„ì¹˜\")\n",
    "\n",
    "# ì¶œë ¥ í´ë”ë“¤\n",
    "SRT_DIR = Path(\"SRT ì €ì¥ ìœ„ì¹˜\")   # ì²­í¬ë³„ SRT\n",
    "TXT_DIR = Path(\"TXT ì €ì¥ ìœ„ì¹˜\")   # ì²­í¬ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ TXT\n",
    "FINAL_TXT = Path(\"ìµœì¢… TXT ì €ì¥ ìœ„ì¹˜\")  # ìµœì¢… 1ê°œ TXT\n",
    "\n",
    "SRT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TXT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ì •ë ¬ëœ ì²­í¬ ëª©ë¡\n",
    "chunk_files = sorted(CHUNK_DIR.glob(\"chunk_*.wav\"))\n",
    "assert chunk_files, f\"ì²­í¬ wavê°€ ì—†ìŠµë‹ˆë‹¤: {CHUNK_DIR}\"\n",
    "print(f\"ì²­í¬ {len(chunk_files)}ê°œ ë°œê²¬\")\n",
    "for p in chunk_files:\n",
    "    print(\" -\", p.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f257a0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# ì´ê³³ì— open ai api key ì…ë ¥\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"Open AI API Key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8ec624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "for i, cp in enumerate(chunk_files, 1):\n",
    "    size_mb = cp.stat().st_size / (1024*1024)\n",
    "    print(f\"â–¶ï¸ {i}/{len(chunk_files)} SRT ì „ì‚¬: {cp.name} ({size_mb:.2f} MB)\")\n",
    "    with cp.open(\"rb\") as f:\n",
    "        srt_text = client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\",\n",
    "            file=f,\n",
    "            language=\"ko\",     # í•œêµ­ì–´ ê³ ì • ì›í•˜ë©´ ì£¼ì„ í•´ì œ\n",
    "            response_format=\"srt\"\n",
    "        )\n",
    "    (SRT_DIR / f\"{cp.stem}.srt\").write_text(srt_text, encoding=\"utf-8\")\n",
    "print(\"âœ… ëª¨ë“  ì²­í¬ SRT ì „ì‚¬ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6766afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from datetime import timedelta\n",
    "import re\n",
    "\n",
    "# ---------- ìœ í‹¸: ì‹œê°„ ë³€í™˜ ----------\n",
    "def ms_to_srt_time(ms:int)->str:\n",
    "    td = timedelta(milliseconds=ms)\n",
    "    hours, rem = divmod(td.seconds, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    hours += td.days * 24\n",
    "    millis = int(ms % 1000)\n",
    "    return f\"{hours:02d}:{minutes:02d}:{seconds:02d}.{millis:03d}\"\n",
    "\n",
    "def srt_time_to_ms(t:str)->int:\n",
    "    # SRT: \"HH:MM:SS,mmm\"\n",
    "    h, m, rest = t.split(\":\")\n",
    "    s, ms = rest.split(\",\")\n",
    "    return (int(h)*3600 + int(m)*60 + int(s))*1000 + int(ms)\n",
    "\n",
    "# ---------- ìœ í‹¸: SRT íŒŒì„œ ----------\n",
    "# \"00:00:01,000 --> 00:00:04,000\" ì¤„ê³¼ ë³¸ë¬¸ì„ cueë¡œ íŒŒì‹±\n",
    "re_time = re.compile(r\"(\\d\\d:\\d\\d:\\d\\d,\\d\\d\\d)\\s*-->\\s*(\\d\\d:\\d\\d:\\d\\d,\\d\\d\\d)\")\n",
    "\n",
    "def parse_srt(srt_text:str):\n",
    "    lines = [ln.rstrip(\"\\n\") for ln in srt_text.splitlines()]\n",
    "    cues = []\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i].strip()\n",
    "        # ë²ˆí˜¸ ë¼ì¸(ìˆì„ ìˆ˜ë„ ì—†ìŒ)\n",
    "        if line.isdigit():\n",
    "            i += 1\n",
    "            if i >= len(lines): break\n",
    "            line = lines[i].strip()\n",
    "        # ì‹œê°„ ë¼ì¸\n",
    "        m = re_time.match(line)\n",
    "        if not m:\n",
    "            i += 1\n",
    "            continue\n",
    "        start, end = m.group(1), m.group(2)\n",
    "        i += 1\n",
    "        # ë³¸ë¬¸\n",
    "        text_lines = []\n",
    "        while i < len(lines) and lines[i].strip():\n",
    "            text_lines.append(lines[i])\n",
    "            i += 1\n",
    "        cues.append((start, end, \"\\n\".join(text_lines)))\n",
    "        # ë¹ˆ ì¤„ ìŠ¤í‚µ\n",
    "        while i < len(lines) and not lines[i].strip():\n",
    "            i += 1\n",
    "    return cues\n",
    "\n",
    "# ---------- 1) ì²­í¬ ëˆ„ì  ì˜¤í”„ì…‹ ê³„ì‚° ----------\n",
    "offsets = []\n",
    "acc = 0\n",
    "for cp in chunk_files:\n",
    "    offsets.append(acc)\n",
    "    dur_ms = len(AudioSegment.from_file(cp))\n",
    "    acc += dur_ms\n",
    "print(\"ëˆ„ì  ì˜¤í”„ì…‹(ms):\", offsets)\n",
    "\n",
    "# ---------- 2) ì²­í¬ë³„ TXT ìƒì„± + ìµœì¢… ë³‘í•© ----------\n",
    "all_lines = []\n",
    "for idx, cp in enumerate(chunk_files):\n",
    "    srt_path = SRT_DIR / f\"{cp.stem}.srt\"\n",
    "    assert srt_path.exists(), f\"SRT ì—†ìŒ: {srt_path}\"\n",
    "    srt_text = srt_path.read_text(encoding=\"utf-8\")\n",
    "    cues = parse_srt(srt_text)\n",
    "    off = offsets[idx]\n",
    "\n",
    "    # ì²­í¬ë³„ TXT(ì˜µì…˜)\n",
    "    per_chunk_txt = []\n",
    "    for (st, et, text) in cues:\n",
    "        st_ms = srt_time_to_ms(st) + off\n",
    "        et_ms = srt_time_to_ms(et) + off\n",
    "        one_line = f\"[{ms_to_srt_time(st_ms)} - {ms_to_srt_time(et_ms)}] {text.replace('\\n',' ')}\"\n",
    "        per_chunk_txt.append(one_line)\n",
    "        all_lines.append(one_line)\n",
    "\n",
    "    (TXT_DIR / f\"{cp.stem}.txt\").write_text(\"\\n\".join(per_chunk_txt), encoding=\"utf-8\")\n",
    "    print(f\"âœ… ì²­í¬ TXT ì €ì¥: {(TXT_DIR / f'{cp.stem}.txt').name}\")\n",
    "\n",
    "# ìµœì¢… ë³‘í•©ë³¸ ì €ì¥\n",
    "FINAL_TXT.write_text(\"\\n\".join(all_lines), encoding=\"utf-8\")\n",
    "print(f\"ğŸ¯ ìµœì¢… íƒ€ì„ìŠ¤íƒ¬í”„ TXT ë³‘í•© ì™„ë£Œ â†’ {FINAL_TXT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67672e94",
   "metadata": {},
   "source": [
    "#í›„ì²˜ë¦¬ - ì¤‘ë³µ ë¬¸ì¥ ì œê±°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfd8be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "from typing import List, Tuple\n",
    "\n",
    "# ====== ê²½ë¡œ ì„¤ì • ======\n",
    "INPUT_TXT = Path(\"ì…ë ¥ íŒŒì¼ ìœ„ì¹˜\")  # ì…ë ¥\n",
    "OUTPUT_TXT = Path(\"ì¶œë ¥ íŒŒì¼ ìœ„ì¹˜\")  # ì¶œë ¥\n",
    "\n",
    "assert INPUT_TXT.exists(), f\"ì…ë ¥ íŒŒì¼ ì—†ìŒ: {INPUT_TXT}\"\n",
    "\n",
    "# ====== ë¼ì¸ íŒŒì„œ: [HH:MM:SS.mmm - HH:MM:SS.mmm] í…ìŠ¤íŠ¸ ======\n",
    "re_line = re.compile(\n",
    "    r\"^\\[(\\d{2}:\\d{2}:\\d{2}\\.\\d{3})\\s*-\\s*(\\d{2}:\\d{2}:\\d{2}\\.\\d{3})\\]\\s*(.*)$\"\n",
    ")\n",
    "\n",
    "def parse_line(line: str) -> Tuple[str, str, str]:\n",
    "    m = re_line.match(line.strip())\n",
    "    if not m:\n",
    "        # í˜•ì‹ì—ì„œ ë²—ì–´ë‚œ ë¼ì¸ì€ ë‚´ìš© ì „ì²´ë¥¼ textë¡œ ê°„ì£¼(íƒ€ì„ìŠ¤íƒ¬í”„ëŠ” ë¹ˆ ê°’)\n",
    "        return (\"\", \"\", line.strip())\n",
    "    return m.group(1), m.group(2), m.group(3)\n",
    "\n",
    "# ====== ì •ê·œí™” ìœ í‹¸ ======\n",
    "def normalize_text(s: str) -> str:\n",
    "    # ê³µë°± ì •ë¦¬ + ë ê³µë°± ì œê±°\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# ====== ë¼ì¸ ë‚´ë¶€ ì¤‘ë³µ ì¶•ì•½ ======\n",
    "def collapse_sentence_runs(text: str) -> str:\n",
    "    \"\"\"\n",
    "    ë¬¸ì¥ë¶€í˜¸ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì¥ì„ ë‚˜ëˆ  ì—°ì† ë™ì¼ ë¬¸ì¥ ì¤‘ë³µì„ 1íšŒë¡œ ì¶•ì•½.\n",
    "    \"\"\"\n",
    "    # ë¬¸ì¥ ë‹¨ìœ„ ë¶„ë¦¬(êµ¬ë‘ì  ìœ ì§€)\n",
    "    parts = re.split(r\"([\\.!\\?â€¦]+)\", text)\n",
    "    # parts = [frag, punct, frag, punct, ... , last_frag?]\n",
    "    merged = []\n",
    "    last_sent_norm = None\n",
    "\n",
    "    i = 0\n",
    "    while i < len(parts):\n",
    "        frag = parts[i].strip()\n",
    "        punct = parts[i+1] if i+1 < len(parts) else \"\"\n",
    "        sent = (frag + punct).strip()\n",
    "        if sent:\n",
    "            curr_norm = normalize_text(frag.lower())\n",
    "            if curr_norm != last_sent_norm:\n",
    "                merged.append(sent)\n",
    "                last_sent_norm = curr_norm\n",
    "            # ë™ì¼ ë¬¸ì¥ ì—°ì†ì´ë©´ skip\n",
    "        i += 2\n",
    "    return normalize_text(\" \".join(merged))\n",
    "\n",
    "def collapse_word_runs(text: str) -> str:\n",
    "    \"\"\"\n",
    "    ê°™ì€ ë‹¨ì–´ê°€ ì—°ì†ìœ¼ë¡œ ë°˜ë³µë  ë•Œ 1íšŒë¡œ ì¶•ì•½.\n",
    "    (ê³µë°± ê¸°ì¤€ ë‹¨ìˆœ í† í°í™”; í•œêµ­ì–´ ë„ì–´ì“°ê¸° ê¸°ì¤€)\n",
    "    \"\"\"\n",
    "    toks = text.split()\n",
    "    out = []\n",
    "    last = None\n",
    "    for t in toks:\n",
    "        if last is None or t != last:\n",
    "            out.append(t)\n",
    "            last = t\n",
    "        # ë™ì¼ í† í°ì´ë©´ skip\n",
    "    return \" \".join(out)\n",
    "\n",
    "def dedup_inside_line(text: str) -> str:\n",
    "    # 1) ë¬¸ì¥ ë°˜ë³µ ì¶•ì•½ â†’ 2) ë‹¨ì–´ ë°˜ë³µ ì¶•ì•½ â†’ 3) ê³µë°± ì •ë¦¬\n",
    "    s = collapse_sentence_runs(text)\n",
    "    s = collapse_word_runs(s)\n",
    "    s = normalize_text(s)\n",
    "    return s\n",
    "\n",
    "# ====== íŒŒì¼ ë¡œë“œ & íŒŒì‹± ======\n",
    "raw_lines = INPUT_TXT.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines()\n",
    "entries = []\n",
    "for ln in raw_lines:\n",
    "    st, et, tx = parse_line(ln)\n",
    "    tx = dedup_inside_line(tx)\n",
    "    entries.append({\"start\": st, \"end\": et, \"text\": tx})\n",
    "\n",
    "# ====== ë¼ì¸ ê°„ ì¤‘ë³µ/í¬í•¨ ì œê±° ======\n",
    "def norm_for_compare(s: str) -> str:\n",
    "    # ë¹„êµìš© ë…¸ë©€ë¼ì´ì¦ˆ(ì†Œë¬¸ì/ê³µë°± ì •ë¦¬/ë¬¸ì¥ ë ì  í•˜ë‚˜ë¡œ í†µì¼)\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    s = re.sub(r\"(\\.){2,}$\", \".\", s)  # ë ì  ì—°ì†ì€ 1ê°œë¡œ\n",
    "    return s\n",
    "\n",
    "kept = []\n",
    "removed = 0\n",
    "\n",
    "for i, cur in enumerate(entries):\n",
    "    cur_txt = cur[\"text\"]\n",
    "    if not cur_txt:\n",
    "        # ë¹ˆ í…ìŠ¤íŠ¸ëŠ” ì œê±°\n",
    "        removed += 1\n",
    "        continue\n",
    "\n",
    "    cur_norm = norm_for_compare(cur_txt)\n",
    "\n",
    "    # ë¯¸ë¦¬ ë‹¤ìŒ ë¼ì¸ í…ìŠ¤íŠ¸ë¥¼ í™•ì¸(í˜„ì¬ê°€ ë” ì§§ê³  í¬í•¨ë˜ë©´ ì§€ê¸ˆ ì‚­ì œ)\n",
    "    next_norm = None\n",
    "    if i + 1 < len(entries):\n",
    "        nxt_txt = entries[i+1][\"text\"]\n",
    "        next_norm = norm_for_compare(nxt_txt) if nxt_txt else None\n",
    "\n",
    "    # ê·œì¹™ 2-1) í˜„ì¬ âŠ† ë‹¤ìŒ(ë˜ëŠ” ë™ì¼) ì´ê³  í˜„ì¬ ê¸¸ì´ <= ë‹¤ìŒì´ë©´ í˜„ì¬ ì‚­ì œ\n",
    "    if next_norm and cur_norm and (cur_norm == next_norm or cur_norm in next_norm):\n",
    "        if len(cur_norm) <= len(next_norm):\n",
    "            removed += 1\n",
    "            continue  # drop current, keep next\n",
    "\n",
    "    # ì´ì „ê³¼ ë¹„êµ (keptì˜ ë§ˆì§€ë§‰ê³¼ë§Œ ë¹„êµ)\n",
    "    if kept:\n",
    "        prev = kept[-1]\n",
    "        prev_norm = norm_for_compare(prev[\"text\"])\n",
    "\n",
    "        # ë™ì¼/í¬í•¨ ê´€ê³„ â†’ ì§§ì€ ìª½ ì‚­ì œ, ê°™ìœ¼ë©´ ë’¤ìª½(í˜„ì¬) ì‚­ì œ\n",
    "        if cur_norm == prev_norm:\n",
    "            removed += 1\n",
    "            continue  # drop current (ë’¤ìª½)\n",
    "        if cur_norm in prev_norm:\n",
    "            removed += 1\n",
    "            continue  # current ë” ì§§ìŒ â†’ drop current\n",
    "        if prev_norm in cur_norm:\n",
    "            # prev ë” ì§§ìŒ â†’ prev ì‚­ì œ, current ì±„íƒ\n",
    "            kept.pop()\n",
    "            kept.append(cur)\n",
    "            continue\n",
    "\n",
    "    # ì—¬ê¸°ê¹Œì§€ ì™”ìœ¼ë©´ ì±„íƒ\n",
    "    kept.append(cur)\n",
    "\n",
    "# ====== ì €ì¥ ======\n",
    "out_lines = []\n",
    "for e in kept:\n",
    "    st = e[\"start\"] or \"00:00:00.000\"\n",
    "    et = e[\"end\"] or \"00:00:00.000\"\n",
    "    out_lines.append(f\"[{st} - {et}] {e['text']}\")\n",
    "\n",
    "OUTPUT_TXT.write_text(\"\\n\".join(out_lines), encoding=\"utf-8\")\n",
    "\n",
    "print(f\"ì…ë ¥ ë¼ì¸ ìˆ˜: {len(entries)}\")\n",
    "print(f\"ì œê±° ë¼ì¸ ìˆ˜: {removed}\")\n",
    "print(f\"ë‚¨ì€ ë¼ì¸ ìˆ˜: {len(kept)}\")\n",
    "print(f\"âœ… ì €ì¥ ì™„ë£Œ â†’ {OUTPUT_TXT}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
