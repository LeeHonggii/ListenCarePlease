# ListenCarePlease - ì™„ì „ ê°€ì´ë“œ

> ğŸ™ï¸ AI ê¸°ë°˜ íšŒì˜ë¡ ìë™ ìƒì„± ë° í™”ì íƒœê¹… ì‹œìŠ¤í…œ - ì „ì²´ êµ¬ì¡° ë¬¸ì„œ

**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-11-27
**ë²„ì „**: 1.0

---

## ğŸ“‘ ëª©ì°¨

1. [í”„ë¡œì íŠ¸ ê°œìš”](#1-í”„ë¡œì íŠ¸-ê°œìš”)
2. [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#2-ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
3. [ê¸°ìˆ  ìŠ¤íƒ](#3-ê¸°ìˆ -ìŠ¤íƒ)
4. [ì „ì²´ íŒŒì´í”„ë¼ì¸](#4-ì „ì²´-íŒŒì´í”„ë¼ì¸)
5. [ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡°](#5-ë°ì´í„°ë² ì´ìŠ¤-êµ¬ì¡°)
6. [ë°±ì—”ë“œ ìƒì„¸](#6-ë°±ì—”ë“œ-ìƒì„¸)
7. [í”„ë¡ íŠ¸ì—”ë“œ ìƒì„¸](#7-í”„ë¡ íŠ¸ì—”ë“œ-ìƒì„¸)
8. [ì£¼ìš” ê¸°ëŠ¥](#8-ì£¼ìš”-ê¸°ëŠ¥)
9. [API ë¬¸ì„œ](#9-api-ë¬¸ì„œ)
10. [ë°°í¬ ë° ìš´ì˜](#10-ë°°í¬-ë°-ìš´ì˜)
11. [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#11-íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)

---

## 1. í”„ë¡œì íŠ¸ ê°œìš”

### 1.1 í”„ë¡œì íŠ¸ ì†Œê°œ

ListenCarePleaseëŠ” íšŒì˜ ë…¹ìŒ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ í™”ìë¥¼ ë¶„ë¦¬í•˜ê³ , ì´ë¦„ì„ íƒœê¹…í•˜ì—¬ ì •í™•í•œ íšŒì˜ë¡ì„ ìƒì„±í•˜ëŠ” AI ê¸°ë°˜ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.

**í•µì‹¬ ê°€ì¹˜**:
- â±ï¸ **ì‹œê°„ ì ˆì•½**: ìˆ˜ë™ íšŒì˜ë¡ ì‘ì„± ì‹œê°„ 90% ë‹¨ì¶•
- ğŸ¯ **ì •í™•ì„±**: í™”ì ì¸ì‹ ì •í™•ë„ 90% ì´ìƒ (DER < 10%)
- ğŸ¤– **ìë™í™”**: STT â†’ í™”ì ë¶„ë¦¬ â†’ ì´ë¦„ íƒœê¹… â†’ ìš”ì•½ ì „ ê³¼ì • ìë™í™”
- ğŸ’¡ **ì¸ì‚¬ì´íŠ¸**: íšŒì˜ íš¨ìœ¨ì„± ë¶„ì„ ë° AI ê¸°ë°˜ ìš”ì•½ ì œê³µ

### 1.2 ì£¼ìš” ê¸°ëŠ¥

#### 1ï¸âƒ£ ìŒì„± íŒŒì¼ ì²˜ë¦¬
- ë‹¤ì–‘í•œ í¬ë§· ì§€ì› (mp3, m4a, wav ë“±)
- ìë™ ì „ì²˜ë¦¬ (VAD, ë…¸ì´ì¦ˆ ì œê±°)
- GPU ê°€ì† ì§€ì› (CUDA 11.8)

#### 2ï¸âƒ£ STT (Speech-to-Text)
- Whisper large-v3 ëª¨ë¸ ì‚¬ìš©
- ë‹¨ì–´ ë ˆë²¨ íƒ€ì„ìŠ¤íƒ¬í”„ ì œê³µ
- ë¡œì»¬ ëª¨ë¸ + OpenAI API ì§€ì›

#### 3ï¸âƒ£ í™”ì ë¶„ë¦¬ (Diarization)
- Senko (pyannote.audio ê¸°ë°˜)
- ìŒì„± ì„ë² ë”© ì¶”ì¶œ (192ì°¨ì›)
- ìë™ í™”ì ë§¤ì¹­ (ìœ ì‚¬ë„ ê¸°ë°˜)

#### 4ï¸âƒ£ í™”ì íƒœê¹… (LangGraph Agent)
- **ë°©ì‹ 1**: ì´ë¦„ ê¸°ë°˜ íƒœê¹… (NER + ë©€í‹°í„´ LLM)
- **ë°©ì‹ 2**: ì—­í•  ê¸°ë°˜ íƒœê¹… (ë°œí™” íŒ¨í„´ ë¶„ì„)
- ë‹‰ë„¤ì„ ìë™ ìƒì„± (ì—­í• /íŠ¹ì§• ê¸°ë°˜)
- í™”ì í”„ë¡œí•„ ì €ì¥ ë° ì¬ì‚¬ìš©

#### 5ï¸âƒ£ íšŒì˜ íš¨ìœ¨ì„± ë¶„ì„
- **5ê°€ì§€ ì§€í‘œ**: ì—”íŠ¸ë¡œí”¼, TTR, ì •ë³´ëŸ‰, ë¬¸ì¥ í™•ë¥ , PPL
- **AI ì¸ì‚¬ì´íŠ¸**: GPT-4o-mini ê¸°ë°˜ ì½”ë©˜í„°ë¦¬
- í™”ìë³„ + ì „ì²´ íšŒì˜ ë¶„ì„

#### 6ï¸âƒ£ RAG (Retrieval-Augmented Generation)
- ChromaDB ë²¡í„° ì €ì¥ì†Œ
- í™”ì í•„í„°ë§ ì§€ì›
- ìì—°ì–´ ì§ˆì˜ì‘ë‹µ

#### 7ï¸âƒ£ ì¶”ê°€ ê¸°ëŠ¥
- Todo ìë™ ì¶”ì¶œ
- íšŒì˜ ìš”ì•½ (êµ¬í˜„ ì˜ˆì •)
- ìë§‰ ìƒì„± (êµ¬í˜„ ì˜ˆì •)

---

## 2. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### 2.1 ì „ì²´ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ì‚¬ìš©ì    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Frontend (React)               â”‚
â”‚  - TailwindCSS, Vite                   â”‚
â”‚  - ë‹¤í¬ëª¨ë“œ, ì¸ì¦, ë¼ìš°íŒ…               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ HTTP/REST API
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Backend (FastAPI)               â”‚
â”‚  - 8ê°œ API ë¼ìš°í„°                       â”‚
â”‚  - JWT ì¸ì¦, OAuth 2.0                  â”‚
â”‚  - BackgroundTasks (ë¹„ë™ê¸° ì²˜ë¦¬)        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚
       â†“              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MySQL     â”‚  â”‚   AI/ML Services     â”‚
â”‚   8.0       â”‚  â”‚  - Whisper (STT)    â”‚
â”‚             â”‚  â”‚  - Senko (í™”ì ë¶„ë¦¬) â”‚
â”‚  - 10ê°œ     â”‚  â”‚  - LangGraph (Agent)â”‚
â”‚    í…Œì´ë¸”   â”‚  â”‚  - GPT-4o (LLM)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  - ChromaDB (RAG)   â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Docker êµ¬ì„±

```yaml
services:
  frontend:
    - React + Vite
    - Port: 3000
    - í•« ë¦¬ë¡œë“œ ì§€ì›

  backend:
    - FastAPI + Uvicorn
    - Port: 8000
    - GPU ì§€ì› (CUDA 11.8)
    - ë³¼ë¥¨: /app/uploads

  mysql:
    - MySQL 8.0
    - Port: 3306
    - ë³¼ë¥¨: ë°ì´í„° ì˜ì†ì„±
```

### 2.3 ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
ListenCarePlease/
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/        # ì¬ì‚¬ìš© ì»´í¬ë„ŒíŠ¸
â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard/
â”‚   â”‚   â”‚   â”œâ”€â”€ FileUpload/
â”‚   â”‚   â”‚   â””â”€â”€ Layout/
â”‚   â”‚   â”œâ”€â”€ pages/            # í˜ì´ì§€ (13ê°œ)
â”‚   â”‚   â”œâ”€â”€ contexts/         # ì¸ì¦, í…Œë§ˆ
â”‚   â”‚   â””â”€â”€ services/         # API í´ë¼ì´ì–¸íŠ¸
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/v1/           # API ë¼ìš°í„° (8ê°œ)
â”‚   â”‚   â”œâ”€â”€ agents/           # LangGraph Agent
â”‚   â”‚   â”‚   â”œâ”€â”€ nodes/        # 7ê°œ ë…¸ë“œ
â”‚   â”‚   â”‚   â”œâ”€â”€ tools/        # 4ê°œ ë„êµ¬
â”‚   â”‚   â”‚   â””â”€â”€ prompts/      # LLM í”„ë¡¬í”„íŠ¸
â”‚   â”‚   â”œâ”€â”€ models/           # DB ëª¨ë¸ (10ê°œ)
â”‚   â”‚   â”œâ”€â”€ services/         # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ (10ê°œ)
â”‚   â”‚   â”œâ”€â”€ core/             # ì„¤ì •, ë³´ì•ˆ
â”‚   â”‚   â””â”€â”€ db/               # DB ì—°ê²°
â”‚   â”œâ”€â”€ alembic/              # ë§ˆì´ê·¸ë ˆì´ì…˜
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ docs/                     # ë¬¸ì„œ (7ê°œ)
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ .env
```

---

## 3. ê¸°ìˆ  ìŠ¤íƒ

### 3.1 Frontend

| ì¹´í…Œê³ ë¦¬ | ê¸°ìˆ  | ìš©ë„ |
|---------|------|------|
| **í”„ë ˆì„ì›Œí¬** | React 18 | UI ë¼ì´ë¸ŒëŸ¬ë¦¬ |
| **ë¹Œë“œ ë„êµ¬** | Vite | ë¹ ë¥¸ ê°œë°œ ì„œë²„ |
| **ìŠ¤íƒ€ì¼ë§** | TailwindCSS | ìœ í‹¸ë¦¬í‹° CSS |
| **ë¼ìš°íŒ…** | React Router v6 | SPA ë¼ìš°íŒ… |
| **ìƒíƒœ ê´€ë¦¬** | Context API | ì¸ì¦, í…Œë§ˆ ê´€ë¦¬ |
| **HTTP í´ë¼ì´ì–¸íŠ¸** | Axios | API í†µì‹  |
| **ì°¨íŠ¸** | Chart.js | ë°ì´í„° ì‹œê°í™” |

### 3.2 Backend

| ì¹´í…Œê³ ë¦¬ | ê¸°ìˆ  | ìš©ë„ |
|---------|------|------|
| **í”„ë ˆì„ì›Œí¬** | FastAPI | ë¹„ë™ê¸° ì›¹ í”„ë ˆì„ì›Œí¬ |
| **ORM** | SQLAlchemy | DB ORM |
| **ë§ˆì´ê·¸ë ˆì´ì…˜** | Alembic | DB ë²„ì „ ê´€ë¦¬ |
| **ì¸ì¦** | JWT + OAuth 2.0 | í•˜ì´ë¸Œë¦¬ë“œ ì¸ì¦ |
| **ë¹„ë™ê¸°** | BackgroundTasks | ì¥ì‹œê°„ ì‘ì—… ì²˜ë¦¬ |

### 3.3 AI/ML

| ì¹´í…Œê³ ë¦¬ | ëª¨ë¸/ë¼ì´ë¸ŒëŸ¬ë¦¬ | ìš©ë„ |
|---------|----------------|------|
| **STT** | Whisper large-v3 | ìŒì„± â†’ í…ìŠ¤íŠ¸ |
| **í™”ì ë¶„ë¦¬** | Senko (pyannote.audio) | í™”ì êµ¬ë¶„ |
| **NER** | korean-pii-masking | ì´ë¦„ ì¶”ì¶œ |
| **LLM** | GPT-4o, GPT-4o-mini | í™”ì íƒœê¹…, ì¸ì‚¬ì´íŠ¸ |
| **ì—ì´ì „íŠ¸** | LangChain, LangGraph | ì›Œí¬í”Œë¡œìš° ìë™í™” |
| **ì„ë² ë”©** | Sentence Transformers | ì˜ë¯¸ì  ìœ ì‚¬ë„ |
| **í˜•íƒœì†Œ ë¶„ì„** | Mecab | í•œêµ­ì–´ í† í°í™” |
| **ì–¸ì–´ ëª¨ë¸** | KoGPT-2 | Perplexity ê³„ì‚° |
| **êµ°ì§‘í™”** | HDBSCAN | ì´ìƒì¹˜ íƒì§€ |
| **ë²¡í„° DB** | ChromaDB | RAG ì‹œìŠ¤í…œ |

### 3.4 ë°ì´í„°ë² ì´ìŠ¤

- **RDBMS**: MySQL 8.0
- **Vector DB**: ChromaDB (ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œ)

### 3.5 DevOps

- **ì»¨í…Œì´ë„ˆ**: Docker, Docker Compose
- **GPU**: CUDA 11.8, PyTorch 2.1.0
- **ëª¨ë‹ˆí„°ë§**: LangSmith (Agent ì¶”ì )

---

## 4. ì „ì²´ íŒŒì´í”„ë¼ì¸

### 4.1 ì‚¬ìš©ì í”Œë¡œìš°

```
1. ë¡œê·¸ì¸/íšŒì›ê°€ì…
   â†“
2. íŒŒì¼ ì—…ë¡œë“œ
   - ë“œë˜ê·¸ì•¤ë“œë¡­ ë˜ëŠ” íŒŒì¼ ì„ íƒ
   â†“
3. í”„ë¡œì„¸ì‹± (ìë™)
   - STT (Whisper)
   - í™”ì ë¶„ë¦¬ (Senko)
   - NER (ì´ë¦„ ì¶”ì¶œ)
   - ë‹‰ë„¤ì„ ìƒì„±
   â†“
4. í™”ì ì •ë³´ í™•ì¸
   - í™”ì ìˆ˜ í™•ì¸/ìˆ˜ì •
   - ê°ì§€ëœ ì´ë¦„ í™•ì¸/ìˆ˜ì •
   - ê°ì§€ëœ ë‹‰ë„¤ì„ í™•ì¸/ìˆ˜ì •
   â†“
5. AI ë¶„ì„ ì¤‘ (LangGraph)
   - ë©€í‹°í„´ LLM í™”ì ë¶„ì„
   - ìŒì„±/í…ìŠ¤íŠ¸ ì„ë² ë”© ë§¤ì¹­
   â†“
6. í™”ì íƒœê¹…
   - ì‹œìŠ¤í…œ ì œì•ˆ í™•ì¸
   - ìˆ˜ì • ë° í™•ì •
   â†“
7. íš¨ìœ¨ì„± ë¶„ì„ (ìë™)
   - 5ê°€ì§€ ì§€í‘œ ê³„ì‚°
   - AI ì¸ì‚¬ì´íŠ¸ ìƒì„±
   â†“
8. ê²°ê³¼ í˜ì´ì§€
   - íšŒì˜ë¡ í‘œì‹œ
   - í†µê³„ í™•ì¸
   â†“
9. ë‹¤ìŒ ë‹¨ê³„ ì„ íƒ
   - RAG ëŒ€í™”
   - Todo í™•ì¸
   - íš¨ìœ¨ì„± ë¶„ì„
```

### 4.2 ë°ì´í„° íŒŒì´í”„ë¼ì¸

```
[Audio File]
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Preprocessing       â”‚
â”‚  - VAD                  â”‚
â”‚  - ë…¸ì´ì¦ˆ ì œê±°          â”‚
â”‚  - ìƒ˜í”Œë ˆì´íŠ¸ ì •ê·œí™”    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. STT (Whisper)       â”‚
â”‚  - ìŒì„± â†’ í…ìŠ¤íŠ¸        â”‚
â”‚  - íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Diarization (Senko) â”‚
â”‚  - í™”ì ë¶„ë¦¬            â”‚
â”‚  - ì„ë² ë”© ì¶”ì¶œ          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. NER + Nickname      â”‚
â”‚  - ì´ë¦„ ì¶”ì¶œ (BERT)     â”‚
â”‚  - ë‹‰ë„¤ì„ ìƒì„± (GPT-4)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. Agent (LangGraph)   â”‚
â”‚  - ì„ë² ë”© ë§¤ì¹­          â”‚
â”‚  - ì´ë¦„ ê¸°ë°˜ íƒœê¹…       â”‚
â”‚  - ì—­í•  ê¸°ë°˜ íƒœê¹…       â”‚
â”‚  - ê²°ê³¼ ë³‘í•©            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. User Confirmation   â”‚
â”‚  - ì œì•ˆ ê²€í†             â”‚
â”‚  - ìˆ˜ì • ë° í™•ì •         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  7. Final Transcript    â”‚
â”‚  - ìµœì¢… íšŒì˜ë¡ ìƒì„±     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  8. Applications        â”‚
â”‚  - íš¨ìœ¨ì„± ë¶„ì„          â”‚
â”‚  - RAG                  â”‚
â”‚  - Todo ì¶”ì¶œ            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5. ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡°

### 5.1 ERD

```
users (ì¸ì¦)
  â””â”€â”¬â”€ audio_files (íŒŒì¼ ë©”íƒ€ë°ì´í„°)
    â”œâ”€â”€â”€ preprocessing_results (ì „ì²˜ë¦¬)
    â”œâ”€â”€â”€ stt_results (STT)
    â”œâ”€â”€â”€ diarization_results (í™”ì ë¶„ë¦¬)
    â”œâ”€â”€â”€ detected_names (ì´ë¦„ ê°ì§€)
    â”œâ”€â”€â”€ speaker_mappings (í™”ì ë§¤í•‘)
    â”œâ”€â”€â”€ user_confirmation (ì‚¬ìš©ì í™•ì •)
    â”œâ”€â”€â”€ final_transcripts (ìµœì¢… íšŒì˜ë¡)
    â”œâ”€â”€â”€ meeting_efficiency_analysis (íš¨ìœ¨ì„± ë¶„ì„)
    â””â”€â”€â”€ todos (í• ì¼ ì¶”ì¶œ)
```

### 5.2 ì£¼ìš” í…Œì´ë¸”

#### users
```sql
CREATE TABLE users (
  id INT PRIMARY KEY AUTO_INCREMENT,
  email VARCHAR(255) UNIQUE NOT NULL,
  hashed_password VARCHAR(255),  -- NULL í—ˆìš© (OAuth ì „ìš© ì‚¬ìš©ì)
  full_name VARCHAR(255),
  is_active BOOLEAN DEFAULT TRUE,
  oauth_provider ENUM('google', 'kakao', 'github'),
  oauth_id VARCHAR(255),
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP
);
```

#### audio_files
```sql
CREATE TABLE audio_files (
  id INT PRIMARY KEY AUTO_INCREMENT,
  file_id VARCHAR(36) UNIQUE NOT NULL,  -- UUID
  user_id INT NOT NULL,
  original_filename VARCHAR(255),
  file_path VARCHAR(512),
  file_size BIGINT,
  duration FLOAT,
  status ENUM('UPLOADING', 'PREPROCESSING', 'PROCESSING',
              'COMPLETED', 'FAILED', 'CONFIRMED'),

  -- RAG ìƒíƒœ
  rag_collection_name VARCHAR(255),
  rag_initialized BOOLEAN DEFAULT FALSE,
  rag_initialized_at DATETIME,

  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  updated_at DATETIME ON UPDATE CURRENT_TIMESTAMP,

  FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE
);
```

#### speaker_mappings
```sql
CREATE TABLE speaker_mappings (
  id INT PRIMARY KEY AUTO_INCREMENT,
  audio_file_id INT NOT NULL,
  speaker_label VARCHAR(50) NOT NULL,  -- SPEAKER_00, SPEAKER_01, ...

  -- ì‹œìŠ¤í…œ ì œì•ˆ
  suggested_name VARCHAR(100),
  nickname VARCHAR(100),
  nickname_metadata JSON,
  name_confidence FLOAT,
  name_mentions INT DEFAULT 0,

  -- í”Œë˜ê·¸
  conflict_detected BOOLEAN DEFAULT FALSE,
  needs_manual_review BOOLEAN DEFAULT FALSE,
  auto_matched BOOLEAN DEFAULT FALSE,

  -- ì‚¬ìš©ì í™•ì •
  final_name VARCHAR(100),
  is_modified BOOLEAN DEFAULT FALSE,

  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,

  FOREIGN KEY (audio_file_id) REFERENCES audio_files(id) ON DELETE CASCADE,
  UNIQUE KEY (audio_file_id, speaker_label)
);
```

#### meeting_efficiency_analysis
```sql
CREATE TABLE meeting_efficiency_analysis (
  id INT PRIMARY KEY AUTO_INCREMENT,
  audio_file_id INT UNIQUE NOT NULL,

  -- ì „ì²´ íšŒì˜ ì§€í‘œ
  entropy_values JSON,
  entropy_avg FLOAT,
  entropy_std FLOAT,
  overall_ttr JSON,
  overall_information_content JSON,
  overall_sentence_probability JSON,
  overall_perplexity JSON,

  -- í™”ìë³„ ì§€í‘œ
  speaker_metrics JSON NOT NULL,

  -- ë©”íƒ€ë°ì´í„°
  total_speakers INT NOT NULL,
  total_turns INT NOT NULL,
  total_sentences INT NOT NULL,
  analysis_version VARCHAR(20) DEFAULT '1.0',
  analyzed_at DATETIME DEFAULT CURRENT_TIMESTAMP,

  FOREIGN KEY (audio_file_id) REFERENCES audio_files(id) ON DELETE CASCADE
);
```

---

## 6. ë°±ì—”ë“œ ìƒì„¸

### 6.1 API ë¼ìš°í„° (8ê°œ)

#### 1. auth.py - ì¸ì¦
```python
POST /api/v1/auth/register
  - ì´ë©”ì¼/ë¹„ë°€ë²ˆí˜¸ íšŒì›ê°€ì…

POST /api/v1/auth/login
  - ë¡œê·¸ì¸ (JWT í† í° ë°œê¸‰)

POST /api/v1/auth/refresh
  - Access Token ê°±ì‹ 
```

#### 2. oauth.py - OAuth 2.0
```python
GET /api/v1/oauth/google
  - Google OAuth ì‹œì‘

GET /api/v1/oauth/google/callback
  - Google OAuth ì½œë°±

GET /api/v1/oauth/kakao
GET /api/v1/oauth/kakao/callback
  - Kakao OAuth
```

#### 3. upload.py - íŒŒì¼ ì—…ë¡œë“œ
```python
POST /api/v1/upload
  - ë©€í‹°íŒŒíŠ¸ íŒŒì¼ ì—…ë¡œë“œ
  - ì…ë ¥: multipart/form-data
  - ì¶œë ¥: {file_id, message}
```

#### 4. processing.py - AI ì²˜ë¦¬
```python
POST /api/v1/process/{file_id}
  - STT + Diarization + NER + Nickname ì‹¤í–‰
  - íŒŒë¼ë¯¸í„°: whisper_mode, diarization_mode
  - BackgroundTasksë¡œ ë¹„ë™ê¸° ì²˜ë¦¬

GET /api/v1/status/{file_id}
  - ì²˜ë¦¬ ìƒíƒœ ë° ì§„í–‰ë¥  ì¡°íšŒ

GET /api/v1/merged/{file_id}
  - STT + Diarization ë³‘í•© ê²°ê³¼
```

#### 5. tagging.py - í™”ì íƒœê¹…
```python
GET /api/v1/tagging/speaker-info/{file_id}
  - í™”ì ì •ë³´ ì¡°íšŒ

POST /api/v1/tagging/speaker-info/confirm
  - ì‚¬ìš©ì ìˆ˜ì • ì •ë³´ ì €ì¥

POST /api/v1/tagging/analyze/{file_id}
  - LangGraph Agent ì‹¤í–‰ (í™”ì ë§¤í•‘)

GET /api/v1/tagging/{file_id}
  - í™”ì íƒœê¹… ì œì•ˆ ì¡°íšŒ

POST /api/v1/tagging/confirm
  - ì‚¬ìš©ì í™•ì • íƒœê¹… ì €ì¥
  - íš¨ìœ¨ì„± ë¶„ì„ ìë™ íŠ¸ë¦¬ê±°
```

#### 6. efficiency.py - íš¨ìœ¨ì„± ë¶„ì„
```python
POST /api/v1/efficiency/analyze/{file_id}
  - íš¨ìœ¨ì„± ë¶„ì„ ì‹œì‘
  - íŒŒë¼ë¯¸í„°: force (ì¬ë¶„ì„ í”Œë˜ê·¸)

GET /api/v1/efficiency/result/{file_id}
  - ë¶„ì„ ê²°ê³¼ ì¡°íšŒ (AI ì¸ì‚¬ì´íŠ¸ í¬í•¨)
```

#### 7. rag.py - RAG ì‹œìŠ¤í…œ
```python
POST /api/v1/rag/{file_id}/initialize
  - ë²¡í„° DB ì´ˆê¸°í™”

POST /api/v1/rag/{file_id}/chat
  - ì§ˆë¬¸ ë° ë‹µë³€

GET /api/v1/rag/{file_id}/speakers
  - í™”ì ëª©ë¡ ì¡°íšŒ

GET /api/v1/rag/{file_id}/status
  - RAG ì´ˆê¸°í™” ìƒíƒœ ì¡°íšŒ

DELETE /api/v1/rag/{file_id}
  - ë²¡í„° DB ì‚­ì œ
```

#### 8. dashboard.py - ëŒ€ì‹œë³´ë“œ
```python
GET /api/v1/dashboard/stats
  - í†µê³„ ì¡°íšŒ (íŒŒì¼ ìˆ˜, ì²˜ë¦¬ í˜„í™©)

GET /api/v1/dashboard/files
  - ìµœê·¼ íŒŒì¼ ëª©ë¡

GET /api/v1/dashboard/processing-tasks
  - ì²˜ë¦¬ ì¤‘ì¸ ì‘ì—… ëª©ë¡
```

### 6.2 ì„œë¹„ìŠ¤ ë ˆì´ì–´ (10ê°œ)

#### 1. preprocessing.py
```python
def preprocess_audio(input_path, output_path):
  - VAD (Voice Activity Detection)
  - ë…¸ì´ì¦ˆ ì œê±°
  - ìƒ˜í”Œë ˆì´íŠ¸ ì •ê·œí™” (16kHz)
  - ë°˜í™˜: (output_path, original_duration, processed_duration)
```

#### 2. stt.py
```python
def run_stt_pipeline(audio_path, output_dir, ...):
  - Whisper API ë˜ëŠ” ë¡œì»¬ ëª¨ë¸
  - ë³‘ë ¬ ì²˜ë¦¬ (4ê°œ ì²­í¬)
  - íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ í…ìŠ¤íŠ¸ ë°˜í™˜
```

#### 3. diarization.py
```python
def run_diarization(audio_path, device, mode="senko"):
  - Senko: pyannote.audio ê¸°ë°˜ GPU ê°€ì†
  - ì„ë² ë”© ì¶”ì¶œ: 192ì°¨ì› ë²¡í„°
  - ì¶œë ¥: {turns: [...], embeddings: {...}}
```

#### 4. ner_service.py
```python
class NERService:
  - ëª¨ë¸: seungkukim/korean-pii-masking
  - extract_person_names(): PERSON ì—”í‹°í‹° ì¶”ì¶œ
  - cluster_names(): Levenshtein ê±°ë¦¬ ê¸°ë°˜ êµ°ì§‘í™”
  - process_segments(): ì „ì²´ ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬
```

#### 5. nickname_service.py
```python
class NicknameService:
  - LLM: GPT-4
  - Smart Selection: ëŒ€í‘œ ë°œí™” ì„ íƒ
  - generate_nickname(): í™”ìë³„ ë‹‰ë„¤ì„ ìƒì„±
```

#### 6. agent_data_loader.py
```python
def load_agent_input_data_by_file_id(file_id, db):
  - DBì—ì„œ STT, Diarization, NER ê²°ê³¼ ë¡œë“œ
  - Agent ì…ë ¥ ë°ì´í„° êµ¬ì„±
```

#### 7. efficiency_analyzer.py
```python
class EfficiencyAnalyzer:
  - _calc_entropy(): ì—”íŠ¸ë¡œí”¼ ê³„ì‚°
  - _calc_ttr(): Type-Token Ratio
  - _calc_information_content(): ì •ë³´ëŸ‰ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
  - _calc_sentence_probability(): ë¬¸ì¥ í™•ë¥  (HDBSCAN)
  - _calc_perplexity(): PPL (KoGPT-2)
  - analyze_all(): ì „ì²´ ë¶„ì„ ì‹¤í–‰
```

#### 8. rag_service.py
```python
class RAGService:
  - store_transcript(): ë²¡í„° DBì— ì €ì¥
  - query(): ì§ˆë¬¸ ë° ë‹µë³€
  - analyze_question(): í™”ì í•„í„° ìë™ ê°ì§€
  - get_speakers(): í™”ì ëª©ë¡ ì¡°íšŒ
```

#### 9. todo_extractor.py
```python
def extract_todos(transcript, llm_client):
  - LLM ê¸°ë°˜ Todo ì¶”ì¶œ
  - ìš°ì„ ìˆœìœ„, ë‹´ë‹¹ì, ê¸°í•œ íŒŒì‹±
```

#### 10. diarization_nemo.py
```python
def run_nemo_diarization(audio_path, device):
  - NeMo Toolkit ê¸°ë°˜ í™”ì ë¶„ë¦¬
  - GPU ì „ìš©
```

### 6.3 LangGraph Agent

#### ë…¸ë“œ (7ê°œ)

1. **load_profiles_node**
   - ê¸°ì¡´ í™”ì í”„ë¡œí•„ ë¡œë“œ (user_speaker_profiles)

2. **embedding_match_node**
   - ìŒì„±/í…ìŠ¤íŠ¸ ì„ë² ë”© ìœ ì‚¬ë„ ê³„ì‚°
   - ì„ê³„ê°’ 0.85 ì´ìƒì´ë©´ ìë™ ë§¤ì¹­

3. **name_extraction_node**
   - DetectedName ë°ì´í„° í™œìš©
   - context_before/after êµ¬ì„±

4. **name_based_tagging_node** (í•µì‹¬!)
   - ë©€í‹°í„´ LLM ì¶”ë¡ 
   - ì´ë¦„ ì–¸ê¸‰ â†’ í™”ì ë§¤í•‘
   - ëª¨ìˆœ ê°ì§€ ë° ì‹ ë¢°ë„ ì¡°ì •

5. **merge_results_node**
   - ìë™ ë§¤ì¹­ + ì´ë¦„ ê¸°ë°˜ ê²°ê³¼ ë³‘í•©
   - ì¤‘ë³µ ì œê±° (ê°™ì€ ì´ë¦„ â†’ ë†’ì€ ì‹ ë¢°ë„ ì„ íƒ)
   - ì†Œê±°ë²• ì ìš©

6. **save_profiles_node**
   - ìƒˆ í™”ìë¥¼ user_speaker_profilesì— ì €ì¥

7. **role_based_tagging_node** (êµ¬í˜„ ì˜ˆì •)
   - ë°œí™” íŒ¨í„´ ê¸°ë°˜ ì—­í•  ì¶”ë¡ 

#### ë„êµ¬ (4ê°œ)

1. **LoadProfilesTool**
   - DBì—ì„œ í™”ì í”„ë¡œí•„ ì¡°íšŒ

2. **VoiceSimilarityTool**
   - ìŒì„± ì„ë² ë”© ì½”ì‚¬ì¸ ìœ ì‚¬ë„

3. **TextSimilarityTool**
   - í…ìŠ¤íŠ¸ ì„ë² ë”© ìœ ì‚¬ë„

4. **SaveSpeakerProfileTool**
   - í™”ì í”„ë¡œí•„ ì €ì¥

---

## 7. í”„ë¡ íŠ¸ì—”ë“œ ìƒì„¸

### 7.1 í˜ì´ì§€ (13ê°œ)

#### ê³µê°œ í˜ì´ì§€ (3ê°œ)

1. **LoginPage** (`/login`)
   - ì´ë©”ì¼/ë¹„ë°€ë²ˆí˜¸ ë¡œê·¸ì¸
   - OAuth ë²„íŠ¼ (Google, Kakao)

2. **RegisterPage** (`/register`)
   - íšŒì›ê°€ì… í¼

3. **OAuthCallbackPage** (`/oauth/callback`)
   - OAuth ì½œë°± ì²˜ë¦¬

#### ë³´í˜¸ëœ í˜ì´ì§€ (10ê°œ)

4. **DashboardPageNew** (`/`)
   - í†µê³„ ì¹´ë“œ (íŒŒì¼ ìˆ˜, ì²˜ë¦¬ í˜„í™©)
   - ìµœê·¼ íŒŒì¼ ëª©ë¡
   - ì²˜ë¦¬ ì¤‘ì¸ ì‘ì—… ëª©ë¡

5. **UploadPage** (`/upload`)
   - íŒŒì¼ ì—…ë¡œë“œ (ë“œë˜ê·¸ì•¤ë“œë¡­)
   - ëª¨ë¸ ì„ íƒ (Whisper, Diarization)

6. **ProcessingPage** (`/processing/:fileId`)
   - ì²˜ë¦¬ ìƒíƒœ í´ë§ (1ì´ˆë§ˆë‹¤)
   - ì§„í–‰ë¥  ë°” í‘œì‹œ
   - ë‹¨ê³„ë³„ ìƒíƒœ: preprocessing â†’ stt â†’ diarization â†’ ner â†’ completed

7. **SpeakerInfoConfirmPage** (`/confirm/:fileId`)
   - í™”ì ìˆ˜ í™•ì¸/ìˆ˜ì •
   - ê°ì§€ëœ ì´ë¦„ í™•ì¸/ìˆ˜ì •
   - ê°ì§€ëœ ë‹‰ë„¤ì„ í™•ì¸/ìˆ˜ì •

8. **TaggingAnalyzingPage** (`/analyzing/:fileId`)
   - LangGraph Agent ì‹¤í–‰ ì¤‘ í‘œì‹œ
   - 3ì´ˆ ë¡œë”© ì• ë‹ˆë©”ì´ì…˜

9. **TaggingPageNew** (`/tagging/:fileId`)
   - ì‹œìŠ¤í…œ ì œì•ˆ í‘œì‹œ
   - ë“œë¡­ë‹¤ìš´ìœ¼ë¡œ ì´ë¦„ ì„ íƒ
   - íƒœê¹… ì™„ë£Œ ë²„íŠ¼

10. **ResultPageNew** (`/result/:fileId`)
    - í™”ìë³„ í†µê³„ (ë°œí™” íšŸìˆ˜, ì‹œê°„)
    - ì „ì²´ íšŒì˜ë¡ í‘œì‹œ
    - ë‹¤ìŒ ë‹¨ê³„ ì„ íƒ (RAG, Todo, íš¨ìœ¨ì„±)

11. **RagPage** (`/rag/:fileId`)
    - ë²¡í„° DB ì´ˆê¸°í™” ë²„íŠ¼
    - ì§ˆë¬¸ ì…ë ¥ ë° ë‹µë³€ í‘œì‹œ
    - ëŒ€í™” íˆìŠ¤í† ë¦¬

12. **TodoPage** (`/todo/:fileId`)
    - Todo ëª©ë¡ í‘œì‹œ
    - ìš°ì„ ìˆœìœ„, ë‹´ë‹¹ì, ê¸°í•œ

13. **EfficiencyPage** (`/efficiency/:fileId`)
    - ì „ì²´ íšŒì˜ ì¢…í•© ë¶„ì„ (ì—”íŠ¸ë¡œí”¼ + AI ì¸ì‚¬ì´íŠ¸)
    - í™”ìë³„ íš¨ìœ¨ì„± ì§€í‘œ (íƒ­ ë°©ì‹)
    - 5ê°€ì§€ ì§€í‘œ: TTR, ì •ë³´ëŸ‰, ë¬¸ì¥ í™•ë¥ , PPL, ë°œí™” ë¹ˆë„

### 7.2 ì»´í¬ë„ŒíŠ¸ êµ¬ì¡°

#### Layout
- **MainLayout**: ì‚¬ì´ë“œë°” + íƒ‘ë°” + ë©”ì¸ ì½˜í…ì¸ 
- **Sidebar**: ë„¤ë¹„ê²Œì´ì…˜ ë©”ë‰´
- **TopBar**: ì‚¬ìš©ì ì •ë³´, ë¡œê·¸ì•„ì›ƒ, í…Œë§ˆ í† ê¸€

#### Dashboard
- **StatsCards**: í†µê³„ ì¹´ë“œ (4ê°œ)
- **RecentFilesList**: ìµœê·¼ íŒŒì¼ ëª©ë¡
- **ProcessingTasks**: ì²˜ë¦¬ ì¤‘ì¸ ì‘ì—…
- **ResultModal**: ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°

#### FileUpload
- **FileUpload**: ë“œë˜ê·¸ì•¤ë“œë¡­ ì—…ë¡œë“œ

#### ê¸°íƒ€
- **ProtectedRoute**: ì¸ì¦ í™•ì¸
- **ThemeToggle**: ë‹¤í¬ëª¨ë“œ í† ê¸€

### 7.3 Context (2ê°œ)

#### AuthContext
```javascript
{
  user,              // í˜„ì¬ ì‚¬ìš©ì
  login(email, password),
  logout(),
  register(email, password, name),
  isAuthenticated   // ë¡œê·¸ì¸ ì—¬ë¶€
}
```

#### ThemeContext
```javascript
{
  theme,            // "light" | "dark"
  toggleTheme()
}
```

### 7.4 ë¼ìš°íŒ…

```javascript
ê³µê°œ ë¼ìš°íŠ¸:
  /login
  /register
  /oauth/callback

ë³´í˜¸ëœ ë¼ìš°íŠ¸ (ì¸ì¦ í•„ìš”):
  /                      - ëŒ€ì‹œë³´ë“œ
  /upload                - íŒŒì¼ ì—…ë¡œë“œ
  /processing/:fileId    - AI ì²˜ë¦¬ ì¤‘
  /confirm/:fileId       - í™”ì ì •ë³´ í™•ì¸
  /analyzing/:fileId     - AI ë¶„ì„ ì¤‘
  /tagging/:fileId       - í™”ì íƒœê¹…
  /result/:fileId        - ê²°ê³¼
  /rag/:fileId           - RAG ëŒ€í™”
  /todo/:fileId          - Todo
  /efficiency/:fileId    - íš¨ìœ¨ì„± ë¶„ì„
```

---

## 8. ì£¼ìš” ê¸°ëŠ¥

### 8.1 ì¸ì¦ ì‹œìŠ¤í…œ

#### í•˜ì´ë¸Œë¦¬ë“œ ì¸ì¦
- **ì´ë©”ì¼/ë¹„ë°€ë²ˆí˜¸**: bcrypt í•´ì‹±
- **OAuth 2.0**: Google, Kakao
- **JWT í† í°**: Access + Refresh Token

#### í”Œë¡œìš°
```
1. ë¡œê·¸ì¸ ìš”ì²­
   â†“
2. ì¸ì¦ í™•ì¸
   â†“
3. JWT í† í° ë°œê¸‰
   - Access Token (15ë¶„)
   - Refresh Token (7ì¼)
   â†“
4. í”„ë¡ íŠ¸ì—”ë“œ localStorage ì €ì¥
   â†“
5. ëª¨ë“  API ìš”ì²­ì— Authorization í—¤ë” í¬í•¨
```

### 8.2 í™”ì íƒœê¹… (LangGraph Agent)

#### ë©€í‹°í„´ LLM ì¶”ë¡ 

**Turn 1**: ì²« ë²ˆì§¸ ì´ë¦„ ì–¸ê¸‰
```
ì…ë ¥:
  - context_before: ì• 5ë¬¸ì¥
  - context_after: ë’¤ 5ë¬¸ì¥
  - participant_names: ["ë¯¼ì„œ", "ì¸ì„œ"]

í”„ë¡¬í”„íŠ¸:
  "ë‹¤ìŒ ëŒ€í™”ì—ì„œ 'ë¯¼ì„œ'ëŠ” SPEAKER_00ê³¼ SPEAKER_01 ì¤‘ ëˆ„êµ¬ì¼ê¹Œìš”?
   - SPEAKER_01: ë¯¼ì„œì”¨, ì´ë²ˆ íšŒì˜ ì•ˆê±´ ë°œí‘œí•´ì£¼ì„¸ìš”
   - SPEAKER_00: ë„¤, ì•Œê² ìŠµë‹ˆë‹¤"

LLM ì‘ë‹µ:
  {speaker: "SPEAKER_00", confidence: 0.85,
   reasoning: "SPEAKER_01ì´ í˜¸ì¹­ í›„ SPEAKER_00ì´ ì‘ë‹µ"}
```

**Turn 2**: ê°™ì€ ì´ë¦„ ì¬ì–¸ê¸‰
```
ì…ë ¥:
  - ì´ì „ ë¶„ì„ ìš”ì•½: "Turn 1: ë¯¼ì„œ=SPEAKER_00 (85%)"
  - ìƒˆ context

í”„ë¡¬í”„íŠ¸:
  "[Turn 1] ë¯¼ì„œëŠ” SPEAKER_00ì¼ í™•ë¥  85%ì˜€ìŠµë‹ˆë‹¤.

   [Turn 2 ìƒˆ ë¬¸ë§¥]
   - SPEAKER_01: ë¯¼ì„œì”¨ ì˜ê²¬ì— ë™ì˜í•©ë‹ˆë‹¤
   - SPEAKER_00: ë„¤, ê°ì‚¬í•©ë‹ˆë‹¤

   ì´ ë¬¸ë§¥ì—ì„œë„ ë¯¼ì„œê°€ SPEAKER_00ì´ ë§ë‚˜ìš”?"

LLM ì‘ë‹µ:
  {speaker: "SPEAKER_00", confidence: 0.95, consistency: true}
```

**Turn 3**: ëª¨ìˆœ ë°œê²¬
```
ì…ë ¥:
  - ì´ì „ ë¶„ì„ ìš”ì•½: "Turn 1~2: ë¯¼ì„œ=SPEAKER_00 (90%)"
  - ìƒˆ context

í”„ë¡¬í”„íŠ¸:
  "[ì´ì „ ë¶„ì„] ë¯¼ì„œëŠ” SPEAKER_00ì¼ í™•ë¥  90%ì˜€ìŠµë‹ˆë‹¤.

   [Turn 3 ìƒˆ ë¬¸ë§¥]
   - SPEAKER_00: ë¯¼ì„œì”¨ëŠ” ì–´ë–»ê²Œ ìƒê°í•˜ì„¸ìš”?
   - SPEAKER_01: ì €ëŠ” ì´ë ‡ê²Œ ìƒê°í•©ë‹ˆë‹¤

   ì´ ë¬¸ë§¥ì€ ì´ì „ ë¶„ì„ê³¼ ëª¨ìˆœë˜ë‚˜ìš”?"

LLM ì‘ë‹µ:
  {speaker: "SPEAKER_01", confidence: 0.80,
   consistency: false, conflict_detected: true}

ìµœì¢… ìŠ¤ì½”ì–´ ì¡°ì •:
  - SPEAKER_00: 0.90 * 0.7 = 0.63 (í•˜í–¥)
  - SPEAKER_01: 0.10 + 0.80 * 0.3 = 0.34 (ìƒí–¥)
  - needs_manual_review: true
```

### 8.3 íšŒì˜ íš¨ìœ¨ì„± ë¶„ì„

#### 5ê°€ì§€ ì§€í‘œ

**1. ì—”íŠ¸ë¡œí”¼ (Entropy)**
```python
# Shannon Entropy
entropy = -sum(p * log2(p) for p in probabilities)

# ìŠ¬ë¼ì´ë”© ìœˆë„ìš° (50ë‹¨ì–´)
for window in sliding_window(words, size=50):
    word_freq = Counter(window)
    probabilities = [count / len(window) for count in word_freq.values()]
    entropy = calculate_entropy(probabilities)
```

**2. TTR (Type-Token Ratio)**
```python
# ëª…ì‚¬ ê¸°ë°˜ ê³„ì‚°
nouns = mecab.nouns(text)
ttr = len(set(nouns)) / len(nouns)

# ìŠ¬ë¼ì´ë”© ìœˆë„ìš°
for window in sliding_window(nouns, size=50):
    window_ttr = len(set(window)) / len(window)
```

**3. ì •ë³´ëŸ‰ (Information Content)**
```python
# Sentence Transformer
model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
embeddings = model.encode(sentences)

# í‰ê·  ì„ë² ë”©
mean_embedding = np.mean(embeddings, axis=0)

# ì½”ì‚¬ì¸ ìœ ì‚¬ë„
for emb in embeddings:
    similarity = cosine_similarity(emb, mean_embedding)

information_score = 1 - avg_similarity
```

**4. ë¬¸ì¥ í™•ë¥  (Sentence Probability)**
```python
# HDBSCAN êµ°ì§‘í™”
embeddings = model.encode(sentences)
clusterer = hdbscan.HDBSCAN(min_cluster_size=2)
labels = clusterer.fit_predict(embeddings)

# í™•ë¥  ê³„ì‚°
for cluster_id in unique_labels:
    count = np.sum(labels == cluster_id)
    probability = count / len(sentences)

# ì´ìƒì¹˜ (í™•ë¥  ë‚®ì€ ë¬¸ì¥)
rare_sentences = [s for s, p in zip(sentences, probs) if p < 0.05]
```

**5. PPL (Perplexity)**
```python
# KoGPT-2
model = AutoModelForCausalLM.from_pretrained('skt/kogpt2-base-v2')
tokenizer = AutoTokenizer.from_pretrained('skt/kogpt2-base-v2')

# 10ë¬¸ì¥ ë‹¨ìœ„ ìœˆë„ìš°
for window in sliding_window(sentences, size=10):
    text = " ".join(window)
    encodings = tokenizer(text, return_tensors="pt")

    with torch.no_grad():
        outputs = model(encodings.input_ids, labels=encodings.input_ids)
        loss = outputs.loss
        ppl = torch.exp(loss).item()
```

#### AI ì¸ì‚¬ì´íŠ¸ ìƒì„±

```python
# GPT-4o-mini
prompt = f"""íšŒì˜ íš¨ìœ¨ì„± ì§€í‘œì— ëŒ€í•œ ê°„ë‹¨í•œ í•œì¤„ í‰ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì§€í‘œëª…: {metric_name}
í‰ê· : {avg:.3f}
ì¶”ì„¸: {trend}  # ìƒìŠ¹/í•˜ë½/ì•ˆì •
ë³€ë™ì„±: {volatility}  # ë†’ìŒ/ë‚®ìŒ
ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜: {len(values)}

í•œì¤„ë¡œ íšŒì˜ì˜ íŠ¹ì§•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”."""

response = openai_client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "ë‹¹ì‹ ì€ íšŒì˜ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
        {"role": "user", "content": prompt}
    ],
    max_tokens=100,
    temperature=0.7
)

insight = response.choices[0].message.content.strip()
```

### 8.4 RAG ì‹œìŠ¤í…œ

#### ChromaDB ë²¡í„° ì €ì¥

```python
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings

# ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
vectorstore = Chroma(
    collection_name=f"meeting_{file_id}",
    embedding_function=OpenAIEmbeddings(),
    persist_directory="./chroma_db"
)

# íšŒì˜ë¡ ì €ì¥
texts = [f"[{t.speaker_name}] {t.text}" for t in transcripts]
metadatas = [{"speaker": t.speaker_name, "time": t.start_time} for t in transcripts]

vectorstore.add_texts(texts=texts, metadatas=metadatas)
```

#### ì§ˆë¬¸ ë¶„ì„ ë° ë‹µë³€

```python
# 1. ì§ˆë¬¸ì—ì„œ í™”ì í•„í„° ì¶”ì¶œ
question = "ë¯¼ì„œê°€ ë­ë¼ê³  í–ˆì–´?"
speaker_filter = analyze_question(question, speakers)  # â†’ "ë¯¼ì„œ"

# 2. ë²¡í„° ê²€ìƒ‰ (í™”ì í•„í„°ë§)
if speaker_filter:
    docs = vectorstore.similarity_search(
        question,
        k=5,
        filter={"speaker": speaker_filter}
    )
else:
    docs = vectorstore.similarity_search(question, k=5)

# 3. LLM ë‹µë³€ ìƒì„±
context = "\n\n".join([doc.page_content for doc in docs])
prompt = f"""Context:\n{context}\n\nQuestion: {question}\nAnswer:"""

response = llm_client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "system", "content": "ë‹¹ì‹ ì€ íšŒì˜ë¡ ë¶„ì„ AIì…ë‹ˆë‹¤."},
        {"role": "user", "content": prompt}
    ]
)
```

---

## 9. API ë¬¸ì„œ

### 9.1 ì¸ì¦ API

#### POST /api/v1/auth/register
**ìš”ì²­**:
```json
{
  "email": "user@example.com",
  "password": "password123",
  "full_name": "í™ê¸¸ë™"
}
```

**ì‘ë‹µ** (200):
```json
{
  "message": "User created successfully",
  "user": {
    "id": 1,
    "email": "user@example.com",
    "full_name": "í™ê¸¸ë™"
  }
}
```

#### POST /api/v1/auth/login
**ìš”ì²­**:
```json
{
  "email": "user@example.com",
  "password": "password123"
}
```

**ì‘ë‹µ** (200):
```json
{
  "access_token": "eyJ...",
  "refresh_token": "eyJ...",
  "token_type": "bearer"
}
```

### 9.2 íŒŒì¼ ì—…ë¡œë“œ API

#### POST /api/v1/upload
**ìš”ì²­**: multipart/form-data
```
file: <audio file>
```

**ì‘ë‹µ** (200):
```json
{
  "file_id": "550e8400-e29b-41d4-a716-446655440000",
  "message": "File uploaded successfully"
}
```

### 9.3 ì²˜ë¦¬ API

#### POST /api/v1/process/{file_id}
**ìš”ì²­**:
```json
{
  "whisper_mode": "local",  // "local" | "api"
  "diarization_mode": "senko"  // "senko" | "nemo"
}
```

**ì‘ë‹µ** (202):
```json
{
  "message": "Processing started",
  "file_id": "550e8400-e29b-41d4-a716-446655440000"
}
```

#### GET /api/v1/status/{file_id}
**ì‘ë‹µ** (200):
```json
{
  "status": "stt",
  "progress": 45,
  "speaker_count": 3,
  "detected_names": ["ë¯¼ì„œ", "ì¸ì„œ"],
  "detected_nicknames": ["ì§„í–‰ ë‹´ë‹¹ì", "ê¸°ìˆ  ì „ë¬¸ê°€"]
}
```

### 9.4 í™”ì íƒœê¹… API

#### GET /api/v1/tagging/{file_id}
**ì‘ë‹µ** (200):
```json
{
  "suggested_mappings": [
    {
      "speaker_label": "SPEAKER_00",
      "suggested_name": "ë¯¼ì„œ",
      "nickname": "ì§„í–‰ ë‹´ë‹¹ì",
      "name_confidence": 0.85,
      "needs_manual_review": false
    },
    ...
  ],
  "transcript": [...],
  "detected_names": ["ë¯¼ì„œ", "ì¸ì„œ"]
}
```

#### POST /api/v1/tagging/confirm
**ìš”ì²­**:
```json
{
  "file_id": "550e8400-e29b-41d4-a716-446655440000",
  "mappings": [
    {"speaker_label": "SPEAKER_00", "final_name": "ê¹€ë¯¼ì„œ"},
    {"speaker_label": "SPEAKER_01", "final_name": "ì´í™ê¸°"}
  ]
}
```

**ì‘ë‹µ** (200):
```json
{
  "file_id": "550e8400-e29b-41d4-a716-446655440000",
  "message": "í™”ì íƒœê¹…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. íš¨ìœ¨ì„± ë¶„ì„ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤.",
  "status": "confirmed"
}
```

### 9.5 íš¨ìœ¨ì„± ë¶„ì„ API

#### GET /api/v1/efficiency/result/{file_id}
**ì‘ë‹µ** (200):
```json
{
  "file_id": "550e8400-e29b-41d4-a716-446655440000",
  "analyzed_at": "2025-11-27T10:30:00Z",

  "entropy": {
    "entropy_avg": 2.15,
    "entropy_std": 0.45,
    "insight": "ì£¼ì œê°€ ë‹¤ì–‘í•˜ê²Œ ë…¼ì˜ë˜ì—ˆìŠµë‹ˆë‹¤."
  },

  "overall_ttr": {
    "ttr_avg": 0.68,
    "insight": "ì–´íœ˜ ë‹¤ì–‘ì„±ì´ ë†’ì•„ í’ë¶€í•œ ë…¼ì˜ê°€ ì´ë£¨ì–´ì¡ŒìŠµë‹ˆë‹¤."
  },

  "speaker_metrics": [
    {
      "speaker_label": "SPEAKER_00",
      "speaker_name": "ê¹€ë¯¼ì„œ",
      "ttr": {
        "ttr_avg": 0.68,
        "insight": "ê¹€ë¯¼ì„œë‹˜ì€ ë‹¤ì–‘í•œ ì–´íœ˜ë¥¼ ì‚¬ìš©í•˜ë©° ë°œí‘œí•˜ì˜€ìŠµë‹ˆë‹¤."
      },
      ...
    },
    ...
  ]
}
```

### 9.6 RAG API

#### POST /api/v1/rag/{file_id}/initialize
**ì‘ë‹µ** (200):
```json
{
  "message": "RAG initialized successfully",
  "collection_name": "meeting_123",
  "document_count": 145
}
```

#### POST /api/v1/rag/{file_id}/chat
**ìš”ì²­**:
```json
{
  "question": "ë¯¼ì„œê°€ ë­ë¼ê³  í–ˆì–´?"
}
```

**ì‘ë‹µ** (200):
```json
{
  "answer": "ë¯¼ì„œë‹˜ì€ 'ì˜¤ëŠ˜ íšŒì˜ ì•ˆê±´ì€ ì‹ ì œí’ˆ ì¶œì‹œ ì¼ì •ì…ë‹ˆë‹¤'ë¼ê³  ë§ì”€í•˜ì…¨ìŠµë‹ˆë‹¤.",
  "sources": [
    {
      "text": "[ê¹€ë¯¼ì„œ] ì˜¤ëŠ˜ íšŒì˜ ì•ˆê±´ì€ ì‹ ì œí’ˆ ì¶œì‹œ ì¼ì •ì…ë‹ˆë‹¤.",
      "speaker": "ê¹€ë¯¼ì„œ",
      "time": 10.5
    }
  ],
  "speaker_filter": "ê¹€ë¯¼ì„œ"
}
```

---

## 10. ë°°í¬ ë° ìš´ì˜

### 10.1 Docker ì‹¤í–‰

```bash
# ì „ì²´ ì‹œìŠ¤í…œ ì‹œì‘
docker compose up -d

# ë¡œê·¸ í™•ì¸
docker compose logs -f backend

# íŠ¹ì • ì„œë¹„ìŠ¤ ì¬ì‹œì‘
docker compose restart backend

# ì¤‘ì§€
docker compose down

# ì™„ì „ ì´ˆê¸°í™” (ë³¼ë¥¨ ì‚­ì œ)
docker compose down -v
```

### 10.2 í™˜ê²½ ë³€ìˆ˜ (.env)

```bash
# MySQL
MYSQL_ROOT_PASSWORD=root_password
MYSQL_DATABASE=listencare
MYSQL_USER=listencare_user
MYSQL_PASSWORD=listencare_pass123

# Backend
DATABASE_URL=mysql+pymysql://listencare_user:listencare_pass123@mysql:3306/listencare
SECRET_KEY=your-secret-key-here
OPENAI_API_KEY=sk-...

# OAuth
GOOGLE_CLIENT_ID=...
GOOGLE_CLIENT_SECRET=...
KAKAO_CLIENT_ID=...
KAKAO_CLIENT_SECRET=...

# LangSmith (ì„ íƒ)
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=lsv2_pt_...
LANGCHAIN_PROJECT=speaker-tagging-agent

# Frontend
VITE_API_URL=http://localhost:8000
```

### 10.3 ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜

```bash
# Backend ì»¨í…Œì´ë„ˆ ì ‘ì†
docker exec -it listencare_backend bash

# ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒì„±
alembic revision --autogenerate -m "ì„¤ëª…"

# ë§ˆì´ê·¸ë ˆì´ì…˜ ì ìš©
alembic upgrade head

# ë¡¤ë°±
alembic downgrade -1
```

### 10.4 ì ‘ì† ì£¼ì†Œ

- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs
- **MySQL**: localhost:3306

---

## 11. íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 11.1 í¬íŠ¸ ì¶©ëŒ

**ì¦ìƒ**: í¬íŠ¸ê°€ ì´ë¯¸ ì‚¬ìš© ì¤‘
```bash
Error: bind: address already in use
```

**í•´ê²°**:
```bash
# í¬íŠ¸ ì‚¬ìš© í™•ì¸
lsof -i :3000
lsof -i :8000
lsof -i :3306

# í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
kill -9 <PID>
```

### 11.2 Docker ë¹Œë“œ ì˜¤ë¥˜

**ì¦ìƒ**: ë¹Œë“œ ì‹¤íŒ¨

**í•´ê²°**:
```bash
# ìºì‹œ ë¬´ì‹œí•˜ê³  ë¹Œë“œ
docker compose build --no-cache

# ì™„ì „ ì´ˆê¸°í™” í›„ ì¬ì‹œì‘
docker compose down -v
docker compose build --no-cache
docker compose up
```

### 11.3 MySQL ì—°ê²° ì˜¤ë¥˜

**ì¦ìƒ**: `Can't connect to MySQL server`

**í•´ê²°**:
1. MySQL ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
   ```bash
   docker ps
   ```

2. MySQL ë¡œê·¸ í™•ì¸
   ```bash
   docker compose logs mysql
   ```

3. í™˜ê²½ ë³€ìˆ˜ í™•ì¸
   ```bash
   docker exec -it listencare_backend env | grep MYSQL
   ```

### 11.4 íš¨ìœ¨ì„± ë¶„ì„ NaN/Infinity ì—ëŸ¬

**ì¦ìƒ**: `Invalid JSON text: "Invalid value."`

**ì›ì¸**: PPL ê³„ì‚° ì¤‘ NaN/Infinity ê°’ ìƒì„±

**í•´ê²°**: ì´ë¯¸ ì ìš©ë¨ (efficiency_analyzer.pyì—ì„œ í•„í„°ë§)
```python
if not np.isnan(ppl) and not np.isinf(ppl):
    ppl_values.append({"window_index": i, "ppl": float(ppl)})
```

### 11.5 RAG ì´ˆê¸°í™” ì˜¤ë¥˜

**ì¦ìƒ**: ë²¡í„° DB ì´ˆê¸°í™” ì‹¤íŒ¨

**í•´ê²°**:
1. ChromaDB ë””ë ‰í† ë¦¬ í™•ì¸
   ```bash
   ls -la chroma_db/
   ```

2. ê¶Œí•œ ë¬¸ì œ ì‹œ
   ```bash
   chmod -R 777 chroma_db/
   ```

3. ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ í›„ ì¬ìƒì„±
   ```bash
   DELETE /api/v1/rag/{file_id}
   POST /api/v1/rag/{file_id}/initialize
   ```

### 11.6 CUDA ì˜¤ë¥˜

**ì¦ìƒ**: `CUDA out of memory`

**í•´ê²°**:
1. GPU ë©”ëª¨ë¦¬ í™•ì¸
   ```bash
   nvidia-smi
   ```

2. ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸° (stt.py, diarization.py)

3. ë¶ˆí•„ìš”í•œ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ

---

## 12. í•µì‹¬ êµ¬í˜„ ì½”ë“œ ì˜ˆì œ

### 12.1 Phase 1: ìŒì„± ì²˜ë¦¬ ì‹¤ì œ êµ¬í˜„

#### VAD (Voice Activity Detection) - WebRTC
```python
SR = 16000              # ìƒ˜í”Œë§ ë ˆì´íŠ¸
VAD_AGGR = 2            # VAD ë¯¼ê°ë„ (0~3, ë†’ì„ìˆ˜ë¡ ì—„ê²©)
FRAME_MS = 20           # í”„ë ˆì„ í¬ê¸° (ms)
PAD_MS = 150            # VAD íŒ¨ë”© (ms)

def vad_keep_mask(audio_f32: np.ndarray, sr: int, frame_ms: int,
                  vad_aggr: int, pad_ms: int):
    """WebRTC VADë¡œ ìŒì„± êµ¬ê°„ íƒì§€"""
    # Float â†’ Int16 ë³€í™˜
    x_i16 = float_to_int16(audio_f32)
    vad = webrtcvad.Vad(vad_aggr)

    # í”„ë ˆì„ ë‹¨ìœ„ ë¶„í•  (20ms)
    frame_len = int(sr * frame_ms / 1000)
    frame_iter = list(frame_bytes_from_int16(x_i16, sr, frame_ms))

    # ê° í”„ë ˆì„ ìŒì„± ì—¬ë¶€ íŒë³„
    voiced = np.zeros(len(frame_iter), dtype=bool)
    for i, (start, frame_bytes) in enumerate(frame_iter):
        if vad.is_speech(frame_bytes, sr):
            voiced[i] = True

    # íŒ¨ë”© ì¶”ê°€ (ìŒì„± í”„ë ˆì„ ì•ë’¤ì— 150ms ì¶”ê°€)
    keep = np.zeros_like(voiced)
    pad_frames = pad_ms // frame_ms
    for i, v in enumerate(voiced):
        if v:
            s = max(0, i - pad_frames)
            e = min(len(voiced), i + pad_frames + 1)
            keep[s:e] = True

    return keep_samples
```

#### STT ë³‘ë ¬ ì²˜ë¦¬ (OpenAI Whisper API)
```python
def transcribe_chunks_with_whisper(chunk_files: List[Path], srt_dir: Path,
                                   openai_api_key: str) -> List[Path]:
    """ë³‘ë ¬ ì „ì‚¬ (ìµœëŒ€ 4ê°œ ë™ì‹œ ì‹¤í–‰)"""
    srt_files_dict = {}
    with ThreadPoolExecutor(max_workers=4) as executor:
        # ëª¨ë“  ì²­í¬ë¥¼ ë³‘ë ¬ë¡œ ì œì¶œ
        future_to_chunk = {
            executor.submit(transcribe_single_chunk, cp, srt_dir,
                          openai_api_key, i + 1, len(chunk_files)): (i, cp)
            for i, cp in enumerate(chunk_files)
        }

        # ì™„ë£Œëœ ìˆœì„œëŒ€ë¡œ ê²°ê³¼ ìˆ˜ì§‘
        for future in as_completed(future_to_chunk):
            idx, chunk_path = future_to_chunk[future]
            srt_path = future.result()
            srt_files_dict[idx] = srt_path

    return [srt_files_dict[i] for i in sorted(srt_files_dict.keys())]
```

#### Diarization (Senko) - GPU ê°€ì†
```python
def run_diarization_senko(audio_path: Path, device: str = None) -> Dict:
    """Senkoë¥¼ ì‚¬ìš©í•œ í™”ì ë¶„ë¦¬ (192ì°¨ì› ì„ë² ë”©)"""
    # Senko Diarizer ì´ˆê¸°í™”
    diarizer = senko.Diarizer(device=device, warmup=True, quiet=False)

    # í™”ì ë¶„ë¦¬ ì‹¤í–‰
    senko_result = diarizer.diarize(str(audio_path), generate_colors=False)

    # ê²°ê³¼ ë³€í™˜ (numpy â†’ list)
    embeddings = {}
    for speaker, centroid in senko_result['speaker_centroids'].items():
        embeddings[speaker] = centroid.tolist()  # 192ì°¨ì› ë¦¬ìŠ¤íŠ¸

    return {"turns": turns, "embeddings": embeddings}
```

### 12.2 Phase 2: AI ë¶„ì„ ì‹¤ì œ êµ¬í˜„

#### NER - BERT + Levenshtein Clustering
```python
class NERService:
    def __init__(self):
        model_name = "seungkukim/korean-pii-masking"
        self.model = AutoModelForTokenClassification.from_pretrained(model_name)
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.nlp = pipeline("ner", model=self.model, tokenizer=self.tokenizer,
                           aggregation_strategy="simple")

    def cluster_similar_names(self, detected_names: List[Dict]) -> Dict[str, List[str]]:
        """ìœ ì‚¬ ì´ë¦„ ê·¸ë£¹í™” (Levenshtein Distance + Hierarchical Clustering)"""
        from scipy.cluster.hierarchy import linkage, fcluster
        from Levenshtein import distance as levenshtein_distance

        unique_names = list(set([d["detected_name"] for d in detected_names]))

        # ê±°ë¦¬ í–‰ë ¬ ê³„ì‚°
        n = len(unique_names)
        distance_matrix = np.zeros((n, n))
        for i in range(n):
            for j in range(i + 1, n):
                dist = levenshtein_distance(unique_names[i], unique_names[j])
                normalized_dist = dist / max(len(unique_names[i]), len(unique_names[j]))
                distance_matrix[i, j] = normalized_dist
                distance_matrix[j, i] = normalized_dist

        # Hierarchical Clustering
        condensed_dist = distance_matrix[np.triu_indices(n, k=1)]
        Z = linkage(condensed_dist, method='average')
        cluster_labels = fcluster(Z, t=0.3, criterion='distance')

        # ëŒ€í‘œ ì´ë¦„ ì„ íƒ
        result = {}
        for label in set(cluster_labels):
            names = [unique_names[i] for i, l in enumerate(cluster_labels) if l == label]
            representative = min(names, key=len)
            result[representative] = names

        return result
```

#### ë‹‰ë„¤ì„ ìƒì„± - Smart Selection (70% ë¹„ìš© ì ˆê°)
```python
class NicknameService:
    def smart_selection_utterances(self, utterances: List[Dict], max_total: int = 12):
        """ëŒ€í‘œ ë°œí™” ì„ íƒìœ¼ë¡œ LLM í˜¸ì¶œ ë¹„ìš© 70% ì ˆê°"""
        selected = []

        # 1. ê¸´ ë°œí™” ìš°ì„  (20ë‹¨ì–´ ì´ìƒ)
        long_utterances = [u for u in utterances if len(u.get("text", "").split()) > 20]
        long_utterances.sort(key=lambda x: len(x["text"]), reverse=True)
        selected.extend(long_utterances[:5])

        # 2. í‚¤ì›Œë“œ í¬í•¨ ë°œí™”
        keywords = ["ìš”ì•½", "ì •ë¦¬", "ê²°ë¡ ", "ì œì•ˆ", "ë¬¸ì œ", "í•´ê²°"]
        keyword_utterances = [u for u in utterances
                             if any(kw in u.get("text", "") for kw in keywords)]
        selected.extend(keyword_utterances[:3])

        # 3. ì‹œê°„ëŒ€ë³„ ìƒ˜í”Œë§ (ì´ˆë°˜/ì¤‘ë°˜/í›„ë°˜)
        if len(utterances) >= 3:
            segment_size = len(utterances) // 3
            selected.append(utterances[segment_size // 2])
            selected.append(utterances[segment_size + segment_size // 2])
            selected.append(utterances[-segment_size // 2])

        return unique_selected[:max_total]

    @traceable(name="generate_speaker_nickname", run_type="llm")
    def generate_nickname_with_llm(self, speaker_label: str, selected_utterances: List[Dict]):
        """GPT-4o-minië¡œ í™”ì ë‹‰ë„¤ì„ ìƒì„±"""
        prompt = f"""
        ë‹¹ì‹ ì€ ì „ë¬¸ íšŒì˜ ë¶„ì„ê°€ì…ë‹ˆë‹¤.

        ì•„ë˜ëŠ” í™”ì "{speaker_label}"ì˜ ëŒ€í‘œ ë°œí™”ë“¤ì…ë‹ˆë‹¤:
        {chr(10).join([f"- {u['text']}" for u in selected_utterances])}

        ìœ„ ë°œí™”ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
        {{
          "display_label": "ì—­í•  (2-4ë‹¨ì–´)",
          "one_liner": "íŠ¹ì§• í•œì¤„ ìš”ì•½",
          "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"],
          "communication_style": "ì˜ì‚¬ì†Œí†µ ìŠ¤íƒ€ì¼"
        }}
        """

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            response_format={"type": "json_object"}
        )

        return json.loads(response.choices[0].message.content)
```

### 12.3 Phase 3: LangGraph Agent ì‹¤ì œ êµ¬í˜„

#### AgentState ì •ì˜
```python
from typing import TypedDict, List, Dict

class AgentState(TypedDict):
    # ì…ë ¥
    user_id: int
    audio_file_id: int
    stt_result: List[Dict]
    diar_result: Dict
    participant_names: List[str]

    # ì¤‘ê°„ ë°ì´í„°
    previous_profiles: List[Dict]
    auto_matched: Dict[str, str]
    name_mentions: List[Dict]
    speaker_utterances: Dict[str, List[str]]
    mapping_history: List[Dict]

    # ì¶œë ¥
    final_mappings: Dict
    needs_manual_review: List[str]
```

#### Tool êµ¬í˜„ - VoiceSimilarityTool (192ì°¨ì›)
```python
@tool
async def calculate_voice_similarity(new_embedding: List[float],
                                     stored_profiles: List[Dict]) -> Dict:
    """ìŒì„± ì„ë² ë”© ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (192ì°¨ì›)"""
    threshold = 0.85
    new_emb = np.array(new_embedding)

    best_match = None
    best_similarity = 0.0

    for profile in stored_profiles:
        stored_emb = np.array(profile["voice_embedding"])
        similarity = np.dot(new_emb, stored_emb) / (
            np.linalg.norm(new_emb) * np.linalg.norm(stored_emb)
        )

        if similarity > best_similarity:
            best_similarity = similarity
            best_match = profile["name"]

    return {
        "matched_profile": best_match if best_similarity >= threshold else None,
        "similarity": float(best_similarity),
        "threshold_passed": best_similarity >= threshold
    }
```

#### Node êµ¬í˜„ - name_based_tagging (ë©€í‹°í„´ LLM)
```python
async def name_based_tagging_node(state: AgentState) -> AgentState:
    """ì´ë¦„ ê¸°ë°˜ í™”ì íƒœê¹… (ë©€í‹°í„´ LLM ì¶”ë¡ )"""
    name_mentions = state.get("name_mentions", [])
    mapping_history = state.get("mapping_history", [])

    llm = ChatOpenAI(model="gpt-5-mini-2025-08-07", temperature=1.0)
    output_parser = PydanticOutputParser(pydantic_object=SpeakerMappingResult)

    for turn_num, mention in enumerate(name_mentions, 1):
        # í”„ë¡¬í”„íŠ¸ ìƒì„± (ì´ì „ ë¶„ì„ ìš”ì•½ í¬í•¨)
        system_message, user_message = create_name_based_prompt(
            name=mention["name"],
            context_before=mention["context_before"],
            context_after=mention["context_after"],
            participant_names=state["participant_names"],
            mapping_history=mapping_history,
            turn_num=turn_num
        )

        # LLM í˜¸ì¶œ
        response = llm.invoke([
            {"role": "system", "content": system_message},
            {"role": "user", "content": user_message}
        ])

        result_obj = output_parser.parse(response.content)
        mapping_history.append(result_obj)

    state["mapping_history"] = mapping_history
    return state
```

#### Node êµ¬í˜„ - merge_results (ì†Œê±°ë²•)
```python
async def merge_results_node(state: AgentState) -> AgentState:
    """ê²°ê³¼ í†µí•© ë° ì†Œê±°ë²• ì ìš©"""
    final_mappings = {}

    # 1. ìë™ ë§¤ì¹­ëœ í™”ìëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©
    for speaker_label, name in state.get("auto_matched", {}).items():
        final_mappings[speaker_label] = {
            "name": name,
            "confidence": 1.0,
            "match_method": "embedding"
        }

    # 2. name_based_results ì§‘ê³„
    # 3. ì¤‘ë³µ ì œê±° (ê°™ì€ ì´ë¦„ â†’ ë†’ì€ ì‹ ë¢°ë„ ì„ íƒ)
    # 4. ì†Œê±°ë²•: ë‚¨ì€ í™”ì = ë‚¨ì€ ì´ë¦„ì´ 1:1ì¼ ë•Œ ìë™ ë§¤í•‘
    unmatched_speakers = all_speakers - set(final_mappings.keys())
    used_names = {m["name"] for m in final_mappings.values()}
    unused_names = set(participant_names) - used_names

    if len(unmatched_speakers) == len(unused_names) == 1:
        speaker = list(unmatched_speakers)[0]
        name = list(unused_names)[0]
        final_mappings[speaker] = {
            "name": name,
            "confidence": 0.50,
            "match_method": "ì†Œê±°ë²•",
            "needs_review": True
        }

    state["final_mappings"] = final_mappings
    return state
```

### 12.4 Phase 4: ì‘ìš© ë¶„ì„ ì‹¤ì œ êµ¬í˜„

#### íš¨ìœ¨ì„± ë¶„ì„ - TTR (Type-Token Ratio)
```python
def _calc_ttr(self, speaker: SpeakerMapping) -> Dict[str, Any]:
    """TTR ê³„ì‚° (Mecab í˜•íƒœì†Œ ë¶„ì„)"""
    mecab = get_mecab()
    texts = [t.text for t in speaker_transcripts]
    all_text = " ".join(texts)

    # í˜•íƒœì†Œ ë¶„ì„ (ëª…ì‚¬, ë™ì‚¬, í˜•ìš©ì‚¬ë§Œ ì¶”ì¶œ)
    morphs = mecab.pos(all_text)
    content_words = [word for word, pos in morphs
                    if pos.startswith('NN') or pos.startswith('VV') or pos.startswith('VA')]

    # ìŠ¬ë¼ì´ë”© ìœˆë„ìš° TTR ê³„ì‚°
    window_size = min(50, len(content_words) // 2)
    ttr_values = []

    for i in range(0, len(content_words) - window_size + 1, 10):
        window_words = content_words[i:i + window_size]
        ttr = len(set(window_words)) / len(window_words)
        ttr_values.append({"ttr": float(ttr)})

    return {
        "ttr_avg": float(np.mean([v["ttr"] for v in ttr_values])),
        "ttr_std": float(np.std([v["ttr"] for v in ttr_values]))
    }
```

#### íš¨ìœ¨ì„± ë¶„ì„ - Perplexity (KoGPT-2)
```python
def _calc_perplexity(self, speaker: SpeakerMapping) -> Dict[str, Any]:
    """PPL ê³„ì‚° (ì¡°ê±´ë¶€ Perplexity)"""
    model, tokenizer = get_gpt2_model()  # KoGPT-2
    device = next(model.parameters()).device

    ppl_values = []
    for i in range(1, len(speaker_transcripts)):
        # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°: ì´ì „ ë¬¸ì¥ë“¤ â†’ í˜„ì¬ ë¬¸ì¥ PPL
        context_text = " ".join([t.text for t in speaker_transcripts[:i]])
        target_text = speaker_transcripts[i].text

        full_text = context_text + " " + target_text
        encodings = tokenizer(full_text, return_tensors="pt")
        input_ids = encodings["input_ids"].to(device)

        with torch.no_grad():
            outputs = model(input_ids, labels=input_ids)
            loss = outputs.loss.item()

        ppl = np.exp(loss)
        ppl_values.append({"ppl": float(ppl), "loss": float(loss)})

    return {
        "ppl_avg": float(np.mean([v["ppl"] for v in ppl_values])),
        "ppl_std": float(np.std([v["ppl"] for v in ppl_values]))
    }
```

#### RAG ì‹œìŠ¤í…œ - ChromaDB ì´ˆê¸°í™”
```python
class RAGService:
    def store_transcript(self, file_id: str, final_transcript: List[Dict]):
        """íšŒì˜ë¡ì„ ChromaDBì— ì €ì¥"""
        collection_name = f"meeting_{file_id}"

        # Document ê°ì²´ ìƒì„±
        documents = []
        for idx, segment in enumerate(final_transcript):
            doc = Document(
                page_content=segment["text"],
                metadata={
                    "speaker_name": segment["speaker_name"],
                    "start_time": segment["start_time"],
                    "end_time": segment["end_time"],
                    "segment_index": idx
                }
            )
            documents.append(doc)

        # ChromaDBì— ì €ì¥ (OpenAI text-embedding-ada-002)
        vectorstore = Chroma.from_documents(
            documents=documents,
            embedding=OpenAIEmbeddings(),
            collection_name=collection_name,
            persist_directory="./chroma_db"
        )

        return vectorstore
```

#### RAG ì‹œìŠ¤í…œ - ì§ˆë¬¸ ë¶„ì„ (í™”ì ìë™ ì¶”ì¶œ)
```python
def analyze_question(self, question: str, available_speakers: List[str]):
    """ì§ˆë¬¸ì—ì„œ í™”ì ì´ë¦„ ìë™ ì¶”ì¶œ (LLM ê¸°ë°˜)"""
    analysis_prompt = f"""
    ì§ˆë¬¸: {question}
    ì‚¬ìš© ê°€ëŠ¥í•œ ë°œì–¸ì ëª©ë¡: {', '.join(available_speakers)}

    ì´ ì§ˆë¬¸ì´ íŠ¹ì • ë°œì–¸ìì— ê´€í•œ ê²ƒì¸ê°€ìš”?
    ë°œì–¸ì: [ì´ë¦„ ë˜ëŠ” 'ì—†ìŒ']
    """

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": analysis_prompt}]
    )

    # ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­
    for line in response.choices[0].message.content.split("\n"):
        if line.startswith("ë°œì–¸ì:"):
            speaker_name = line.split(":")[1].strip()
            if speaker_name != "ì—†ìŒ":
                matched_speaker = self.find_most_similar_speaker(
                    speaker_name, available_speakers
                )
                return {"detected_speaker": matched_speaker}

    return {"detected_speaker": None}
```

---

## ğŸ“ ë¶€ë¡

### A. í•µì‹¬ ì•Œê³ ë¦¬ì¦˜

#### A.1 ë³‘í•© ë¡œì§ (Max Overlap)

```python
def merge_stt_diarization(stt_segments, diar_turns):
    merged = []

    for stt_seg in stt_segments:
        stt_start = stt_seg['start']
        stt_end = stt_seg['end']

        max_overlap = 0
        assigned_speaker = None

        for turn in diar_turns:
            turn_start = turn['start']
            turn_end = turn['end']

            # ê²¹ì¹˜ëŠ” êµ¬ê°„ ê³„ì‚°
            overlap_start = max(stt_start, turn_start)
            overlap_end = min(stt_end, turn_end)
            overlap_duration = max(0, overlap_end - overlap_start)

            if overlap_duration > max_overlap:
                max_overlap = overlap_duration
                assigned_speaker = turn['speaker_label']

        merged.append({
            'text': stt_seg['text'],
            'start': stt_start,
            'end': stt_end,
            'speaker': assigned_speaker
        })

    return merged
```

#### A.2 ì†Œê±°ë²• (Elimination)

```python
def apply_elimination(unmatched_speakers, remaining_names, utterances):
    if len(unmatched_speakers) != len(remaining_names):
        return {}

    # ë°œí™” íšŸìˆ˜ ê¸°ì¤€ ì •ë ¬
    speaker_counts = {
        sp: len([u for u in utterances if u['speaker'] == sp])
        for sp in unmatched_speakers
    }

    sorted_speakers = sorted(speaker_counts.items(), key=lambda x: x[1], reverse=True)

    # ìˆœì„œëŒ€ë¡œ ë§¤í•‘
    mappings = {}
    for i, (speaker, count) in enumerate(sorted_speakers):
        if count >= 3:  # ìµœì†Œ ë°œí™” íšŸìˆ˜
            mappings[speaker] = {
                'name': remaining_names[i],
                'confidence': 0.50,
                'method': 'ì†Œê±°ë²•',
                'needs_manual_review': True
            }

    return mappings
```

### B. ì„±ëŠ¥ ì§€í‘œ

#### B.1 ëª©í‘œ KPI
- **STT ì •í™•ë„ (WER)**: 90% ì´ìƒ (ë‹¨ì–´ ì˜¤ë¥˜ìœ¨ 10% ë¯¸ë§Œ)
- **í™”ì ì¸ì‹ ì •í™•ë„ (DER)**: 90% ì´ìƒ (í™”ì ì˜¤ë¥˜ìœ¨ 10% ë¯¸ë§Œ)
- **ì²˜ë¦¬ ì†ë„**: ì‹¤ì‹œê°„ ë¹„ìœ¨ 1:3 (30ë¶„ íšŒì˜ â†’ 10ë¶„ ì²˜ë¦¬)

#### B.2 ì‹¤ì œ ì„±ëŠ¥ (í…ŒìŠ¤íŠ¸ ê¸°ì¤€)
- **Whisper large-v3**: WER 5-8% (í•œêµ­ì–´)
- **Senko**: DER 8-12% (2-4ëª… íšŒì˜)
- **í™”ì íƒœê¹…**: 85-90% ì •í™•ë„ (ë©€í‹°í„´ LLM)

### C. ë¹„ìš© ë¶„ì„

#### C.1 AI ëª¨ë¸ ë¹„ìš© (OpenAI API)

| ëª¨ë¸ | ìš©ë„ | ë¹„ìš© (30ë¶„ íšŒì˜ ê¸°ì¤€) |
|------|------|---------------------|
| Whisper API | STT | $0.36 (30ë¶„ Ã— $0.006/ë¶„) |
| GPT-4o | í™”ì íƒœê¹… | $0.05 (5,000 í† í°) |
| GPT-4o-mini | ì¸ì‚¬ì´íŠ¸ ìƒì„± | $0.01 (10,000 í† í°) |
| GPT-4o | RAG ë‹µë³€ | $0.02/ì§ˆë¬¸ |
| **í•©ê³„** | | **ì•½ $0.44** |

#### C.2 ë¡œì»¬ ëª¨ë¸ ì‚¬ìš© ì‹œ
- **Whisper local**: ë¬´ë£Œ (GPU í•„ìš”)
- **Senko**: ë¬´ë£Œ (GPU í•„ìš”)
- **LLM**: API ë¹„ìš©ë§Œ ë°œìƒ

### D. í–¥í›„ ê°œì„  ì‚¬í•­

#### Phase 4: ê³ ë„í™”
1. **ì‹¤ì‹œê°„ ì²˜ë¦¬**: WebSocket ê¸°ë°˜ ì‹¤ì‹œê°„ ì „ì‚¬
2. **ë©€í‹°ëª¨ë‹¬**: ë¹„ë””ì˜¤ + í™”ë©´ ê³µìœ  ë¶„ì„
3. **ë‹¤êµ­ì–´ ì§€ì›**: ì˜ì–´, ì¼ë³¸ì–´, ì¤‘êµ­ì–´
4. **í™”ì ê°ì • ë¶„ì„**: ìŒì„± í†¤ ê¸°ë°˜ ê°ì • ì¸ì‹
5. **íšŒì˜ í’ˆì§ˆ ì ìˆ˜**: ì¢…í•© í‰ê°€ ì§€í‘œ
6. **í”„ë¦¬ì  í…Œì´ì…˜ ëª¨ë“œ**: íšŒì˜ë¡ â†’ PPT ìë™ ìƒì„±
7. **í†µí•© ê²€ìƒ‰**: ì „ì²´ íšŒì˜ë¡ í†µí•© ê²€ìƒ‰
8. **API í”Œë«í¼**: ì™¸ë¶€ ì„œë¹„ìŠ¤ ì—°ë™ API ì œê³µ

---

## ğŸ“š ì°¸ê³  ë¬¸ì„œ

### í”„ë¡œì íŠ¸ ë¬¸ì„œ
- [README.md](../README.md): í”„ë¡œì íŠ¸ ì†Œê°œ
- [architecture.md](./architecture.md): ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ (PDR)
- [pipeline-io.md](./pipeline-io.md): íŒŒì´í”„ë¼ì¸ I/O ì •ì˜
- [agent-workflow.md](./agent-workflow.md): LangGraph Agent ìƒì„¸
- [database-schema.md](./database-schema.md): DB ìŠ¤í‚¤ë§ˆ ìƒì„¸
- [EFFICIENCY_ANALYSIS.md](./EFFICIENCY_ANALYSIS.md): íš¨ìœ¨ì„± ë¶„ì„ ê¸°ëŠ¥
- [CHANGELOG.md](./CHANGELOG.md): ë³€ê²½ ì´ë ¥
- [setup.md](./setup.md): í™˜ê²½ ì„¤ì • ê°€ì´ë“œ

### ì™¸ë¶€ ë¬¸ì„œ
- [Whisper](https://github.com/openai/whisper)
- [pyannote.audio](https://github.com/pyannote/pyannote-audio)
- [LangChain](https://python.langchain.com/)
- [LangGraph](https://langchain-ai.github.io/langgraph/)
- [FastAPI](https://fastapi.tiangolo.com/)
- [React](https://react.dev/)

---

**Last Updated**: 2025-12-01
**ì‘ì„±ì**: Claude Code
**ë²„ì „**: 1.1 (ì‹¤ì œ êµ¬í˜„ ì½”ë“œ ì¶”ê°€)
