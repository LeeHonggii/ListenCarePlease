{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# GETTING READY FOR NICKNAME-TAGGING, IN CASE THAT THERE ARE NOT ENOUGH NAMES MENTIONED"
      ],
      "metadata": {
        "id": "FYwTbNFz4f0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "I1LjPgDsUysW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "outputId": "ea56e68e-bc69-435e-9b1c-fc73c37af656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "7945bf6433a84289a634e8e6c4185c43"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üî¥ [ÌïÑÏàò] ÏúÑ ÏÑ§ÏπòÍ∞Ä ÏôÑÎ£åÎêòÎ©¥ ÏÉÅÎã® Î©îÎâ¥ 'Îü∞ÌÉÄÏûÑ' > 'ÏÑ∏ÏÖò Îã§Ïãú ÏãúÏûë'ÏùÑ ÌÅ¥Î¶≠ÌïòÏÑ∏Ïöî!\n",
            "üî¥ Í∑∏ ÌõÑ, Ïù¥ ÏÖÄÏùÄ Í±¥ÎÑàÎõ∞Í≥† Îã§Ïùå ÏÖÄ(Ìè¥Îçî ÏÑ∏ÌåÖ)Î∂ÄÌÑ∞ Ïã§ÌñâÌïòÏÑ∏Ïöî.\n"
          ]
        }
      ],
      "source": [
        "# Numpy Îã§Ïö¥Í∑∏Î†àÏù¥Îìú; 'ÏÑ∏ÏÖò Ïû¨ÏãúÏûë'Ìï¥Ïïº Ìï† Ïàò ÏûàÏùå ---> (ÏÑ∏ÏÖò Ïû¨ÏãúÏûë Ïãú,) \"Ìå®ÌÇ§ÏßÄ ÏÑ§Ïπò\" Îã®Í≥ÑÎäî Îã§Ïãú Ïã§ÌñâÌïòÎ©¥ ÏïàÎê®!\n",
        "# Ï£ºÏùò!!! 'ÏÑ∏ÏÖò Ïû¨ÏãúÏûë'Ïù¥ ÏïÑÎãàÎùº, 'Îü∞ÌÉÄÏûÑ Ïó∞Í≤∞ Ìï¥Ï≤¥ Î∞è ÏÇ≠Ï†ú' ÌõÑ Îã§Ïãú Ïó∞Í≤∞Ìïú Í≤ÉÏù¥ÎùºÎ©¥ \"Ìå®ÌÇ§ÏßÄ ÏÑ§Ïπò\" Îã®Í≥ÑÎ•º Î∞òÎìúÏãú Îã§Ïãú Ïã§ÏãúÌï¥Ïïº Ìï®!\n",
        "!pip install numpy==1.26.4\n",
        "\n",
        "print(\"\\nüî¥ [ÌïÑÏàò] ÏúÑ ÏÑ§ÏπòÍ∞Ä ÏôÑÎ£åÎêòÎ©¥ ÏÉÅÎã® Î©îÎâ¥ 'Îü∞ÌÉÄÏûÑ' > 'ÏÑ∏ÏÖò Îã§Ïãú ÏãúÏûë'ÏùÑ ÌÅ¥Î¶≠ÌïòÏÑ∏Ïöî!\")\n",
        "print(\"üî¥ Í∑∏ ÌõÑ, Ïù¥ ÏÖÄÏùÄ Í±¥ÎÑàÎõ∞Í≥† Îã§Ïùå ÏÖÄ(Ìè¥Îçî ÏÑ∏ÌåÖ)Î∂ÄÌÑ∞ Ïã§ÌñâÌïòÏÑ∏Ïöî.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bDONjkDdU_uK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Ìè¥Îçî ÏÑ∏ÌåÖ ===\n",
        "import os, subprocess, json, math, re, pandas as pd\n",
        "BASE = \"/content\"\n",
        "AUDIO_DIR = f\"{BASE}/audio\"\n",
        "WORK = f\"{BASE}/work\"\n",
        "OUT = f\"{WORK}/outputs\"\n",
        "CACHE = f\"{WORK}/cache\"\n",
        "for d in [AUDIO_DIR, OUT, CACHE]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "SU9MFDSzU_r6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6ccqlZLGU_pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Ïò§ÎîîÏò§ ÌååÏùº ÏÑ§Ï†ï (ÎìúÎùºÏù¥Î∏å Ïó∞Îèô or ÏßÅÏ†ë ÏóÖÎ°úÎìú) ===\n",
        "import os, shutil\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "# 1. Í∏∞Î≥∏ ÏÑ§Ï†ï\n",
        "target_filename = \"1107 Ïï†ÏäêÎ¶¨_ÏÜåÏùå\"  # ÌôïÏû•Ïûê Ï†úÏô∏Ìïú ÌååÏùºÎ™Ö (ÌåÄÏõêÎì§Í≥º Ìï©ÏùòÎêú Ïù¥Î¶Ñ)\n",
        "extensions = [\".m4a\", \".wav\", \".mp3\", \".aac\", \".flac\", \".ogg\"]\n",
        "\n",
        "# 2. ÎìúÎùºÏù¥Î∏å ÎßàÏö¥Ìä∏ ÏãúÎèÑ\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# 3. ÌååÏùº Ï∞æÍ∏∞ (Í≤ΩÎ°úÎ•º Ï¢Ä Îçî Ïú†Ïó∞ÌïòÍ≤å ÏÑ§Ï†ïÌïòÍ±∞ÎÇò, ÏóÜÏúºÎ©¥ ÏóÖÎ°úÎìú ÏöîÏ≤≠)\n",
        "# ÌåÄÏõêÎßàÎã§ Í≤ΩÎ°úÍ∞Ä Îã§Î•º Ïàò ÏûàÏúºÎØÄÎ°ú, ÎìúÎùºÏù¥Î∏å ÎÇ¥ ÌäπÏ†ï Í≤ΩÎ°úÎ•º Ï∞æÏßÄ Î™ªÌïòÎ©¥ ÏóÖÎ°úÎìúÌïòÍ≤å Ïú†ÎèÑÌï©ÎãàÎã§.\n",
        "drive_dir = \"/content/drive/MyDrive/final project/audio files\" # ÌåÄÏõê Í≥µÌÜµ Í≤ΩÎ°ú\n",
        "found_path = None\n",
        "\n",
        "# ÎìúÎùºÏù¥Î∏åÏóêÏÑú ÌååÏùº ÌÉêÏÉâ\n",
        "if os.path.exists(drive_dir):\n",
        "    for ext in extensions:\n",
        "        check_path = os.path.join(drive_dir, target_filename + ext)\n",
        "        if os.path.exists(check_path):\n",
        "            found_path = check_path\n",
        "            break\n",
        "\n",
        "# 4. Í≤∞Í≥º Ï≤òÎ¶¨\n",
        "if found_path:\n",
        "    print(f\"‚úÖ Íµ¨Í∏Ä ÎìúÎùºÏù¥Î∏åÏóêÏÑú ÌååÏùºÏùÑ Ï∞æÏïòÏäµÎãàÎã§: {found_path}\")\n",
        "    dst_path = os.path.join(AUDIO_DIR, os.path.basename(found_path))\n",
        "    shutil.copy2(found_path, dst_path)\n",
        "    AUDIO_IN = dst_path\n",
        "else:\n",
        "    print(f\"‚ùå ÎìúÎùºÏù¥Î∏å Í≤ΩÎ°úÏóê '{target_filename}' ÌååÏùºÏù¥ ÏóÜÏäµÎãàÎã§.\")\n",
        "    print(\"üëá ÏïÑÎûò Î≤ÑÌäºÏùÑ ÎàåÎü¨ Ïò§ÎîîÏò§ ÌååÏùºÏùÑ ÏßÅÏ†ë ÏóÖÎ°úÎìúÌï¥Ï£ºÏÑ∏Ïöî.\")\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        fname = list(uploaded.keys())[0]\n",
        "        AUDIO_IN = os.path.join(BASE, fname) # ÏóÖÎ°úÎìúÎêú ÌååÏùº Í≤ΩÎ°ú\n",
        "        # audio Ìè¥ÎçîÎ°ú Ïù¥Îèô\n",
        "        shutil.move(AUDIO_IN, os.path.join(AUDIO_DIR, fname))\n",
        "        AUDIO_IN = os.path.join(AUDIO_DIR, fname)\n",
        "    else:\n",
        "        raise FileNotFoundError(\"ÌååÏùºÏù¥ ÏóÖÎ°úÎìúÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.\")\n",
        "\n",
        "print(f\"üéØ ÏµúÏ¢Ö Î∂ÑÏÑù ÎåÄÏÉÅ ÌååÏùº: {AUDIO_IN}\")"
      ],
      "metadata": {
        "id": "2HaoB5v-U_mp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "442d44d2-d2e7-4d9b-fc90-bdcd73122b1b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Íµ¨Í∏Ä ÎìúÎùºÏù¥Î∏åÏóêÏÑú ÌååÏùºÏùÑ Ï∞æÏïòÏäµÎãàÎã§: /content/drive/MyDrive/final project/audio files/1107 Ïï†ÏäêÎ¶¨_ÏÜåÏùå.m4a\n",
            "üéØ ÏµúÏ¢Ö Î∂ÑÏÑù ÎåÄÏÉÅ ÌååÏùº: /content/audio/1107 Ïï†ÏäêÎ¶¨_ÏÜåÏùå.m4a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nC5MxQ0WU_kR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Ìå®ÌÇ§ÏßÄ ÏÑ§Ïπò (ÏàòÏ†ïÎêú ÏàúÏÑú) ---\n",
        "# 'ÏÑ∏ÏÖò Ïû¨ÏãúÏûë' ÌõÑ Îã§Ïãú ÏãúÏûë Í∏àÏßÄ!!!! but 'Îü∞ÌÉÄÏûÑ Ïó∞Í≤∞Ìï¥Ï†ú' ÌõÑ Îü∞ÌÉÄÏûÑ Ïû¨Ïó∞Í≤∞ÌñàÏúºÎ©¥ Í∑∏ÎïåÎäî Íº≠ Ïã§ÌñâÌï¥Ïïº Ìï®!\n",
        "\n",
        "print(\"--- 1. Colab Í∏∞Î≥∏ Ìå®ÌÇ§ÏßÄ Ìò∏ÌôòÏÑ± ÏÑ§Ï†ï (Pandas) ---\")\n",
        "# google-colabÏù¥ ÏöîÍµ¨ÌïòÎäî pandas==2.2.2 Î≤ÑÏ†ÑÏùÑ Î®ºÏ†Ä ÏÑ§ÏπòÌï©ÎãàÎã§.\n",
        "# (Ïù¥Ï†Ñ ÏóêÎü¨ Î©îÏãúÏßÄÏóêÏÑú Ï∂©ÎèåÏùò Ï£º ÏõêÏù∏Ïù¥ÏóàÏäµÎãàÎã§.)\n",
        "!pip install pandas==2.2.2\n",
        "\n",
        "print(\"--- 2. Diarization Î™®Îìà ÏÑ§Ïπò (NVIDIA NeMo) ---\")\n",
        "# ÏùòÏ°¥ÏÑ±Ïù¥ Í∞ÄÏû• Î¨¥Í≤ÅÍ≥† PyTorch Î≤ÑÏ†ÑÏóê ÎØºÍ∞êÌïú NeMoÎ•º Î®ºÏ†Ä ÏÑ§ÏπòÌï©ÎãàÎã§.\n",
        "# NeMoÍ∞Ä ÌïÑÏöîÌïú torch, numpy Î≤ÑÏ†ÑÏùÑ ÏûêÎèôÏúºÎ°ú ÏÑ§ÏπòÌïòÎèÑÎ°ù Ìï©ÎãàÎã§.\n",
        "!pip -q install \"nemo_toolkit[asr]\"\n",
        "\n",
        "print(\"--- 3. STT Î™®Îìà ÏÑ§Ïπò (Whisper) ---\")\n",
        "# NeMoÍ∞Ä ÏÑ§ÏπòÌïú PyTorch ÌôòÍ≤Ω ÏúÑÏóêÏÑú STT ÎùºÏù¥Î∏åÎü¨Î¶¨Î•º ÏÑ§ÏπòÌï©ÎãàÎã§.\n",
        "# --upgrade ÏòµÏÖòÏùÄ NeMoÏùò PyTorchÎ•º Î≥ÄÍ≤ΩÏãúÌÇ¨ Ïàò ÏûàÏúºÎØÄÎ°ú Ï†úÏô∏ÌïòÍ±∞ÎÇò Ï£ºÏùòÌï©ÎãàÎã§.\n",
        "!pip install -q openai-whisper faster-whisper torchaudio librosa soundfile\n",
        "\n",
        "print(\"--- ÏÑ§Ïπò ÏôÑÎ£å ---\")"
      ],
      "metadata": {
        "id": "YXigtiv6U_h7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c773dd5c-7ffb-4281-b0ca-4523065d6808"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. Colab Í∏∞Î≥∏ Ìå®ÌÇ§ÏßÄ Ìò∏ÌôòÏÑ± ÏÑ§Ï†ï (Pandas) ---\n",
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
            "--- 2. Diarization Î™®Îìà ÏÑ§Ïπò (NVIDIA NeMo) ---\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m95.7/95.7 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m866.5/866.5 kB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m419.8/419.8 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m48.3/48.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m132.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m124.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m93.0/93.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m120.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m753.1/753.1 kB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m126.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m120.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m831.6/831.6 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ctc_segmentation (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for texterrors (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for kaldi-python-io (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m--- 3. STT Î™®Îìà ÏÑ§Ïπò (Whisper) ---\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "--- ÏÑ§Ïπò ÏôÑÎ£å ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pXZwnXV1U_fZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ï†ÑÏ≤òÎ¶¨ ‚Äî 16kHz Î™®ÎÖ∏ WAV ÏÉùÏÑ±\n",
        "\n",
        "# ffmpegÎ°ú 16kHz mono wav ÏÉùÏÑ±\n",
        "WAV_16K = f\"{CACHE}/meeting_16k.wav\"\n",
        "!ffmpeg -y -i \"$AUDIO_IN\" -ac 1 -ar 16000 \"$WAV_16K\" >/dev/null 2>&1\n",
        "print(\"WAV_16K =\", WAV_16K)\n"
      ],
      "metadata": {
        "id": "xHtXGh5HU_c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4647b138-28a4-46e1-ac1f-5e353c4870e9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WAV_16K = /content/work/cache/meeting_16k.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ofqPukhvU_aZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Diarization\n",
        "# 5-1) ÏùºÎ∞ò inferenceÏö© YAML Îã§Ïö¥Î°úÎìú\n",
        "!wget -qO {WORK}/diar_infer_general.yaml \\\n",
        "  https://raw.githubusercontent.com/NVIDIA/NeMo/stable/examples/speaker_tasks/diarization/conf/inference/diar_infer_general.yaml\n",
        "\n",
        "# 5-2) NeMo manifest ÏÉùÏÑ±(JSON lines)\n",
        "import json\n",
        "manifest = f\"{WORK}/manifest.json\"\n",
        "meta = {\n",
        "    \"audio_filepath\": WAV_16K,\n",
        "    \"offset\": 0, \"duration\": None,\n",
        "    \"label\": \"infer\", \"text\": \"-\",\n",
        "    \"num_speakers\": None,      # Î™®Î•¥Î©¥ None, ÏïåÎ©¥ Ï†ïÏàò(Ïòà: 5)\n",
        "    \"rttm_filepath\": None, \"uem_filepath\": None\n",
        "}\n",
        "with open(manifest, \"w\") as f:\n",
        "    f.write(json.dumps(meta) + \"\\n\")\n",
        "\n",
        "# 5-3) ClusteringDiarizer Ïã§Ìñâ\n",
        "from omegaconf import OmegaConf\n",
        "from nemo.collections.asr.models import ClusteringDiarizer\n",
        "\n",
        "cfg = OmegaConf.load(f\"{WORK}/diar_infer_general.yaml\")\n",
        "cfg.diarizer.manifest_filepath = manifest\n",
        "cfg.diarizer.out_dir = OUT\n",
        "# ÌïÑÏöî Ïãú ÏÉÅÌïúÎßå ÏßÄÏ†ï(ÏÑ†ÌÉù): cfg.diarizer.clustering.parameters.max_num_speakers = 10\n",
        "\n",
        "sd = ClusteringDiarizer(cfg=cfg)\n",
        "sd.diarize()\n",
        "print(\"NeMo diarization done. OUT dir:\", OUT)\n"
      ],
      "metadata": {
        "id": "gn1PGdFGU_YB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d4f7faf-4b27-4d42-98ae-8120e04a0fd4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2025-11-14 06:36:20 nemo_logging:405] Megatron num_microbatches_calculator not found, using Apex version.\n",
            "WARNING:nv_one_logger.api.config:OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.\n",
            "WARNING:nv_one_logger.training_telemetry.api.training_telemetry_provider:No exporters were provided. This means that no telemetry data will be collected.\n",
            "[NeMo W 2025-11-14 06:36:23 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:300: SyntaxWarning: invalid escape sequence '\\('\n",
            "      m = re.match('([su]([0-9]{1,2})p?) \\(([0-9]{1,2}) bit\\)$', token)\n",
            "    \n",
            "[NeMo W 2025-11-14 06:36:23 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:301: SyntaxWarning: invalid escape sequence '\\('\n",
            "      m2 = re.match('([su]([0-9]{1,2})p?)( \\(default\\))?$', token)\n",
            "    \n",
            "[NeMo W 2025-11-14 06:36:23 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:310: SyntaxWarning: invalid escape sequence '\\('\n",
            "      elif re.match('(flt)p?( \\(default\\))?$', token):\n",
            "    \n",
            "[NeMo W 2025-11-14 06:36:23 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:314: SyntaxWarning: invalid escape sequence '\\('\n",
            "      elif re.match('(dbl)p?( \\(default\\))?$', token):\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-11-14 06:36:25 nemo_logging:393] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2025-11-14 06:36:25 nemo_logging:393] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemo/vad_multilingual_marblenet/versions/1.10.0/files/vad_multilingual_marblenet.nemo to /root/.cache/torch/NeMo/NeMo_2.5.3/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2025-11-14 06:36:25 nemo_logging:393] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2025-11-14 06:36:25 nemo_logging:405] Please use the EncDecSpeakerLabelModel instead of this model. EncDecClassificationModel model is kept for backward compatibility with older models.\n",
            "[NeMo W 2025-11-14 06:36:25 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2025-11-14 06:36:25 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2025-11-14 06:36:25 nemo_logging:405] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-11-14 06:36:25 nemo_logging:393] PADDING: 16\n",
            "[NeMo I 2025-11-14 06:36:26 nemo_logging:393] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.5.3/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2025-11-14 06:36:26 nemo_logging:393] Loading pretrained titanet_large model from NGC\n",
            "[NeMo I 2025-11-14 06:36:26 nemo_logging:393] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemo/titanet_large/versions/v1/files/titanet-l.nemo to /root/.cache/torch/NeMo/NeMo_2.5.3/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n",
            "[NeMo I 2025-11-14 06:36:32 nemo_logging:393] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2025-11-14 06:36:33 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n",
            "    sample_rate: 16000\n",
            "    labels: null\n",
            "    batch_size: 64\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      noise:\n",
            "        manifest_path: /manifests/noise/rir_noise_manifest.json\n",
            "        prob: 0.5\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 15\n",
            "      speed:\n",
            "        prob: 0.5\n",
            "        sr: 16000\n",
            "        resample_type: kaiser_fast\n",
            "        min_speed_rate: 0.95\n",
            "        max_speed_rate: 1.05\n",
            "    num_workers: 15\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2025-11-14 06:36:33 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n",
            "    sample_rate: 16000\n",
            "    labels: null\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    num_workers: 15\n",
            "    pin_memory: true\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-11-14 06:36:33 nemo_logging:393] PADDING: 16\n",
            "[NeMo I 2025-11-14 06:36:33 nemo_logging:393] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.5.3/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n",
            "[NeMo I 2025-11-14 06:36:33 nemo_logging:393] Number of files to diarize: 1\n",
            "[NeMo I 2025-11-14 06:36:33 nemo_logging:393] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-11-14 06:36:44 nemo_logging:393] Perform streaming frame-level VAD\n",
            "[NeMo I 2025-11-14 06:36:44 nemo_logging:393] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2025-11-14 06:36:44 nemo_logging:393] Dataset successfully loaded with 51 items and total duration provided from manifest is  0.71 hours.\n",
            "[NeMo I 2025-11-14 06:36:44 nemo_logging:393] # 51 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 51/51 [00:09<00:00,  5.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-11-14 06:36:53 nemo_logging:393] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "creating speech segments: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-11-14 06:36:54 nemo_logging:393] Subsegmentation for embedding extraction: scale0, /content/work/outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2025-11-14 06:36:54 nemo_logging:393] Extracting embeddings for Diarization\n",
            "[NeMo I 2025-11-14 06:36:54 nemo_logging:393] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2025-11-14 06:36:54 nemo_logging:393] Dataset successfully loaded with 1749 items and total duration provided from manifest is  0.85 hours.\n",
            "[NeMo I 2025-11-14 06:36:54 nemo_logging:393] # 1749 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/3] extract embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:06<00:00,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-11-14 06:37:00 nemo_logging:393] Saved embedding files to /content/work/outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2025-11-14 06:37:00 nemo_logging:393] Subsegmentation for embedding extraction: scale1, /content/work/outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2025-11-14 06:37:00 nemo_logging:393] Extracting embeddings for Diarization\n",
            "[NeMo I 2025-11-14 06:37:00 nemo_logging:393] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2025-11-14 06:37:00 nemo_logging:393] Dataset successfully loaded with 2809 items and total duration provided from manifest is  0.90 hours.\n",
            "[NeMo I 2025-11-14 06:37:00 nemo_logging:393] # 2809 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/3] extract embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [00:05<00:00,  7.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-11-14 06:37:06 nemo_logging:393] Saved embedding files to /content/work/outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2025-11-14 06:37:06 nemo_logging:393] Subsegmentation for embedding extraction: scale2, /content/work/outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2025-11-14 06:37:06 nemo_logging:393] Extracting embeddings for Diarization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-11-14 06:37:06 nemo_logging:393] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2025-11-14 06:37:06 nemo_logging:393] Dataset successfully loaded with 6966 items and total duration provided from manifest is  0.95 hours.\n",
            "[NeMo I 2025-11-14 06:37:06 nemo_logging:393] # 6966 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/3] extract embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 109/109 [00:06<00:00, 15.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-11-14 06:37:14 nemo_logging:393] Saved embedding files to /content/work/outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-11-14 06:37:17 nemo_logging:393] Outputs are saved in /content/work/outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2025-11-14 06:37:17 nemo_logging:405] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeMo diarization done. OUT dir: /content/work/outputs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FlUpYXxYU_Vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RTTM ÌååÏùº Ï∞æÍ∏∞ & ÌååÏã±\n",
        "\n",
        "import glob, os, json\n",
        "\n",
        "# OUTÎäî ÏïûÏóêÏÑú Ï†ïÏùòÌïú /content/work/outputs\n",
        "rttms = sorted(glob.glob(f\"{OUT}/**/*.rttm\", recursive=True), key=os.path.getmtime)\n",
        "assert rttms, \"RTTM not found under OUT. Check diarization step.\"\n",
        "rttm_path = rttms[-1]\n",
        "print(\"Using RTTM:\", rttm_path)\n",
        "\n",
        "def load_rttm(rttm_path):\n",
        "    segs = []\n",
        "    with open(rttm_path,\"r\") as f:\n",
        "        for line in f:\n",
        "            p = line.strip().split()\n",
        "            if not p or p[0]!=\"SPEAKER\" or len(p)<9:\n",
        "                continue\n",
        "            start = float(p[3]); dur = float(p[4]); spk = p[7]\n",
        "            segs.append({\"speaker\": spk, \"start\": start, \"end\": start+dur})\n",
        "    return sorted(segs, key=lambda x: x[\"start\"])\n",
        "\n",
        "segments = load_rttm(rttm_path)\n",
        "print(\"segments:\", len(segments), \"| sample:\", segments[:3])\n"
      ],
      "metadata": {
        "id": "gii67hdNU_TB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bedd310c-fa21-46dd-e348-6d39a9e65699"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using RTTM: /content/work/outputs/pred_rttms/meeting_16k.rttm\n",
            "segments: 1100 | sample: [{'speaker': 'speaker_2', 'start': 0.0, 'end': 0.625}, {'speaker': 'speaker_0', 'start': 0.625, 'end': 3.375}, {'speaker': 'speaker_1', 'start': 3.375, 'end': 4.85}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GeS8zzUiU_Qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STT Îã®Ïñ¥ ÌååÏùº(ÏóÜÏúºÎ©¥ ÏßÄÍ∏à ÏÉùÏÑ±): Ïù¥ÎØ∏ WhisperÎ•º ÎèåÎ†§ stt_words.jsonÏù¥ ÏûàÎã§Î©¥ Î°úÎìúÎßå ÌïòÏÑ∏Ïöî. ÏóÜÎã§Î©¥ Ïù¥ ÏÖÄÎ°ú Í≥ßÏû• ÎßåÎì≠ÎãàÎã§.\n",
        "\n",
        "import os, json\n",
        "\n",
        "stt_words_path = f\"{OUT}/stt_words.json\"\n",
        "if not os.path.exists(stt_words_path):\n",
        "    import whisper\n",
        "    whisp = whisper.load_model(\"medium\")  # VRAM Ïó¨Ïú†Î©¥ \"large-v3\"\n",
        "    stt = whisp.transcribe(WAV_16K, language=\"ko\", word_timestamps=True)\n",
        "    words = []\n",
        "    for seg in stt.get(\"segments\", []):\n",
        "        if \"words\" in seg:\n",
        "            for w in seg[\"words\"]:\n",
        "                words.append({\"text\": w[\"word\"], \"start\": float(w[\"start\"]), \"end\": float(w[\"end\"])})\n",
        "        else:\n",
        "            words.append({\"text\": seg[\"text\"], \"start\": float(seg[\"start\"]), \"end\": float(seg[\"end\"])})\n",
        "    with open(stt_words_path,\"w\",encoding=\"utf-8\") as f:\n",
        "        json.dump(words, f, ensure_ascii=False, indent=2)\n",
        "    print(\"Created:\", stt_words_path, \"count:\", len(words))\n",
        "else:\n",
        "    print(\"Found:\", stt_words_path)\n"
      ],
      "metadata": {
        "id": "iLcq1qYKU_OB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52843770-ff5d-426d-b44d-078cd6f5315a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.42G/1.42G [00:06<00:00, 243MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created: /content/work/outputs/stt_words.json count: 1953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q2hfoJcX39I1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Î≥ëÌï© (Îã®Ïñ¥ --- ÌôîÏûê, Max-overlap)\n",
        "\n",
        "import bisect, json\n",
        "\n",
        "with open(stt_words_path,\"r\",encoding=\"utf-8\") as f:\n",
        "    words = json.load(f)\n",
        "\n",
        "starts = [s[\"start\"] for s in segments]\n",
        "def find_speaker(ws, we):\n",
        "    i = max(0, bisect.bisect_right(starts, ws)-1)\n",
        "    best, best_ov = None, 0.0\n",
        "    for j in range(i, min(i+6, len(segments))):\n",
        "        s = segments[j]\n",
        "        ov = max(0.0, min(we, s[\"end\"]) - max(ws, s[\"start\"]))\n",
        "        if ov > best_ov:\n",
        "            best_ov, best = ov, s[\"speaker\"]\n",
        "        if s[\"start\"] > we: break\n",
        "    return best or \"UNKNOWN\"\n",
        "\n",
        "for w in words:\n",
        "    w[\"speaker\"] = find_speaker(w[\"start\"], w[\"end\"])\n",
        "\n",
        "utter = []\n",
        "if words:\n",
        "    cur = {\"speaker\": words[0][\"speaker\"], \"start\": words[0][\"start\"], \"end\": words[0][\"end\"], \"text\": words[0][\"text\"].strip()}\n",
        "    for w in words[1:]:\n",
        "        contiguous = (w[\"speaker\"] == cur[\"speaker\"]) and (w[\"start\"] - cur[\"end\"] <= 0.8)\n",
        "        if contiguous:\n",
        "            cur[\"text\"] += (\"\" if cur[\"text\"].endswith((\" \", \"\")) else \" \") + w[\"text\"].strip()\n",
        "            cur[\"end\"]  = w[\"end\"]\n",
        "        else:\n",
        "            utter.append(cur);\n",
        "            cur = {\"speaker\": w[\"speaker\"], \"start\": w[\"start\"], \"end\": w[\"end\"], \"text\": w[\"text\"].strip()}\n",
        "    utter.append(cur)\n",
        "\n",
        "with open(f\"{OUT}/final_transcript.json\",\"w\",encoding=\"utf-8\") as f:\n",
        "    json.dump(utter, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"final_transcript.json saved:\", len(utter))\n",
        "print(\"peek:\", utter[:2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuLlILtu39GN",
        "outputId": "3c018729-80a9-4457-e9b7-85334785f353"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final_transcript.json saved: 613\n",
            "peek: [{'speaker': 'speaker_1', 'start': 7.300000000000001, 'end': 9.98, 'text': 'ÎßõÏûàÍ≤åÎìúÏÑ∏ÏöîÏûò'}, {'speaker': 'speaker_0', 'start': 9.98, 'end': 14.6, 'text': 'ÎìúÏÑ∏Ïöî'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L08T_QUB39Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (ÏÑ†ÌÉùÏÇ¨Ìï≠)\n",
        "# Îπ†Î•∏ Ï†êÍ≤Ä & SRT Ï∂úÎ†•\n",
        "\n",
        "# Ïä§ÌîºÏª§Î≥Ñ Ï¥ù Î∞úÌôî ÏãúÍ∞Ñ/ÌÑ¥ Ïàò\n",
        "from collections import defaultdict\n",
        "stats = defaultdict(lambda: {\"dur\":0.0,\"utt\":0})\n",
        "for u in utter:\n",
        "    stats[u[\"speaker\"]][\"dur\"] += (u[\"end\"]-u[\"start\"])\n",
        "    stats[u[\"speaker\"]][\"utt\"] += 1\n",
        "print({k: (round(v[\"dur\"],1), v[\"utt\"]) for k,v in stats.items()})\n",
        "\n",
        "# SRT ÎÇ¥Î≥¥ÎÇ¥Í∏∞\n",
        "def srt_ts(sec):\n",
        "    h = int(sec//3600); sec -= h*3600\n",
        "    m = int(sec//60); sec -= m*60\n",
        "    s = int(sec); ms = int(round((sec - s)*1000))\n",
        "    return f\"{h:02d}:{m:02d}:{s:02d},{ms:03d}\"\n",
        "\n",
        "srt_lines = []\n",
        "for i,u in enumerate(utter,1):\n",
        "    head = f\"{srt_ts(u['start'])} --> {srt_ts(u['end'])}\"\n",
        "    text = f\"[{u['speaker']}] {u['text'].strip()}\"\n",
        "    srt_lines += [str(i), head, text, \"\"]\n",
        "srt_path = f\"{OUT}/meeting.srt\"\n",
        "with open(srt_path,\"w\",encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(srt_lines))\n",
        "print(\"SRT saved:\", srt_path)\n"
      ],
      "metadata": {
        "id": "VUCcC-vw39A9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0ESpANkW38-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Í≤ΩÎ°ú Î≥µÍµ¨ & Ï†êÍ≤Ä ===\n",
        "import os, json\n",
        "BASE  = \"/content\"\n",
        "WORK  = f\"{BASE}/work\"\n",
        "OUT   = f\"{WORK}/outputs\"\n",
        "CACHE = f\"{WORK}/cache\"\n",
        "for d in (WORK, OUT, CACHE): os.makedirs(d, exist_ok=True)\n",
        "\n",
        "final_json_path = f\"{OUT}/final_transcript.json\"\n",
        "assert os.path.exists(final_json_path), f\"ÌïÑÏöî ÌååÏùº ÏóÜÏùå: {final_json_path}\"\n",
        "print(\"OK:\", final_json_path, \"exists\")\n"
      ],
      "metadata": {
        "id": "dXGDP3s8387k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CiN_qq7t384-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# Nickname-Tagging: Í∑úÏπô ÏóîÏßÑ + ÎåÄÌëú Î∞úÌôî Ï∂îÏ∂ú\n",
        "# =========================================\n",
        "import os, re, json, math, unicodedata\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from google.colab import files\n",
        "\n",
        "OUT_DIR = OUT if 'OUT' in globals() else '/content/work/outputs'\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# ----- 0) Ïú†Ìã∏ -----\n",
        "_PUNCT_RE = re.compile(r'[^\\w\\s„Ñ±-Ìû£?!.~‚Ä¶]+')\n",
        "def _clean(txt:str)->str:\n",
        "    txt = unicodedata.normalize(\"NFKC\", str(txt)).strip()\n",
        "    return _PUNCT_RE.sub('', txt)\n",
        "\n",
        "def _sec(x):\n",
        "    try:\n",
        "        return float(x)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "# ----- 1) ÌååÏÑú: Îëê Ï¢ÖÎ•ò Ìè¨Îß∑ ÏûêÎèô Ïù∏Ïãù -----\n",
        "PAT_BRACKET = re.compile(\n",
        "    r'^\\[(?P<label>[^\\]]+)\\]:\\s*\\((?P<start>[\\d.]+)s\\s*-\\s*(?P<end>[\\d.]+)s\\)\\s*(?P<text>.*)$'\n",
        ")\n",
        "PAT_KR = re.compile(\n",
        "    r'^(?:ÌôîÏûê|Ïä§ÌîºÏª§)\\s*(?P<label>[A-Za-z0-9_Í∞Ä-Ìû£]+)\\s*:\\s*(?P<text>.*)$'\n",
        ")\n",
        "\n",
        "def load_diarized_to_df(path:str)->pd.DataFrame:\n",
        "    rows = []\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        lines = [l.rstrip('\\n') for l in f if l.strip()]\n",
        "    mode = None\n",
        "    # Ìè¨Îß∑ Í∞êÏßÄ\n",
        "    for l in lines[:10]:\n",
        "        if PAT_BRACKET.match(l):\n",
        "            mode = 'bracket'; break\n",
        "        if PAT_KR.match(l):\n",
        "            mode = 'kr'; break\n",
        "    if mode is None:\n",
        "        raise ValueError(\"ÏßÄÏõêÌïòÏßÄ ÏïäÎäî Ìè¨Îß∑ÏûÖÎãàÎã§. ÌååÏùº ÏïûÎ∂ÄÎ∂ÑÏùÑ ÌôïÏù∏Ìï¥ Ï£ºÏÑ∏Ïöî.\")\n",
        "\n",
        "    idx = 0\n",
        "    for l in lines:\n",
        "        if mode=='bracket':\n",
        "            m = PAT_BRACKET.match(l)\n",
        "            if not m: continue\n",
        "            spk = m.group('label').strip()\n",
        "            st  = _sec(m.group('start'))\n",
        "            en  = _sec(m.group('end'))\n",
        "            txt = _clean(m.group('text'))\n",
        "            rows.append({'order':idx, 'speaker':spk, 'start':st, 'end':en, 'text':txt})\n",
        "            idx += 1\n",
        "        else:\n",
        "            m = PAT_KR.match(l)\n",
        "            if not m: continue\n",
        "            spk = m.group('label').strip()\n",
        "            txt = _clean(m.group('text'))\n",
        "            rows.append({'order':idx, 'speaker':f'SPEAKER_{spk}', 'start':np.nan, 'end':np.nan, 'text':txt})\n",
        "            idx += 1\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    if df.empty:\n",
        "        raise ValueError(\"ÌååÏã±Îêú Î∞úÌôîÍ∞Ä ÏóÜÏäµÎãàÎã§.\")\n",
        "    # Í∏∏Ïù¥/Îã®Ïñ¥Ïàò\n",
        "    df['char_len'] = df['text'].str.len()\n",
        "    df['word_len'] = df['text'].str.split().apply(len)\n",
        "    # Íµ¨ÎëêÏ†ê Ï†úÍ±∞Ìïú ÏßßÏùÄ ÌÜ†ÌÅ∞(Î∞±Ï±ÑÎÑê ÌåêÏ†ïÏóê ÏÇ¨Ïö©)\n",
        "    df['text_core'] = df['text'].str.replace(r'[^\\w\\s„Ñ±-Ìû£]+','',regex=True).str.strip()\n",
        "\n",
        "    # duration\n",
        "    if 'start' in df and 'end' in df:\n",
        "        df['dur'] = df['end'] - df['start']\n",
        "    else:\n",
        "        df['dur'] = np.nan\n",
        "    return df.sort_values(['order']).reset_index(drop=True)\n",
        "\n",
        "# ----- 2) Í∑úÏπô ÏóîÏßÑÏùÑ ÏúÑÌïú ÌäπÏßïÎüâ -----\n",
        "BACKCHANNEL_LIST = [\n",
        "    \"ÎÑ§\",\"ÎÑµ\",\"Ïòà\",\"Ïùë\",\"Ïùå\",\"ÏïÑ\",\"Ïñ¥\",\"Ïò§\",\"Ïö∞ÏôÄ\",\n",
        "    \"ÎßûÏïÑ\",\"ÎßûÏïÑÏöî\",\"ÎßûÏäµÎãàÎã§\",\"Í∑∏Î†áÏ£†\",\"Í∑∏Ïµ∏\",\"Í∑∏ÎüºÏöî\",\"Ï¢ãÏïÑÏöî\",\n",
        "    \"ÌóàÌóà\",\"ÌïòÌïò\",\"„Öé„Öé\",\"„Öã„Öã\",\"ÏïÑÌïò\",\"Ïò§ÌÇ§\",\"Ïò§ÏºÄÏù¥\",\"Ïòô\",\"ÏòàÏòà\",\"ÎÑ§ÎÑ§\"\n",
        "]\n",
        "def is_backchannel(s:str)->bool:\n",
        "    s = s.strip()\n",
        "    if not s: return False\n",
        "    # ÏïÑÏ£º ÏßßÍ≥† Í∞êÌÉÑ/ÎèôÏùòÎ•ò ÏúÑÏ£º\n",
        "    if len(s) <= 8:\n",
        "        for bc in BACKCHANNEL_LIST:\n",
        "            if s == bc or s.startswith(bc):\n",
        "                return True\n",
        "    # ÏùòÏÑ±Ïñ¥/Ï∂îÏûÑÏÉàÎßåÏúºÎ°ú Íµ¨ÏÑ±Îêú Í≤ΩÏö∞\n",
        "    if re.fullmatch(r'[„Öã„ÖéÏïÑÏñ¥ÏùåÎÑ§ÏòàÏùëÏò§Ïö∞ÏôÄ\\s]+', s):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "REQ_PAT = re.compile(r'(Ìï¥Ï§Ñ\\s*Ïàò|Ìï¥Ï£ºÏÑ∏Ïöî|Î∂ÄÌÉÅ|Í∞ÄÎä•Ìï†ÍπåÏöî|Í∞ÄÎä•\\s*ÌïúÍ∞ÄÏöî|\\?$)')\n",
        "NEG_PAT = re.compile(r'(ÏïÑÎãà|Î™ªÌïò|ÏóÜ[Îã§Ïñ¥Ïöî]?|Î¨∏Ï†ú|ÏóêÎü¨|ÌûòÎì§|Ïñ¥Î†µ|Í≥§ÎûÄ|Ïïà\\s*Îêò)')\n",
        "AGENDA_PAT = re.compile(r'(ÏùºÎã®|Î®ºÏ†Ä|Îã§Ïùå|Î™©Ìëú|Í≥ÑÌöç|Ï†ïÎ¶¨|ÏöîÏïΩ|ÌååÏù¥ÌîÑÎùºÏù∏|ÏùòÏ†ú|ÏïàÍ±¥)')\n",
        "GUIDE_PAT  = re.compile(r'(Ïûê[, ]|Í∑∏Îüº|ÏßÑÌñâ|ÌïòÏãúÏ£†|Ìï©ÏãúÎã§|Ìï¥Î≥¥Ï£†|ÎÑòÏñ¥Í∞Ä|ÎßêÏîÄÌï¥)')\n",
        "\n",
        "def summarize_rules(df:pd.DataFrame)->pd.DataFrame:\n",
        "    # ÌÉÄÏûÑÎùºÏù∏ Í∏∞Î∞ò Î≥¥Ï°∞ ÌîºÏ≤ò\n",
        "    df = df.copy()\n",
        "    df['is_back'] = df['text_core'].apply(is_backchannel)\n",
        "    df['is_req']  = df['text'].str.contains(REQ_PAT)\n",
        "    df['is_neg']  = df['text'].str.contains(NEG_PAT)\n",
        "    df['is_agenda'] = df['text'].str.contains(AGENDA_PAT)\n",
        "    df['is_guide']  = df['text'].str.contains(GUIDE_PAT)\n",
        "\n",
        "    # ÏùëÎãµ ÏßÄÏó∞(ÏßÅÏ†Ñ ÌÉÄÏù∏ Î∞úÌôî ‚Üí Ïù¥Î≤à ÎÇ¥ Î∞úÌôî)\n",
        "    df['resp_latency'] = np.nan\n",
        "    last_end_by_any = None\n",
        "    last_spk = None\n",
        "    for i,row in df.iterrows():\n",
        "        if not np.isnan(row.get('start', np.nan)) and last_end_by_any is not None and row['speaker']!=last_spk:\n",
        "            df.loc[i,'resp_latency'] = row['start'] - last_end_by_any\n",
        "        if not np.isnan(row.get('end', np.nan)):\n",
        "            last_end_by_any = row['end']\n",
        "        last_spk = row['speaker']\n",
        "\n",
        "    # ÌôîÏûêÎ≥Ñ ÏßëÍ≥Ñ\n",
        "    g = df.groupby('speaker', as_index=False)\n",
        "    tot_dur_all = df['dur'].dropna().sum()\n",
        "    def _safe_share(x):\n",
        "        return float(x)/tot_dur_all if (not np.isnan(x) and tot_dur_all>0) else np.nan\n",
        "\n",
        "    agg = g.agg(\n",
        "        num_utts=('text','count'),\n",
        "        total_chars=('char_len','sum'),\n",
        "        avg_chars=('char_len','mean'),\n",
        "        total_words=('word_len','sum'),\n",
        "        total_dur=('dur','sum'),\n",
        "        back_cnt=('is_back','sum'),\n",
        "        req_cnt=('is_req','sum'),\n",
        "        neg_cnt=('is_neg','sum'),\n",
        "        agenda_cnt=('is_agenda','sum'),\n",
        "        guide_cnt=('is_guide','sum'),\n",
        "        first_idx=('order','min'),\n",
        "        last_idx=('order','max'),\n",
        "        first_start=('start','min'),\n",
        "        last_end=('end','max'),\n",
        "        mean_latency=('resp_latency','mean')\n",
        "    )\n",
        "    # ÎπÑÏú®\n",
        "    agg['back_ratio'] = agg['back_cnt'] / agg['num_utts'].clip(lower=1)\n",
        "    agg['req_ratio']  = agg['req_cnt']  / agg['num_utts'].clip(lower=1)\n",
        "    agg['neg_ratio']  = agg['neg_cnt']  / agg['num_utts'].clip(lower=1)\n",
        "    agg['talk_share'] = agg['total_dur'].apply(_safe_share)\n",
        "\n",
        "    # ÏµúÎåÄ Î¨¥Î∞úÌôî Í∞ÑÍ≤©(ÏûêÏã†Ïùò Ïó∞ÏÜç ÌÑ¥ ÏÇ¨Ïù¥ gap)\n",
        "    max_gaps = []\n",
        "    for spk, d in g:\n",
        "        d2 = d.sort_values('order')\n",
        "        gaps = []\n",
        "        prev_end = None\n",
        "        for _,r in d2.iterrows():\n",
        "            if prev_end is not None and not (np.isnan(prev_end) or np.isnan(r.get('start',np.nan))):\n",
        "                gaps.append(r['start']-prev_end)\n",
        "            prev_end = r.get('end', np.nan)\n",
        "        max_gaps.append({'speaker':spk,'max_gap': max(gaps) if gaps else np.nan})\n",
        "    agg = agg.merge(pd.DataFrame(max_gaps), on='speaker', how='left')\n",
        "\n",
        "    # Í∑úÏπô ÎùºÎ≤®ÎßÅ\n",
        "    roles = []\n",
        "    for _,r in agg.iterrows():\n",
        "        role_tags = []\n",
        "        # 1) ÏßÑÌñâÏûê ÌõÑÎ≥¥\n",
        "        if (r.get('guide_cnt',0)>=4) or \\\n",
        "           ((not np.isnan(r.get('talk_share',np.nan)) and r['talk_share']>=0.30) and r.get('agenda_cnt',0)>=3):\n",
        "            role_tags.append('ÏßÑÌñâÏûê')\n",
        "\n",
        "        # 2) Î∞±Ï±ÑÎÑêÎü¨\n",
        "        if r['back_ratio']>=0.6 and r['avg_chars']<=12 and r['num_utts']>=3:\n",
        "            role_tags.append('Î∞±Ï±ÑÎÑêÎü¨')\n",
        "\n",
        "        # 3) ÏöîÏ≤≠Ïûê(ÏöîÏ≤≠/ÏßàÎ¨∏ ÎπàÎèÑ ÎÜíÏùå)\n",
        "        if r['req_ratio']>=0.30 and r['num_utts']>=2:\n",
        "            role_tags.append('ÏöîÏ≤≠Ïûê')\n",
        "\n",
        "        # 4) Î¨∏Ï†úÏ†úÍ∏∞/Ïö∞Î†§ Ï†úÏãú\n",
        "        if r['neg_ratio']>=0.25 and r['avg_chars']>=20:\n",
        "            role_tags.append('Ïö∞Î†§¬∑Î¨∏Ï†úÏ†úÍ∏∞')\n",
        "\n",
        "        # 5) Ïû†ÍπêÏ∞∏Ïó¨\n",
        "        if (r['num_utts']<=3 and (r['total_chars']<=40 or (not np.isnan(r['talk_share']) and r['talk_share']<0.05))):\n",
        "            role_tags.append('Ïû†ÍπêÏ∞∏Ïó¨')\n",
        "\n",
        "        # 6) Í∏∞Î≥∏ ÌÉúÍ∑∏\n",
        "        if not role_tags:\n",
        "            if not np.isnan(r.get('talk_share',np.nan)) and r['talk_share']>=0.20:\n",
        "                role_tags.append('ÌïµÏã¨Ï∞∏Ïó¨')\n",
        "            else:\n",
        "                role_tags.append('ÏùºÎ∞òÏ∞∏Ïó¨')\n",
        "\n",
        "        roles.append({'speaker':r['speaker'], 'role_tags':role_tags})\n",
        "    role_df = pd.DataFrame(roles)\n",
        "    return agg.merge(role_df, on='speaker', how='left').sort_values(\n",
        "        ['talk_share','num_utts','total_chars'], ascending=[False,False,False]\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "# ----- 3) ÎåÄÌëú Î∞úÌôî Ï∂îÏ∂ú -----\n",
        "def pick_representatives(df:pd.DataFrame, per_speaker:int=2)->dict:\n",
        "    reps = {}\n",
        "    # ÏãúÍ∞Ñ Ï∂ï percentile Í≥ÑÏÇ∞(ÏãúÍ∞Ñ ÏóÜÏúºÎ©¥ orderÎ•º ÎåÄÏö©)\n",
        "    has_time = df['start'].notna().any() and df['end'].notna().any()\n",
        "    timeline_key = 'start' if has_time else 'order'\n",
        "    # Î∞±Ï±ÑÎÑê/Îß§Ïö∞ ÏßßÏùÄ Î∞úÌôî Ï†úÏô∏\n",
        "    cand = df[~df['text_core'].apply(is_backchannel)].copy()\n",
        "    if cand.empty: cand = df.copy()\n",
        "    # Ïä§ÏΩîÏñ¥: Í∏∏Ïù¥ Ïö∞ÏÑ† + (Ï¥àÎ∞ò 20~40%/Ï§ëÎ∞ò 40~70%)ÏóêÏÑú ÌïòÎÇòÏî©\n",
        "    if has_time:\n",
        "        total_span = (np.nanmin(df['start']), np.nanmax(df['end']))\n",
        "        span = total_span[1] - total_span[0] if not np.isnan(total_span[0]) and not np.isnan(total_span[1]) else None\n",
        "        def pct(s):\n",
        "            if span and not np.isnan(s):\n",
        "                return (s - total_span[0]) / max(span, 1e-6)\n",
        "            return np.nan\n",
        "        cand['pos_pct'] = cand['start'].apply(pct)\n",
        "    else:\n",
        "        cand['pos_pct'] = cand['order'] / max(len(df), 1)\n",
        "\n",
        "    reps = {}\n",
        "    for spk, d in cand.groupby('speaker'):\n",
        "        d2 = d.sort_values(['char_len'], ascending=False)\n",
        "        early = d2.loc[(d2['pos_pct']>=0.20) & (d2['pos_pct']<=0.45)]\n",
        "        mid   = d2.loc[(d2['pos_pct']>0.45) & (d2['pos_pct']<=0.75)]\n",
        "        take = []\n",
        "        if not early.empty:\n",
        "            take.append(early.iloc[0])\n",
        "        if not mid.empty and len(take)<per_speaker:\n",
        "            take.append(mid.iloc[0])\n",
        "        # Î∂ÄÏ°±ÌïòÎ©¥ Í∑∏ÎÉ• Í∏¥ ÏàúÏúºÎ°ú Ï±ÑÏö∞Í∏∞\n",
        "        if len(take)<per_speaker:\n",
        "            for _,r in d2.iterrows():\n",
        "                if any(r.name==t.name for t in take):\n",
        "                    continue\n",
        "                take.append(r)\n",
        "                if len(take)>=per_speaker: break\n",
        "        reps[spk] = [\n",
        "            {\n",
        "              'start': float(r['start']) if not np.isnan(r['start']) else None,\n",
        "              'end':   float(r['end']) if not np.isnan(r['end']) else None,\n",
        "              'text':  r['text']\n",
        "            } for r in take\n",
        "        ]\n",
        "    return reps\n",
        "\n",
        "# ----- 4) Ïã§Ìñâ: ÌååÏùº ÏÑ†ÌÉù ‚Üí ÌååÏã± ‚Üí ÏöîÏïΩ/ÎåÄÌëúÎ∞úÌôî ‚Üí Ï†ÄÏû•/Îã§Ïö¥Î°úÎìú -----\n",
        "# ÌïÑÏöîÏóê Îî∞Îùº Ìïú Í∞úÎßå Ïã§ÌñâÌïòÍ≥† Ïã∂ÏúºÎ©¥ paths Î¶¨Ïä§Ìä∏ÏóêÏÑú ÌïòÎÇòÎßå ÎÇ®Í∏∞ÏÑ∏Ïöî.\n",
        "paths = [\n",
        "  \"/content/drive/MyDrive/final project/diarized/1106_Ïò§ÌõÑ_ÌöåÏùò_assemblyai1 (recommended result).txt\",\n",
        "  \"/content/drive/MyDrive/final project/diarized/1106_Ïò§ÌõÑ_ÌöåÏùò_senko (recommended result).txt\",\n",
        "]\n",
        "\n",
        "all_outputs = []\n",
        "for in_path in paths:\n",
        "    print(f\"\\n### Processing: {in_path}\")\n",
        "    df = load_diarized_to_df(in_path)\n",
        "    prof = summarize_rules(df)\n",
        "    reps = pick_representatives(df, per_speaker=2)\n",
        "\n",
        "    base = os.path.splitext(os.path.basename(in_path))[0]\n",
        "    df_path      = os.path.join(OUT_DIR, f\"{base}__utterances.parquet\")\n",
        "    prof_csv     = os.path.join(OUT_DIR, f\"{base}__speaker_profiles.csv\")\n",
        "    prof_json    = os.path.join(OUT_DIR, f\"{base}__speaker_profiles.json\")\n",
        "    reps_json    = os.path.join(OUT_DIR, f\"{base}__representatives.json\")\n",
        "\n",
        "    df.to_parquet(df_path, index=False)\n",
        "    prof.to_csv(prof_csv, index=False, encoding='utf-8')\n",
        "    with open(prof_json,'w',encoding='utf-8') as f:\n",
        "        json.dump(json.loads(prof.to_json(orient='records', force_ascii=False)), f, ensure_ascii=False, indent=2)\n",
        "    with open(reps_json,'w',encoding='utf-8') as f:\n",
        "        json.dump(reps, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    # Ï¶âÏãú Îã§Ïö¥Î°úÎìú(Colab ‚Üí Î°úÏª¨)\n",
        "    for p in [prof_csv, prof_json, reps_json]:\n",
        "        try:\n",
        "            files.download(p)\n",
        "        except Exception as e:\n",
        "            print(f\"(download skip) {p}: {e}\")\n",
        "\n",
        "    all_outputs.append({\n",
        "        'input': in_path,\n",
        "        'utterances_parquet': df_path,\n",
        "        'speaker_profiles_csv': prof_csv,\n",
        "        'speaker_profiles_json': prof_json,\n",
        "        'representatives_json': reps_json\n",
        "    })\n",
        "\n",
        "print(\"\\nDone. Summary:\")\n",
        "print(pd.DataFrame(all_outputs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "AjinLqFJ382F",
        "outputId": "c64f37f6-be0f-4ee9-ca0e-74b7200ccbc3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### Processing: /content/drive/MyDrive/final project/diarized/1106_Ïò§ÌõÑ_ÌöåÏùò_assemblyai1 (recommended result).txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6b7af2be-6868-426a-9ce6-0b2b61810d1f\", \"1106_\\uc624\\ud6c4_\\ud68c\\uc758_assemblyai1 (recommended result)__speaker_profiles.csv\", 914)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6e5e3126-771b-4d42-ba29-62dc1a5f0c0b\", \"1106_\\uc624\\ud6c4_\\ud68c\\uc758_assemblyai1 (recommended result)__speaker_profiles.json\", 2793)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f74ffa3d-7ce6-4d80-a74d-5201a140626a\", \"1106_\\uc624\\ud6c4_\\ud68c\\uc758_assemblyai1 (recommended result)__representatives.json\", 7159)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### Processing: /content/drive/MyDrive/final project/diarized/1106_Ïò§ÌõÑ_ÌöåÏùò_senko (recommended result).txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_21a00aa1-5b20-446e-8a13-fc151ada51f4\", \"1106_\\uc624\\ud6c4_\\ud68c\\uc758_senko (recommended result)__speaker_profiles.csv\", 1267)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4bc06fc7-0a09-4d37-b573-382d9e150d8b\", \"1106_\\uc624\\ud6c4_\\ud68c\\uc758_senko (recommended result)__speaker_profiles.json\", 2873)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_97881d07-6961-4410-86c1-b36d813a3cbf\", \"1106_\\uc624\\ud6c4_\\ud68c\\uc758_senko (recommended result)__representatives.json\", 7290)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Done. Summary:\n",
            "                                               input  \\\n",
            "0  /content/drive/MyDrive/final project/diarized/...   \n",
            "1  /content/drive/MyDrive/final project/diarized/...   \n",
            "\n",
            "                                  utterances_parquet  \\\n",
            "0  /content/work/outputs/1106_Ïò§ÌõÑ_ÌöåÏùò_assemblyai1 (...   \n",
            "1  /content/work/outputs/1106_Ïò§ÌõÑ_ÌöåÏùò_senko (recomm...   \n",
            "\n",
            "                                speaker_profiles_csv  \\\n",
            "0  /content/work/outputs/1106_Ïò§ÌõÑ_ÌöåÏùò_assemblyai1 (...   \n",
            "1  /content/work/outputs/1106_Ïò§ÌõÑ_ÌöåÏùò_senko (recomm...   \n",
            "\n",
            "                               speaker_profiles_json  \\\n",
            "0  /content/work/outputs/1106_Ïò§ÌõÑ_ÌöåÏùò_assemblyai1 (...   \n",
            "1  /content/work/outputs/1106_Ïò§ÌõÑ_ÌöåÏùò_senko (recomm...   \n",
            "\n",
            "                                representatives_json  \n",
            "0  /content/work/outputs/1106_Ïò§ÌõÑ_ÌöåÏùò_assemblyai1 (...  \n",
            "1  /content/work/outputs/1106_Ïò§ÌõÑ_ÌöåÏùò_senko (recomm...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "41B9KLV238zV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g7dcV1WO38wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6S9ftiXZ38t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tckOFKCm38rM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ydSs2FEC38om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GTI8_d0w38mE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qw8cYax-38jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R7WUoRVy38g8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tbsAYpBa38eN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eRgfT1jP38bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fm_zo7Aj38ZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GyfLrGnD38We"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xiy-95iL38Tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BskmJ6hh38RN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}