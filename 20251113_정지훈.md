# klue/roberta-large 파인튜닝
## 진행 시간
09:30 ~ 11:00
## 진행 방식
제미나이와 gpt를 이용해서 바이브 코딩으로 진행
## 한계점
버전을 명시하고 명확하게 지시를 해도 여러 에러가 계속 나옴
에러 한개를 해결하고 다음 에러를 해결하면 이전에 발생했던 에러 발생 -> 무한 반복함
## 결과
바이브 코딩과 내 지식으로는 진행이 더 힘들다고 판단해 파인튜닝 방식은 포기

# 모델 서칭
## 진행 시간
11:00 ~ 11:30
## 진행 방식
1. 제미나이와 gpt, 구글링, 허깅페이스 탐색
2. 허깅페이스에서 Token Classification 체크 후 검색창에 ko. ner 등을 넣어서 탐색
3. 인기 순위를 기준으로 여러 모델을 테스트
## 결과
korean-pii-masking 모델 발견


# korean-pii-masking
## 진행 시간
11:30 ~ 17:50
## 진행 방식
제미나이와 gpt를 이용해서 바이브 코딩으로 진행
## 결과
1. 기존의 허깅페이스의 다른 모델보다도 ner을 통해서 이름인식 기능은 제일 잘 나옴
2. 원하던 score도 나와서 정성적 판단 결과 필요한 이름들은 score가 0.95 이상이라고 판단
3. score 0.95 이상 인것들만 출력 시 배경지식이 있는 나에 의한 판단으로는 같은 인물이지만 stt 결과에서 조금 다르게 인식하는 경우 발견(지훈, 기훈 등)
4. 군집화를 위해 Levenshtein 과 jellyfish 테스트
5. Levenshtein의 결과가 더 잘 나와서 Levenshtein 으로 진행
6. 초창기에는 "상주"와 "이상준"이 동일 인물이지만 묶이지 못하는 상황 인지
7. 해결을 위해 바이브 코딩 중 어느 순간 "상주"를 인식 못함
8. 다시 찾는 코드를 하고 처리 방법을 고민하다가 과적합을 우려해 그냥 진행함
9. 대비책으로 threshold=1 말고 다른 값을 넣어보다가 1.5가 가장 이상적임을 발견해서 1.5으로 진행 -> jellyfish도 테스트 다시 해볼까하다가 threshold 방식이 아니여서 귀찮아서 포기
10. LLM에서 태깅 작업을 위해 text 파일로 구글 드라이브에 (경로 : /content/drive/MyDrive/final_project/) 저장