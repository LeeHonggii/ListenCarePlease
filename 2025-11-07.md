#To Do
- SpeechBrain 설명 및 결과 공유
- 음성 데이터 전처리 방식 탐색 및 시도


#진행과정
- SpeechBrain
    - 빠른 속도
    - 발화자 분리 미숙(5인 음성 기준 3~4인만 잡는다.)
    - 낮은 성능으로 인한 폐기

- 음성 데이터 전처리
[입력: y (waveform)]
       │
       ▼
───────────────────────────────────────────────
① 프레임 분할 (frame_generator)
───────────────────────────────────────────────
  - 일정 프레임 단위(10ms 등)로 쪼갬
  - 각 프레임 → webrtcvad.is_speech()로
    "말소리인지/무음인지" 판정
  - 결과: [(start, end, True/False), ...] 리스트
       │
       ▼
───────────────────────────────────────────────
② 음성 구간 추출 (speech segment detection)
───────────────────────────────────────────────
  - 연속된 True 구간을 하나의 “발화 세그먼트”로 병합
  - 결과: [(seg_start, seg_end), (seg_start2, seg_end2), ...]
       │
       ▼
───────────────────────────────────────────────
③ 앞뒤 패딩 (padding)
───────────────────────────────────────────────
  - 각 세그먼트에 ±PAD_MS 만큼 앞뒤 확장  
    → s_p = max(0, s - pad), e_p = min(len(y), e + pad)
  - 말소리 초입/끝이 잘리는 걸 방지
       │
       ▼
───────────────────────────────────────────────
④ 자르기 (cut)
───────────────────────────────────────────────
  - 원본 y에서 해당 구간들을 잘라냄  
    → seg_wave = y[s_p:e_p]
       │
       ▼
───────────────────────────────────────────────
⑤ 합성 (concatenate)
───────────────────────────────────────────────
  - 잘라낸 세그먼트들을 순서대로 이어붙임  
  - (겹침 방지 + 부드럽게 연결 위해 crossfade_ms 옵션 존재)
       │
       ▼
[출력: y_vad (무음 제거 후 연속 음성)]

#진행 중 어려운 점
- 음성 중복 발생
    - VAD padding 문제
    - padding 150, 100, 50, 0 조정
- 음성 출력 낮아짐
    - 프리엠퍼시스, VAD, 노이즈 억제 융합문제


#해결 방안 및 고민
- Nemo, Senko 모두 내부에 VAD 작업 진행
    - 굳이 VAD를 전처리에서 진행 할 필요가 없다.
    - VAD padding = 0/VAD 제거 버전 2가지 실험 예정
- DC, STFT, MelSpectogram만 사용하여 진행 예정