#보이스피싱
- 데이터 셋
    - 금융 감독원
        - 바로 이 목소리 : 영상 파일(.mp4) 94건
        - 그놈 목소리 : 음성 파일(.mp3)
            - 대출사기형 : 185건
            - 수사기관 사칭형 : 227건
        - 총합 : 506건
    - KorCCVi(csv)
        - 2927개 데이터(label : 0/1)
        - 0 : 일반 데이터 - 2232개
        - 1 : 보이스 피싱 데이터 - 695개
        - 총합 : 2927개

- 파이프라인
┌──────────────────────────────────────────────────────────────┐
│  Input: 음성 데이터 세트                                      │
│  - KorCCVi 음성 (통화/상담)                                   │
│  - 금감원 보이스피싱 504개 음성                               │
│  메타: 통화길이, 채널, 라벨(피싱/정상, 유형)                   │
└──────────────────────────────────────────────────────────────┘
                           ↓
┌──────────────────────────────────────────────────────────────┐
│  Data Preprocessing                                          │
│  - 표준화(16kHz mono), VAD, 무성구간/침묵 검출                │
│  - 노이즈 제거/레벨링, 세그먼트 자르기(예: 5~30초)            │
│  - 라벨 정합/클래스 불균형 처리(가중치/오버샘플/컷믹스)        │
└──────────────────────────────────────────────────────────────┘
                           ↓
┌──────────────────────────────────────────────────────────────┐
│  ASR(음성→텍스트)                                            │
│  - 한국어 ASR(예: Whisper-ko, 파라미터 고정/미세튜닝 선택)    │
│  - 타임스탬프 단어/문장 단위 정렬                             │
│  산출: 전사 텍스트, 발화 단위 시간구간                        │
└──────────────────────────────────────────────────────────────┘
                 ↓                            ↓
      (A) Acoustic/Paralinguistic Path   (B) Text/Linguistic Path
┌──────────────────────────────────────┐   ┌──────────────────────────────────────┐
│  Acoustic Feature Encoder            │   │  Text Feature Encoder                │
│  - 스펙트로그램/로그멜               │   │  - KoBERT / KLUE-RoBERTa 임베딩     │
│  - MFCC/에너지/피치/폼란트           │   │  - 위험어휘 스코어(사전+규칙)        │
│  - 말속도, 휴지(pause), 억양         │   │  - N-gram/키프레이즈/개체명          │
│  - 화자 임베딩(ECAPA/x-vector)       │   │  - 문장 행위(요구/협박/유도) 힌트     │
│  Encoder: CNN/Conformer/AST          │   │  Encoder: Transformer Encoder        │
│  산출: A-임베딩(음향·화자·감정 단서)  │   │  산출: B-임베딩(의미·어휘·문맥 단서) │
└──────────────────────────────────────┘   └──────────────────────────────────────┘
                 ↓                            ↓
               ┌────────────────────────────────────────────────┐
               │  Cross-Modal Fusion (교차 주의/특징 융합)      │
               │  - Cross-Attention(A↔B)                        │
               │  - [CLS] 토큰 기반 가중 결합                   │
               │  - 메타피처(통화길이/시간대/채널) 추가          │
               │  산출: 통합 임베딩(Z)                          │
               └────────────────────────────────────────────────┘
                                   ↓
┌──────────────────────────────────────────────────────────────┐
│  Classification Head                                         │
│  - 보이스피싱 여부(이진)                                     │
│  - 세부유형(대출사기/기관사칭/메신저피싱 등, 선택)            │
│  - 신뢰도(Prob.)/리스크 점수                                 │
│  Loss: BCE(+Focal), 유형 CE, 멀티태스크 가중 합               │
└──────────────────────────────────────────────────────────────┘
                                   ↓
┌──────────────────────────────────────────────────────────────┐
│  Training & Validation                                       │
│  - Stratified K-Fold / 세션 분리(발화자/통화 누수 방지)       │
│  - SpecAugment/NoiseMix, 텍스트 드롭아웃/동의어 치환          │
│  - 조기종료/스케줄러, 클래스가중치                            │
│  - 지표: AUC, F1, Precision@Recall(=95%), EER(화자 단서)      │
└──────────────────────────────────────────────────────────────┘
                                   ↓
┌──────────────────────────────────────────────────────────────┐
│  Inference & Monitoring                                      │
│  - 실시간 스트리밍: 프레임 단위 리스크 누적                   │
│  - 구간별 해설(키워드/억양 급변) 하이라이트                   │
│  - 임계값 초과 시 경고/차단 트리거                            │
│  - 데이터 드리프트/ASR WER 모니터링                          │
└──────────────────────────────────────────────────────────────┘



#작가 문체 학습
- 데이터 셋
    - google books ngram dataset
        - 계속되는 오류
        - 제대로 된 데이터 셋이 맞나? 검증 필요
    - Books Author Classifier(Kaggle)
        - csv file
        - 1578 data
            - Author set : 83
            - Quotes set : 1555
            - 왜 다르지?
    - goodreads books/author data
        - 이름/성별/장르/출생지 정리
        - 상점 페이지 가져옴 : 제대로 된 문체 학습 불가 판단
    - 대규모 구매도서 기반 한국어 말뭉치 데이터
        - https://www.aihub.or.kr/aihubdata/data/view.do?pageIndex=3&currMenu=115&topMenu=100&srchOptnCnd=OPTNCND001&searchKeyword=%EB%A7%90%EB%AD%89%EC%B9%98&srchDetailCnd=DETAILCND001&srchOrder=ORDER001&srchPagePer=20&aihubDataSe=data&dataSetSn=653
	    - 저자, 텍스트만 뽑아 사용?

- 파이프라인
┌──────────────────────────────────────────────────────────────┐
│  Input: 텍스트 코퍼스                                         │
│  - Kaggle: Books Author Classifier (작가 라벨 포함)            │
│  - AI Hub: 구매도서 기반 한국어 말뭉치(대규모 문장/문단)        │
│  메타: 작가ID/장르/출판연도(가능 시)                           │
└──────────────────────────────────────────────────────────────┘
                           ↓
┌──────────────────────────────────────────────────────────────┐
│  Data Preprocessing                                          │
│  - 정제: 중복/노이즈/문장 분할(kss), 따옴표/각주 제거          │
│  - 라벨 정합: 작가ID 표준화, 저자·시대·장르 메타 정리          │
│  - 토큰화: 형태소/서브워드(BPE), 긴 문단 슬라이싱              │
└──────────────────────────────────────────────────────────────┘
                           ↓
┌──────────────────────────────────────────────────────────────┐
│  Style Bank Construction                                     │
│  - 작가별 스타일 프로파일 생성(문체 통계/품사분포/구문패턴)     │
│  - 키프레이즈/어휘 분포, 리듬(문장 길이·부사/접속사 비율)       │
│  산출: 작가 스타일 코드(style embedding)                      │
└──────────────────────────────────────────────────────────────┘
                           ↓
┌──────────────────────────────────────────────────────────────┐
│  Style Encoder                                               │
│  - Text CNN/Transformer로 문단→스타일 임베딩                  │
│  - 작가 분류 보조손실(Author-ID CE)로 스타일 정보 강화         │
│  산출: s (style vector)                                      │
└──────────────────────────────────────────────────────────────┘
                           ↓
┌──────────────────────────────────────────────────────────────┐
│  Content Encoder                                             │
│  - 의미 보존 인코더(예: KLUE-RoBERTa/KoBERT)                 │
│  - NER/의존구문으로 핵심 의미·개체 잠금(content mask)         │
│  산출: c (content representation)                            │
└──────────────────────────────────────────────────────────────┘
                           ↓
┌──────────────────────────────────────────────────────────────┐
│  Style-Guided Editor (교정/변환 디코더)                       │
│  - Encoder-Decoder / Prefix-LM / BART-ko                     │
│  - 입력: 초안 텍스트 + c + s (+ style strength α)            │
│  - 제약: 의미 보존·금칙어·길이/톤 컨트롤                      │
│  산출: 작가 스타일에 맞춘 교정문                             │
└──────────────────────────────────────────────────────────────┘
                           ↓
┌──────────────────────────────────────────────────────────────┐
│  Training Objectives                                         │
│  - L_lm: 문장 생성/교정 언어모델 손실                         │
│  - L_style: 생성문 스타일 판별 정확도(Style Clf)             │
│  - L_content: 의미 보존(BERTScore/Cosine, copy constraints)   │
└──────────────────────────────────────────────────────────────┘
                           ↓
┌──────────────────────────────────────────────────────────────┐
│  Inference Pipeline                                          │
│  - 입력 초안 + 목표 작가(또는 자동추정)                       │
│  - 스타일 강도/길이/어휘격식 하이퍼파라미터                   │
│  - 출력: 동일 의미, 목표 문체로 교정된 결과                   │
└──────────────────────────────────────────────────────────────┘
                           ↓
┌──────────────────────────────────────────────────────────────┐
│  Evaluation & Safety                                         │
│  - 스타일 정확도(작가 판별기), PPL, BLEU/BERTScore             │
│  - 과교정/표절 감시, 금칙어/민감개체 보존 여부 체크           │
│  - 휴리스틱/규칙 기반 품질 점수 + 샘플 리뷰                    │
└──────────────────────────────────────────────────────────────┘
