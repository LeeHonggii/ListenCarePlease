# 경제 뉴스 정리 AI
[ref_구글 뉴스 AI 요약봇 만들기](https://wikidocs.net/290959 )

## workflow
~~~ markdwon
Schedule Trigger → RSS Feed Read → Loop Over Items → HTTP Request → HTML Extract → Content Processor → OpenAI Chat Model → Slack → Wait
~~~


1. Schedule Trigger (스케줄 트리거)
자동화를 시작하는 시작점입니다. 정해진 시간 간격(예: 매 시간, 매일 오전 9시 등)마다 워크플로우를 자동으로 실행합니다.

2. RSS Feed Read (RSS 피드 읽기)
구글 뉴스의 RSS 피드 URL에 접속하여 최신 뉴스 목록을 가져옵니다. RSS는 뉴스 사이트가 제공하는 표준화된 콘텐츠 피드 형식입니다.

3. Loop Over Items (항목 반복)
RSS 피드에서 가져온 여러 개의 뉴스 기사들을 하나씩 처리하기 위해 반복문을 시작합니다. 각 뉴스 항목마다 다음 단계들이 실행됩니다.

4. HTTP Request (HTTP 요청)
각 뉴스 기사의 URL로 HTTP 요청을 보내 실제 기사의 전체 웹페이지 내용을 가져옵니다.

5. HTML Extract (HTML 추출)
가져온 웹페이지의 HTML 코드에서 실제 기사 본문만을 추출합니다. 광고, 메뉴, 푸터 등 불필요한 요소는 제거하고 순수한 텍스트 콘텐츠만 뽑아냅니다.

6. Content Processor (콘텐츠 처리)
추출된 텍스트를 정리하고 가공합니다. 공백 제거, 특수문자 정리, 텍스트 길이 제한 등의 전처리 작업을 수행합니다.

7. OpenAI Chat Model (OpenAI 챗 모델)
정리된 기사 내용을 OpenAI API(예: GPT-4)에 전달하여 요약문을 생성합니다. "이 기사를 3문장으로 요약해줘" 같은 프롬프트와 함께 전송됩니다.

8. Slack (슬랙)
AI가 생성한 요약문을 슬랙 채널이나 특정 사용자에게 메시지로 전송합니다. 기사 제목, 요약문, 원문 링크 등을 포함하여 보냅니다.

9. Wait (대기)
다음 기사를 처리하기 전에 잠시 대기합니다. API 호출 제한(Rate Limit)을 피하고 서버에 부담을 주지 않기 위한 단계입니다.

---

**전체 흐름 요약** <br>
정해진 시간마다 구글 뉴스 RSS를 확인 → 새 기사들을 하나씩 가져와서 → AI로 요약하고 → 슬랙으로 전송하는 자동화 프로세스입니다.


## 구글 뉴스 AI 요약봇 워크플로우 - NLP Task 관점 분류

### 1. Automation & Scheduling (자동화 및 스케줄링)
- **Schedule Trigger**: 워크플로우 자동 실행 관리

---

### 2. Data Collection (데이터 수집)
- **RSS Feed Read**: 뉴스 피드에서 메타데이터 수집
- **HTTP Request**: 실제 뉴스 기사 원문 수집

---

### 3. Data Preprocessing (데이터 전처리)
- **Loop Over Items**: 배치 처리를 위한 데이터 구조화
- **HTML Extract**: 웹 크롤링 및 텍스트 추출
- **Content Processor**: 텍스트 정제 (노이즈 제거, 정규화, 토큰화 등)

---

### 4. NLP Core Task (핵심 NLP 작업)
- **OpenAI Chat Model**: **Text Summarization (텍스트 요약)**
  - Extractive or Abstractive Summarization
  - LLM 기반 자연어 생성 (NLG)

---

### 5. Output & Delivery (결과 전달)
- **Slack**: 사용자 인터페이스 / 결과 배포

---

### 6. System Optimization (시스템 최적화)
- **Wait**: Rate Limiting, API 호출 제어

---

### NLP Task 분류 요약

| 단계 | NLP Task 카테고리 | 세부 작업 |
|------|------------------|----------|
| Schedule Trigger | Automation | 스케줄링 |
| RSS Feed Read | Data Collection | 메타데이터 수집 |
| Loop Over Items | Data Preprocessing | 반복 처리 구조화 |
| HTTP Request | Data Collection | 원문 수집 (Web Scraping) |
| HTML Extract | Data Preprocessing | 텍스트 추출 |
| Content Processor | Data Preprocessing | 텍스트 정제 (Cleaning, Normalization) |
| OpenAI Chat Model | **NLP Core Task** | **Text Summarization (요약)** |
| Slack | Output Delivery | 결과 전달 |
| Wait | System Optimization | Rate Limiting |

---

## 주요 NLP 기술 스택

### 전처리 단계
- Web Scraping
- HTML Parsing
- Text Cleaning
- Tokenization

### 핵심 NLP 작업
- **Abstractive Summarization** (추상적 요약)
- Large Language Model (LLM) 활용
- Prompt Engineering

### 잠재적 확장 가능 NLP Tasks
- Named Entity Recognition (NER) - 주요 인물/장소 추출
- Sentiment Analysis - 뉴스 감성 분석
- Topic Modeling - 뉴스 주제 분류
- Keyword Extraction - 핵심 키워드 추출

## 고민사항
task : summrization + traslation

모델을 만든다면 요약기(영) + 번역기(영->한) 의 과제가 될듯

영 요약기에는 kaggle의 amazon 리뷰 데이터 사용 (review - summary)

번역기 모델에는 ai-hub 한국어-영어 번역 말뭉치 데이터 적절해보임

# 발화자 자동 태깅 음성 요약 서비스

기본적으로 음성기반 Classification(화자 인식) + STT task로 생각할 수 있다.

## 화자 인식 (speaker recognition)

유사도?
* **화자 식별 (speaker identification) : 말한 사람이 누구인가**
    - 목적 : 주어진 음성이 미리 정의된 화자 중 누구에 해당하는지 식별
    - 동작 : 시스템은 사전에 등록된 여러 회자들의 특성을 구분하여 학습하고, 주어진 음성이 어떤 화자에 해당하는지 식별합니다.
    [ref](https://gambalabs.ai/speaker-recognition/)
    [Speaker Recognition_ref](https://velog.io/@judy_choi/Speaker-Recognition-Diarization)

* 화자 검증 (speaker verification) : A가 말한게 맞아?
* 화자 분리 (speaker separation) : 오디오 물린거 분리하기
* 화자 분할 (speaker diarization) : 오디오 안물리고 화자가 다름을 인식

## data
[aihub_한국어 음성](https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=data&dataSetSn=123)

[aihub_화자 인식용 음성 데이터](https://aihub.or.kr/aihubdata/data/view.do?dataSetSn=537)

## 프레임워크
[화자분할 프레임워크](https://velog.io/@judy_choi/%ED%99%94%EC%9E%90%EB%B6%84%ED%95%A0-%EC%98%A4%ED%94%88%EC%86%8C%EC%8A%A4-%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%AC-%EC%86%8C%EA%B0%9C)

[]